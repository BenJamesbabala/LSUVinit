I1123 22:08:53.257860 12543 upgrade_proto.cpp:990] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': mnist/fitnet_mnist_lsuv_rms_SVM.prototxt
I1123 22:08:53.258041 12543 upgrade_proto.cpp:997] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W1123 22:08:53.258047 12543 upgrade_proto.cpp:999] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I1123 22:08:53.258139 12543 caffe.cpp:184] Using GPUs 0
I1123 22:08:53.396775 12543 solver.cpp:47] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.002
display: 100
max_iter: 50000
lr_policy: "step"
gamma: 0.1
weight_decay: 0.0005
stepsize: 15000
snapshot_prefix: "snapshots/fitnet_mnist_lsuv_SVM"
solver_mode: GPU
device_id: 0
net_param {
  name: "FitNet_MNIST"
  layer {
    name: "mnist"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.004
    }
    data_param {
      source: "../mnist/mnist_train_lmdb"
      batch_size: 64
      backend: LMDB
    }
  }
  layer {
    name: "mnist"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.004
    }
    data_param {
      source: "../mnist/mnist_test_lmdb"
      batch_size: 100
      backend: LMDB
    }
  }
  layer {
    name: "conv1_1a"
    type: "Convolution"
    bottom: "data"
    top: "conv1_1a"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 16
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv1_1b"
    type: "Convolution"
    bottom: "data"
    top: "conv1_1b"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 16
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv1_1"
    type: "Eltwise"
    bottom: "conv1_1a"
    bottom: "conv1_1b"
    top: "conv1_1"
    eltwise_param {
      operation: MAX
    }
  }
  layer {
    name: "conv1_2a"
    type: "Convolution"
    bottom: "conv1_1"
    top: "conv1_2a"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 16
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv1_2b"
    type: "Convolution"
    bottom: "conv1_1"
    top: "conv1_2b"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 16
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv1_2"
    type: "Eltwise"
    bottom: "conv1_2a"
    bottom: "conv1_2b"
    top: "conv1_2"
    eltwise_param {
      operation: MAX
    }
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1_2"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 4
      stride: 2
    }
  }
  layer {
    name: "conv2_1a"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2_1a"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 16
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv2_1b"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2_1b"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 16
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv2_1"
    type: "Eltwise"
    bottom: "conv2_1a"
    bottom: "conv2_1b"
    top: "conv2_1"
    eltwise_param {
      operation: MAX
    }
  }
  layer {
    name: "conv2_2a"
    type: "Convolution"
    bottom: "conv2_1"
    top: "conv2_2a"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 16
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv2_2b"
    type: "Convolution"
    bottom: "conv2_1"
    top: "conv2_2b"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 16
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv2_2"
    type: "Eltwise"
    bottom: "conv2_2a"
    bottom: "conv2_2b"
    top: "conv2_2"
    eltwise_param {
      operation: MAX
    }
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "conv2_2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 4
      stride: 2
    }
  }
  layer {
    name: "conv3_1a"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3_1a"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 12
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv3_1b"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3_1b"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 12
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv3_1"
    type: "Eltwise"
    bottom: "conv3_1a"
    bottom: "conv3_1b"
    top: "conv3_1"
    eltwise_param {
      operation: MAX
    }
  }
  layer {
    name: "conv3_2a"
    type: "Convolution"
    bottom: "conv3_1"
    top: "conv3_2a"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 12
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv3_2b"
    type: "Convolution"
    bottom: "conv3_1"
    top: "conv3_2b"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    convolution_param {
      num_output: 12
      pad: 1
      kernel_size: 3
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "conv3_2"
    type: "Eltwise"
    bottom: "conv3_2a"
    bottom: "conv3_2b"
    top: "conv3_2"
    eltwise_param {
      operation: MAX
    }
  }
  layer {
    name: "pool3"
    type: "Pooling"
    bottom: "conv3_2"
    top: "pool3"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layer {
    name: "final_drop"
    type: "Dropout"
    bottom: "pool3"
    top: "final_drop"
    dropout_param {
      dropout_ratio: 0.3
    }
  }
  layer {
    name: "clf"
    type: "InnerProduct"
    bottom: "final_drop"
    top: "clf"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 1
    }
    inner_product_param {
      num_output: 10
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "clf"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "HingeLoss"
    bottom: "clf"
    bottom: "label"
    top: "loss"
    hinge_loss_param {
      norm: L1
    }
  }
}
test_initialization: false
average_loss: 40
rms_decay: 0.99
type: "RMSProp"
I1123 22:08:53.396883 12543 solver.cpp:85] Creating training net specified in net_param.
I1123 22:08:53.396991 12543 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1123 22:08:53.397029 12543 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1123 22:08:53.397238 12543 net.cpp:49] Initializing net from parameters: 
name: "FitNet_MNIST"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.004
  }
  data_param {
    source: "../mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1b"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1"
  type: "Eltwise"
  bottom: "conv1_1a"
  bottom: "conv1_1b"
  top: "conv1_1"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "conv1_2a"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2b"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2"
  type: "Eltwise"
  bottom: "conv1_2a"
  bottom: "conv1_2b"
  top: "conv1_2"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 2
  }
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1a"
  bottom: "conv2_1b"
  top: "conv2_1"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2a"
  bottom: "conv2_2b"
  top: "conv2_2"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 2
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1a"
  bottom: "conv3_1b"
  top: "conv3_1"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2a"
  bottom: "conv3_2b"
  top: "conv3_2"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "final_drop"
  type: "Dropout"
  bottom: "pool3"
  top: "final_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "clf"
  type: "InnerProduct"
  bottom: "final_drop"
  top: "clf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "HingeLoss"
  bottom: "clf"
  bottom: "label"
  top: "loss"
  hinge_loss_param {
    norm: L1
  }
}
I1123 22:08:53.397440 12543 layer_factory.hpp:76] Creating layer mnist
I1123 22:08:53.398068 12543 net.cpp:106] Creating Layer mnist
I1123 22:08:53.398079 12543 net.cpp:411] mnist -> data
I1123 22:08:53.398113 12543 net.cpp:411] mnist -> label
I1123 22:08:53.398733 12547 db_lmdb.cpp:38] Opened lmdb ../mnist/mnist_train_lmdb
I1123 22:08:53.404530 12543 data_layer.cpp:41] output data size: 64,1,28,28
I1123 22:08:53.405216 12543 net.cpp:150] Setting up mnist
I1123 22:08:53.405232 12543 net.cpp:157] Top shape: 64 1 28 28 (50176)
I1123 22:08:53.405239 12543 net.cpp:157] Top shape: 64 (64)
I1123 22:08:53.405243 12543 net.cpp:165] Memory required for data: 200960
I1123 22:08:53.405254 12543 layer_factory.hpp:76] Creating layer data_mnist_0_split
I1123 22:08:53.405269 12543 net.cpp:106] Creating Layer data_mnist_0_split
I1123 22:08:53.405277 12543 net.cpp:454] data_mnist_0_split <- data
I1123 22:08:53.405288 12543 net.cpp:411] data_mnist_0_split -> data_mnist_0_split_0
I1123 22:08:53.405300 12543 net.cpp:411] data_mnist_0_split -> data_mnist_0_split_1
I1123 22:08:53.405339 12543 net.cpp:150] Setting up data_mnist_0_split
I1123 22:08:53.405347 12543 net.cpp:157] Top shape: 64 1 28 28 (50176)
I1123 22:08:53.405352 12543 net.cpp:157] Top shape: 64 1 28 28 (50176)
I1123 22:08:53.405365 12543 net.cpp:165] Memory required for data: 602368
I1123 22:08:53.405370 12543 layer_factory.hpp:76] Creating layer conv1_1a
I1123 22:08:53.405388 12543 net.cpp:106] Creating Layer conv1_1a
I1123 22:08:53.405393 12543 net.cpp:454] conv1_1a <- data_mnist_0_split_0
I1123 22:08:53.405402 12543 net.cpp:411] conv1_1a -> conv1_1a
I1123 22:08:53.508100 12543 net.cpp:150] Setting up conv1_1a
I1123 22:08:53.508126 12543 net.cpp:157] Top shape: 64 16 28 28 (802816)
I1123 22:08:53.508129 12543 net.cpp:165] Memory required for data: 3813632
I1123 22:08:53.508150 12543 layer_factory.hpp:76] Creating layer conv1_1b
I1123 22:08:53.508167 12543 net.cpp:106] Creating Layer conv1_1b
I1123 22:08:53.508172 12543 net.cpp:454] conv1_1b <- data_mnist_0_split_1
I1123 22:08:53.508180 12543 net.cpp:411] conv1_1b -> conv1_1b
I1123 22:08:53.509778 12543 net.cpp:150] Setting up conv1_1b
I1123 22:08:53.509789 12543 net.cpp:157] Top shape: 64 16 28 28 (802816)
I1123 22:08:53.509793 12543 net.cpp:165] Memory required for data: 7024896
I1123 22:08:53.509804 12543 layer_factory.hpp:76] Creating layer conv1_1
I1123 22:08:53.509812 12543 net.cpp:106] Creating Layer conv1_1
I1123 22:08:53.509816 12543 net.cpp:454] conv1_1 <- conv1_1a
I1123 22:08:53.509822 12543 net.cpp:454] conv1_1 <- conv1_1b
I1123 22:08:53.509829 12543 net.cpp:411] conv1_1 -> conv1_1
I1123 22:08:53.509865 12543 net.cpp:150] Setting up conv1_1
I1123 22:08:53.509872 12543 net.cpp:157] Top shape: 64 16 28 28 (802816)
I1123 22:08:53.509876 12543 net.cpp:165] Memory required for data: 10236160
I1123 22:08:53.509881 12543 layer_factory.hpp:76] Creating layer conv1_1_conv1_1_0_split
I1123 22:08:53.509887 12543 net.cpp:106] Creating Layer conv1_1_conv1_1_0_split
I1123 22:08:53.509891 12543 net.cpp:454] conv1_1_conv1_1_0_split <- conv1_1
I1123 22:08:53.509897 12543 net.cpp:411] conv1_1_conv1_1_0_split -> conv1_1_conv1_1_0_split_0
I1123 22:08:53.509904 12543 net.cpp:411] conv1_1_conv1_1_0_split -> conv1_1_conv1_1_0_split_1
I1123 22:08:53.509934 12543 net.cpp:150] Setting up conv1_1_conv1_1_0_split
I1123 22:08:53.509941 12543 net.cpp:157] Top shape: 64 16 28 28 (802816)
I1123 22:08:53.509948 12543 net.cpp:157] Top shape: 64 16 28 28 (802816)
I1123 22:08:53.509950 12543 net.cpp:165] Memory required for data: 16658688
I1123 22:08:53.509954 12543 layer_factory.hpp:76] Creating layer conv1_2a
I1123 22:08:53.509963 12543 net.cpp:106] Creating Layer conv1_2a
I1123 22:08:53.509968 12543 net.cpp:454] conv1_2a <- conv1_1_conv1_1_0_split_0
I1123 22:08:53.509974 12543 net.cpp:411] conv1_2a -> conv1_2a
I1123 22:08:53.511999 12543 net.cpp:150] Setting up conv1_2a
I1123 22:08:53.512012 12543 net.cpp:157] Top shape: 64 16 28 28 (802816)
I1123 22:08:53.512017 12543 net.cpp:165] Memory required for data: 19869952
I1123 22:08:53.512027 12543 layer_factory.hpp:76] Creating layer conv1_2b
I1123 22:08:53.512038 12543 net.cpp:106] Creating Layer conv1_2b
I1123 22:08:53.512043 12543 net.cpp:454] conv1_2b <- conv1_1_conv1_1_0_split_1
I1123 22:08:53.512053 12543 net.cpp:411] conv1_2b -> conv1_2b
I1123 22:08:53.513821 12543 net.cpp:150] Setting up conv1_2b
I1123 22:08:53.513833 12543 net.cpp:157] Top shape: 64 16 28 28 (802816)
I1123 22:08:53.513838 12543 net.cpp:165] Memory required for data: 23081216
I1123 22:08:53.513845 12543 layer_factory.hpp:76] Creating layer conv1_2
I1123 22:08:53.513856 12543 net.cpp:106] Creating Layer conv1_2
I1123 22:08:53.513861 12543 net.cpp:454] conv1_2 <- conv1_2a
I1123 22:08:53.513866 12543 net.cpp:454] conv1_2 <- conv1_2b
I1123 22:08:53.513873 12543 net.cpp:411] conv1_2 -> conv1_2
I1123 22:08:53.513909 12543 net.cpp:150] Setting up conv1_2
I1123 22:08:53.513917 12543 net.cpp:157] Top shape: 64 16 28 28 (802816)
I1123 22:08:53.513921 12543 net.cpp:165] Memory required for data: 26292480
I1123 22:08:53.513924 12543 layer_factory.hpp:76] Creating layer pool1
I1123 22:08:53.513934 12543 net.cpp:106] Creating Layer pool1
I1123 22:08:53.513938 12543 net.cpp:454] pool1 <- conv1_2
I1123 22:08:53.513943 12543 net.cpp:411] pool1 -> pool1
I1123 22:08:53.514497 12543 net.cpp:150] Setting up pool1
I1123 22:08:53.514515 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.514519 12543 net.cpp:165] Memory required for data: 26984704
I1123 22:08:53.514523 12543 layer_factory.hpp:76] Creating layer pool1_pool1_0_split
I1123 22:08:53.514530 12543 net.cpp:106] Creating Layer pool1_pool1_0_split
I1123 22:08:53.514534 12543 net.cpp:454] pool1_pool1_0_split <- pool1
I1123 22:08:53.514539 12543 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1123 22:08:53.514549 12543 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1123 22:08:53.514582 12543 net.cpp:150] Setting up pool1_pool1_0_split
I1123 22:08:53.514590 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.514595 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.514598 12543 net.cpp:165] Memory required for data: 28369152
I1123 22:08:53.514602 12543 layer_factory.hpp:76] Creating layer conv2_1a
I1123 22:08:53.514611 12543 net.cpp:106] Creating Layer conv2_1a
I1123 22:08:53.514616 12543 net.cpp:454] conv2_1a <- pool1_pool1_0_split_0
I1123 22:08:53.514623 12543 net.cpp:411] conv2_1a -> conv2_1a
I1123 22:08:53.516355 12543 net.cpp:150] Setting up conv2_1a
I1123 22:08:53.516366 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.516369 12543 net.cpp:165] Memory required for data: 29061376
I1123 22:08:53.516382 12543 layer_factory.hpp:76] Creating layer conv2_1b
I1123 22:08:53.516392 12543 net.cpp:106] Creating Layer conv2_1b
I1123 22:08:53.516398 12543 net.cpp:454] conv2_1b <- pool1_pool1_0_split_1
I1123 22:08:53.516407 12543 net.cpp:411] conv2_1b -> conv2_1b
I1123 22:08:53.518193 12543 net.cpp:150] Setting up conv2_1b
I1123 22:08:53.518203 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.518208 12543 net.cpp:165] Memory required for data: 29753600
I1123 22:08:53.518216 12543 layer_factory.hpp:76] Creating layer conv2_1
I1123 22:08:53.518224 12543 net.cpp:106] Creating Layer conv2_1
I1123 22:08:53.518229 12543 net.cpp:454] conv2_1 <- conv2_1a
I1123 22:08:53.518234 12543 net.cpp:454] conv2_1 <- conv2_1b
I1123 22:08:53.518241 12543 net.cpp:411] conv2_1 -> conv2_1
I1123 22:08:53.518276 12543 net.cpp:150] Setting up conv2_1
I1123 22:08:53.518283 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.518287 12543 net.cpp:165] Memory required for data: 30445824
I1123 22:08:53.518291 12543 layer_factory.hpp:76] Creating layer conv2_1_conv2_1_0_split
I1123 22:08:53.518298 12543 net.cpp:106] Creating Layer conv2_1_conv2_1_0_split
I1123 22:08:53.518302 12543 net.cpp:454] conv2_1_conv2_1_0_split <- conv2_1
I1123 22:08:53.518308 12543 net.cpp:411] conv2_1_conv2_1_0_split -> conv2_1_conv2_1_0_split_0
I1123 22:08:53.518316 12543 net.cpp:411] conv2_1_conv2_1_0_split -> conv2_1_conv2_1_0_split_1
I1123 22:08:53.518348 12543 net.cpp:150] Setting up conv2_1_conv2_1_0_split
I1123 22:08:53.518354 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.518360 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.518363 12543 net.cpp:165] Memory required for data: 31830272
I1123 22:08:53.518368 12543 layer_factory.hpp:76] Creating layer conv2_2a
I1123 22:08:53.518376 12543 net.cpp:106] Creating Layer conv2_2a
I1123 22:08:53.518380 12543 net.cpp:454] conv2_2a <- conv2_1_conv2_1_0_split_0
I1123 22:08:53.518388 12543 net.cpp:411] conv2_2a -> conv2_2a
I1123 22:08:53.520169 12543 net.cpp:150] Setting up conv2_2a
I1123 22:08:53.520184 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.520189 12543 net.cpp:165] Memory required for data: 32522496
I1123 22:08:53.520197 12543 layer_factory.hpp:76] Creating layer conv2_2b
I1123 22:08:53.520211 12543 net.cpp:106] Creating Layer conv2_2b
I1123 22:08:53.520217 12543 net.cpp:454] conv2_2b <- conv2_1_conv2_1_0_split_1
I1123 22:08:53.520226 12543 net.cpp:411] conv2_2b -> conv2_2b
I1123 22:08:53.522012 12543 net.cpp:150] Setting up conv2_2b
I1123 22:08:53.522027 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.522029 12543 net.cpp:165] Memory required for data: 33214720
I1123 22:08:53.522056 12543 layer_factory.hpp:76] Creating layer conv2_2
I1123 22:08:53.522068 12543 net.cpp:106] Creating Layer conv2_2
I1123 22:08:53.522073 12543 net.cpp:454] conv2_2 <- conv2_2a
I1123 22:08:53.522078 12543 net.cpp:454] conv2_2 <- conv2_2b
I1123 22:08:53.522085 12543 net.cpp:411] conv2_2 -> conv2_2
I1123 22:08:53.522135 12543 net.cpp:150] Setting up conv2_2
I1123 22:08:53.522164 12543 net.cpp:157] Top shape: 64 16 13 13 (173056)
I1123 22:08:53.522169 12543 net.cpp:165] Memory required for data: 33906944
I1123 22:08:53.522173 12543 layer_factory.hpp:76] Creating layer pool2
I1123 22:08:53.522182 12543 net.cpp:106] Creating Layer pool2
I1123 22:08:53.522187 12543 net.cpp:454] pool2 <- conv2_2
I1123 22:08:53.522193 12543 net.cpp:411] pool2 -> pool2
I1123 22:08:53.522804 12543 net.cpp:150] Setting up pool2
I1123 22:08:53.522815 12543 net.cpp:157] Top shape: 64 16 6 6 (36864)
I1123 22:08:53.522820 12543 net.cpp:165] Memory required for data: 34054400
I1123 22:08:53.522825 12543 layer_factory.hpp:76] Creating layer pool2_pool2_0_split
I1123 22:08:53.522832 12543 net.cpp:106] Creating Layer pool2_pool2_0_split
I1123 22:08:53.522836 12543 net.cpp:454] pool2_pool2_0_split <- pool2
I1123 22:08:53.522842 12543 net.cpp:411] pool2_pool2_0_split -> pool2_pool2_0_split_0
I1123 22:08:53.522850 12543 net.cpp:411] pool2_pool2_0_split -> pool2_pool2_0_split_1
I1123 22:08:53.522886 12543 net.cpp:150] Setting up pool2_pool2_0_split
I1123 22:08:53.522892 12543 net.cpp:157] Top shape: 64 16 6 6 (36864)
I1123 22:08:53.522897 12543 net.cpp:157] Top shape: 64 16 6 6 (36864)
I1123 22:08:53.522902 12543 net.cpp:165] Memory required for data: 34349312
I1123 22:08:53.522905 12543 layer_factory.hpp:76] Creating layer conv3_1a
I1123 22:08:53.522915 12543 net.cpp:106] Creating Layer conv3_1a
I1123 22:08:53.522920 12543 net.cpp:454] conv3_1a <- pool2_pool2_0_split_0
I1123 22:08:53.522928 12543 net.cpp:411] conv3_1a -> conv3_1a
I1123 22:08:53.524775 12543 net.cpp:150] Setting up conv3_1a
I1123 22:08:53.524785 12543 net.cpp:157] Top shape: 64 12 6 6 (27648)
I1123 22:08:53.524791 12543 net.cpp:165] Memory required for data: 34459904
I1123 22:08:53.524803 12543 layer_factory.hpp:76] Creating layer conv3_1b
I1123 22:08:53.524814 12543 net.cpp:106] Creating Layer conv3_1b
I1123 22:08:53.524821 12543 net.cpp:454] conv3_1b <- pool2_pool2_0_split_1
I1123 22:08:53.524828 12543 net.cpp:411] conv3_1b -> conv3_1b
I1123 22:08:53.526770 12543 net.cpp:150] Setting up conv3_1b
I1123 22:08:53.526782 12543 net.cpp:157] Top shape: 64 12 6 6 (27648)
I1123 22:08:53.526787 12543 net.cpp:165] Memory required for data: 34570496
I1123 22:08:53.526794 12543 layer_factory.hpp:76] Creating layer conv3_1
I1123 22:08:53.526803 12543 net.cpp:106] Creating Layer conv3_1
I1123 22:08:53.526808 12543 net.cpp:454] conv3_1 <- conv3_1a
I1123 22:08:53.526813 12543 net.cpp:454] conv3_1 <- conv3_1b
I1123 22:08:53.526819 12543 net.cpp:411] conv3_1 -> conv3_1
I1123 22:08:53.526865 12543 net.cpp:150] Setting up conv3_1
I1123 22:08:53.526873 12543 net.cpp:157] Top shape: 64 12 6 6 (27648)
I1123 22:08:53.526876 12543 net.cpp:165] Memory required for data: 34681088
I1123 22:08:53.526880 12543 layer_factory.hpp:76] Creating layer conv3_1_conv3_1_0_split
I1123 22:08:53.526887 12543 net.cpp:106] Creating Layer conv3_1_conv3_1_0_split
I1123 22:08:53.526891 12543 net.cpp:454] conv3_1_conv3_1_0_split <- conv3_1
I1123 22:08:53.526897 12543 net.cpp:411] conv3_1_conv3_1_0_split -> conv3_1_conv3_1_0_split_0
I1123 22:08:53.526904 12543 net.cpp:411] conv3_1_conv3_1_0_split -> conv3_1_conv3_1_0_split_1
I1123 22:08:53.526939 12543 net.cpp:150] Setting up conv3_1_conv3_1_0_split
I1123 22:08:53.526947 12543 net.cpp:157] Top shape: 64 12 6 6 (27648)
I1123 22:08:53.526952 12543 net.cpp:157] Top shape: 64 12 6 6 (27648)
I1123 22:08:53.526955 12543 net.cpp:165] Memory required for data: 34902272
I1123 22:08:53.526959 12543 layer_factory.hpp:76] Creating layer conv3_2a
I1123 22:08:53.526968 12543 net.cpp:106] Creating Layer conv3_2a
I1123 22:08:53.526973 12543 net.cpp:454] conv3_2a <- conv3_1_conv3_1_0_split_0
I1123 22:08:53.526990 12543 net.cpp:411] conv3_2a -> conv3_2a
I1123 22:08:53.528755 12543 net.cpp:150] Setting up conv3_2a
I1123 22:08:53.528767 12543 net.cpp:157] Top shape: 64 12 6 6 (27648)
I1123 22:08:53.528771 12543 net.cpp:165] Memory required for data: 35012864
I1123 22:08:53.528779 12543 layer_factory.hpp:76] Creating layer conv3_2b
I1123 22:08:53.528790 12543 net.cpp:106] Creating Layer conv3_2b
I1123 22:08:53.528795 12543 net.cpp:454] conv3_2b <- conv3_1_conv3_1_0_split_1
I1123 22:08:53.528805 12543 net.cpp:411] conv3_2b -> conv3_2b
I1123 22:08:53.530632 12543 net.cpp:150] Setting up conv3_2b
I1123 22:08:53.530647 12543 net.cpp:157] Top shape: 64 12 6 6 (27648)
I1123 22:08:53.530650 12543 net.cpp:165] Memory required for data: 35123456
I1123 22:08:53.530658 12543 layer_factory.hpp:76] Creating layer conv3_2
I1123 22:08:53.530668 12543 net.cpp:106] Creating Layer conv3_2
I1123 22:08:53.530671 12543 net.cpp:454] conv3_2 <- conv3_2a
I1123 22:08:53.530678 12543 net.cpp:454] conv3_2 <- conv3_2b
I1123 22:08:53.530683 12543 net.cpp:411] conv3_2 -> conv3_2
I1123 22:08:53.530724 12543 net.cpp:150] Setting up conv3_2
I1123 22:08:53.530731 12543 net.cpp:157] Top shape: 64 12 6 6 (27648)
I1123 22:08:53.530735 12543 net.cpp:165] Memory required for data: 35234048
I1123 22:08:53.530738 12543 layer_factory.hpp:76] Creating layer pool3
I1123 22:08:53.530746 12543 net.cpp:106] Creating Layer pool3
I1123 22:08:53.530750 12543 net.cpp:454] pool3 <- conv3_2
I1123 22:08:53.530757 12543 net.cpp:411] pool3 -> pool3
I1123 22:08:53.531308 12543 net.cpp:150] Setting up pool3
I1123 22:08:53.531319 12543 net.cpp:157] Top shape: 64 12 3 3 (6912)
I1123 22:08:53.531323 12543 net.cpp:165] Memory required for data: 35261696
I1123 22:08:53.531327 12543 layer_factory.hpp:76] Creating layer final_drop
I1123 22:08:53.531335 12543 net.cpp:106] Creating Layer final_drop
I1123 22:08:53.531340 12543 net.cpp:454] final_drop <- pool3
I1123 22:08:53.531347 12543 net.cpp:411] final_drop -> final_drop
I1123 22:08:53.531390 12543 net.cpp:150] Setting up final_drop
I1123 22:08:53.531399 12543 net.cpp:157] Top shape: 64 12 3 3 (6912)
I1123 22:08:53.531402 12543 net.cpp:165] Memory required for data: 35289344
I1123 22:08:53.531406 12543 layer_factory.hpp:76] Creating layer clf
I1123 22:08:53.531421 12543 net.cpp:106] Creating Layer clf
I1123 22:08:53.531426 12543 net.cpp:454] clf <- final_drop
I1123 22:08:53.531435 12543 net.cpp:411] clf -> clf
I1123 22:08:53.531535 12543 net.cpp:150] Setting up clf
I1123 22:08:53.531543 12543 net.cpp:157] Top shape: 64 10 (640)
I1123 22:08:53.531546 12543 net.cpp:165] Memory required for data: 35291904
I1123 22:08:53.531554 12543 layer_factory.hpp:76] Creating layer loss
I1123 22:08:53.531561 12543 net.cpp:106] Creating Layer loss
I1123 22:08:53.531565 12543 net.cpp:454] loss <- clf
I1123 22:08:53.531570 12543 net.cpp:454] loss <- label
I1123 22:08:53.531579 12543 net.cpp:411] loss -> loss
I1123 22:08:53.531607 12543 net.cpp:150] Setting up loss
I1123 22:08:53.531613 12543 net.cpp:157] Top shape: (1)
I1123 22:08:53.531617 12543 net.cpp:160]     with loss weight 1
I1123 22:08:53.531632 12543 net.cpp:165] Memory required for data: 35291908
I1123 22:08:53.531637 12543 net.cpp:226] loss needs backward computation.
I1123 22:08:53.531642 12543 net.cpp:226] clf needs backward computation.
I1123 22:08:53.531646 12543 net.cpp:226] final_drop needs backward computation.
I1123 22:08:53.531651 12543 net.cpp:226] pool3 needs backward computation.
I1123 22:08:53.531653 12543 net.cpp:226] conv3_2 needs backward computation.
I1123 22:08:53.531658 12543 net.cpp:226] conv3_2b needs backward computation.
I1123 22:08:53.531663 12543 net.cpp:226] conv3_2a needs backward computation.
I1123 22:08:53.531667 12543 net.cpp:226] conv3_1_conv3_1_0_split needs backward computation.
I1123 22:08:53.531672 12543 net.cpp:226] conv3_1 needs backward computation.
I1123 22:08:53.531677 12543 net.cpp:226] conv3_1b needs backward computation.
I1123 22:08:53.531680 12543 net.cpp:226] conv3_1a needs backward computation.
I1123 22:08:53.531684 12543 net.cpp:226] pool2_pool2_0_split needs backward computation.
I1123 22:08:53.531699 12543 net.cpp:226] pool2 needs backward computation.
I1123 22:08:53.531704 12543 net.cpp:226] conv2_2 needs backward computation.
I1123 22:08:53.531709 12543 net.cpp:226] conv2_2b needs backward computation.
I1123 22:08:53.531713 12543 net.cpp:226] conv2_2a needs backward computation.
I1123 22:08:53.531718 12543 net.cpp:226] conv2_1_conv2_1_0_split needs backward computation.
I1123 22:08:53.531721 12543 net.cpp:226] conv2_1 needs backward computation.
I1123 22:08:53.531726 12543 net.cpp:226] conv2_1b needs backward computation.
I1123 22:08:53.531730 12543 net.cpp:226] conv2_1a needs backward computation.
I1123 22:08:53.531734 12543 net.cpp:226] pool1_pool1_0_split needs backward computation.
I1123 22:08:53.531738 12543 net.cpp:226] pool1 needs backward computation.
I1123 22:08:53.531743 12543 net.cpp:226] conv1_2 needs backward computation.
I1123 22:08:53.531747 12543 net.cpp:226] conv1_2b needs backward computation.
I1123 22:08:53.531751 12543 net.cpp:226] conv1_2a needs backward computation.
I1123 22:08:53.531755 12543 net.cpp:226] conv1_1_conv1_1_0_split needs backward computation.
I1123 22:08:53.531759 12543 net.cpp:226] conv1_1 needs backward computation.
I1123 22:08:53.531764 12543 net.cpp:226] conv1_1b needs backward computation.
I1123 22:08:53.531767 12543 net.cpp:226] conv1_1a needs backward computation.
I1123 22:08:53.531772 12543 net.cpp:228] data_mnist_0_split does not need backward computation.
I1123 22:08:53.531777 12543 net.cpp:228] mnist does not need backward computation.
I1123 22:08:53.531781 12543 net.cpp:270] This network produces output loss
I1123 22:08:53.531808 12543 net.cpp:283] Network initialization done.
I1123 22:08:53.531918 12543 solver.cpp:180] Creating test net (#0) specified by net_param
I1123 22:08:53.531958 12543 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1123 22:08:53.532117 12543 net.cpp:49] Initializing net from parameters: 
name: "FitNet_MNIST"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.004
  }
  data_param {
    source: "../mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1_1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1b"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1"
  type: "Eltwise"
  bottom: "conv1_1a"
  bottom: "conv1_1b"
  top: "conv1_1"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "conv1_2a"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2b"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2"
  type: "Eltwise"
  bottom: "conv1_2a"
  bottom: "conv1_2b"
  top: "conv1_2"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 2
  }
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1a"
  bottom: "conv2_1b"
  top: "conv2_1"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2a"
  bottom: "conv2_2b"
  top: "conv2_2"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 2
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1a"
  bottom: "conv3_1b"
  top: "conv3_1"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2a"
  bottom: "conv3_2b"
  top: "conv3_2"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "final_drop"
  type: "Dropout"
  bottom: "pool3"
  top: "final_drop"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "clf"
  type: "InnerProduct"
  bottom: "final_drop"
  top: "clf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "clf"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "HingeLoss"
  bottom: "clf"
  bottom: "label"
  top: "loss"
  hinge_loss_param {
    norm: L1
  }
}
I1123 22:08:53.532308 12543 layer_factory.hpp:76] Creating layer mnist
I1123 22:08:53.532418 12543 net.cpp:106] Creating Layer mnist
I1123 22:08:53.532426 12543 net.cpp:411] mnist -> data
I1123 22:08:53.532434 12543 net.cpp:411] mnist -> label
I1123 22:08:53.533061 12549 db_lmdb.cpp:38] Opened lmdb ../mnist/mnist_test_lmdb
I1123 22:08:53.533180 12543 data_layer.cpp:41] output data size: 100,1,28,28
I1123 22:08:53.533970 12543 net.cpp:150] Setting up mnist
I1123 22:08:53.533984 12543 net.cpp:157] Top shape: 100 1 28 28 (78400)
I1123 22:08:53.533990 12543 net.cpp:157] Top shape: 100 (100)
I1123 22:08:53.533993 12543 net.cpp:165] Memory required for data: 314000
I1123 22:08:53.533998 12543 layer_factory.hpp:76] Creating layer data_mnist_0_split
I1123 22:08:53.534008 12543 net.cpp:106] Creating Layer data_mnist_0_split
I1123 22:08:53.534011 12543 net.cpp:454] data_mnist_0_split <- data
I1123 22:08:53.534018 12543 net.cpp:411] data_mnist_0_split -> data_mnist_0_split_0
I1123 22:08:53.534028 12543 net.cpp:411] data_mnist_0_split -> data_mnist_0_split_1
I1123 22:08:53.534077 12543 net.cpp:150] Setting up data_mnist_0_split
I1123 22:08:53.534086 12543 net.cpp:157] Top shape: 100 1 28 28 (78400)
I1123 22:08:53.534091 12543 net.cpp:157] Top shape: 100 1 28 28 (78400)
I1123 22:08:53.534096 12543 net.cpp:165] Memory required for data: 941200
I1123 22:08:53.534099 12543 layer_factory.hpp:76] Creating layer label_mnist_1_split
I1123 22:08:53.534106 12543 net.cpp:106] Creating Layer label_mnist_1_split
I1123 22:08:53.534109 12543 net.cpp:454] label_mnist_1_split <- label
I1123 22:08:53.534116 12543 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I1123 22:08:53.534122 12543 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I1123 22:08:53.534159 12543 net.cpp:150] Setting up label_mnist_1_split
I1123 22:08:53.534165 12543 net.cpp:157] Top shape: 100 (100)
I1123 22:08:53.534170 12543 net.cpp:157] Top shape: 100 (100)
I1123 22:08:53.534174 12543 net.cpp:165] Memory required for data: 942000
I1123 22:08:53.534178 12543 layer_factory.hpp:76] Creating layer conv1_1a
I1123 22:08:53.534188 12543 net.cpp:106] Creating Layer conv1_1a
I1123 22:08:53.534193 12543 net.cpp:454] conv1_1a <- data_mnist_0_split_0
I1123 22:08:53.534204 12543 net.cpp:411] conv1_1a -> conv1_1a
I1123 22:08:53.536285 12543 net.cpp:150] Setting up conv1_1a
I1123 22:08:53.536303 12543 net.cpp:157] Top shape: 100 16 28 28 (1254400)
I1123 22:08:53.536306 12543 net.cpp:165] Memory required for data: 5959600
I1123 22:08:53.536319 12543 layer_factory.hpp:76] Creating layer conv1_1b
I1123 22:08:53.536334 12543 net.cpp:106] Creating Layer conv1_1b
I1123 22:08:53.536339 12543 net.cpp:454] conv1_1b <- data_mnist_0_split_1
I1123 22:08:53.536347 12543 net.cpp:411] conv1_1b -> conv1_1b
I1123 22:08:53.538280 12543 net.cpp:150] Setting up conv1_1b
I1123 22:08:53.538296 12543 net.cpp:157] Top shape: 100 16 28 28 (1254400)
I1123 22:08:53.538302 12543 net.cpp:165] Memory required for data: 10977200
I1123 22:08:53.538313 12543 layer_factory.hpp:76] Creating layer conv1_1
I1123 22:08:53.538322 12543 net.cpp:106] Creating Layer conv1_1
I1123 22:08:53.538327 12543 net.cpp:454] conv1_1 <- conv1_1a
I1123 22:08:53.538333 12543 net.cpp:454] conv1_1 <- conv1_1b
I1123 22:08:53.538339 12543 net.cpp:411] conv1_1 -> conv1_1
I1123 22:08:53.538382 12543 net.cpp:150] Setting up conv1_1
I1123 22:08:53.538389 12543 net.cpp:157] Top shape: 100 16 28 28 (1254400)
I1123 22:08:53.538393 12543 net.cpp:165] Memory required for data: 15994800
I1123 22:08:53.538398 12543 layer_factory.hpp:76] Creating layer conv1_1_conv1_1_0_split
I1123 22:08:53.538404 12543 net.cpp:106] Creating Layer conv1_1_conv1_1_0_split
I1123 22:08:53.538408 12543 net.cpp:454] conv1_1_conv1_1_0_split <- conv1_1
I1123 22:08:53.538415 12543 net.cpp:411] conv1_1_conv1_1_0_split -> conv1_1_conv1_1_0_split_0
I1123 22:08:53.538435 12543 net.cpp:411] conv1_1_conv1_1_0_split -> conv1_1_conv1_1_0_split_1
I1123 22:08:53.538475 12543 net.cpp:150] Setting up conv1_1_conv1_1_0_split
I1123 22:08:53.538483 12543 net.cpp:157] Top shape: 100 16 28 28 (1254400)
I1123 22:08:53.538488 12543 net.cpp:157] Top shape: 100 16 28 28 (1254400)
I1123 22:08:53.538492 12543 net.cpp:165] Memory required for data: 26030000
I1123 22:08:53.538496 12543 layer_factory.hpp:76] Creating layer conv1_2a
I1123 22:08:53.538507 12543 net.cpp:106] Creating Layer conv1_2a
I1123 22:08:53.538513 12543 net.cpp:454] conv1_2a <- conv1_1_conv1_1_0_split_0
I1123 22:08:53.538519 12543 net.cpp:411] conv1_2a -> conv1_2a
I1123 22:08:53.540531 12543 net.cpp:150] Setting up conv1_2a
I1123 22:08:53.540546 12543 net.cpp:157] Top shape: 100 16 28 28 (1254400)
I1123 22:08:53.540550 12543 net.cpp:165] Memory required for data: 31047600
I1123 22:08:53.540562 12543 layer_factory.hpp:76] Creating layer conv1_2b
I1123 22:08:53.540576 12543 net.cpp:106] Creating Layer conv1_2b
I1123 22:08:53.540583 12543 net.cpp:454] conv1_2b <- conv1_1_conv1_1_0_split_1
I1123 22:08:53.540593 12543 net.cpp:411] conv1_2b -> conv1_2b
I1123 22:08:53.542439 12543 net.cpp:150] Setting up conv1_2b
I1123 22:08:53.542451 12543 net.cpp:157] Top shape: 100 16 28 28 (1254400)
I1123 22:08:53.542455 12543 net.cpp:165] Memory required for data: 36065200
I1123 22:08:53.542464 12543 layer_factory.hpp:76] Creating layer conv1_2
I1123 22:08:53.542472 12543 net.cpp:106] Creating Layer conv1_2
I1123 22:08:53.542477 12543 net.cpp:454] conv1_2 <- conv1_2a
I1123 22:08:53.542484 12543 net.cpp:454] conv1_2 <- conv1_2b
I1123 22:08:53.542490 12543 net.cpp:411] conv1_2 -> conv1_2
I1123 22:08:53.542531 12543 net.cpp:150] Setting up conv1_2
I1123 22:08:53.542538 12543 net.cpp:157] Top shape: 100 16 28 28 (1254400)
I1123 22:08:53.542542 12543 net.cpp:165] Memory required for data: 41082800
I1123 22:08:53.542546 12543 layer_factory.hpp:76] Creating layer pool1
I1123 22:08:53.542556 12543 net.cpp:106] Creating Layer pool1
I1123 22:08:53.542559 12543 net.cpp:454] pool1 <- conv1_2
I1123 22:08:53.542565 12543 net.cpp:411] pool1 -> pool1
I1123 22:08:53.543143 12543 net.cpp:150] Setting up pool1
I1123 22:08:53.543154 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.543157 12543 net.cpp:165] Memory required for data: 42164400
I1123 22:08:53.543161 12543 layer_factory.hpp:76] Creating layer pool1_pool1_0_split
I1123 22:08:53.543169 12543 net.cpp:106] Creating Layer pool1_pool1_0_split
I1123 22:08:53.543172 12543 net.cpp:454] pool1_pool1_0_split <- pool1
I1123 22:08:53.543179 12543 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_0
I1123 22:08:53.543185 12543 net.cpp:411] pool1_pool1_0_split -> pool1_pool1_0_split_1
I1123 22:08:53.543226 12543 net.cpp:150] Setting up pool1_pool1_0_split
I1123 22:08:53.543232 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.543238 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.543241 12543 net.cpp:165] Memory required for data: 44327600
I1123 22:08:53.543246 12543 layer_factory.hpp:76] Creating layer conv2_1a
I1123 22:08:53.543256 12543 net.cpp:106] Creating Layer conv2_1a
I1123 22:08:53.543261 12543 net.cpp:454] conv2_1a <- pool1_pool1_0_split_0
I1123 22:08:53.543267 12543 net.cpp:411] conv2_1a -> conv2_1a
I1123 22:08:53.545166 12543 net.cpp:150] Setting up conv2_1a
I1123 22:08:53.545177 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.545181 12543 net.cpp:165] Memory required for data: 45409200
I1123 22:08:53.545192 12543 layer_factory.hpp:76] Creating layer conv2_1b
I1123 22:08:53.545202 12543 net.cpp:106] Creating Layer conv2_1b
I1123 22:08:53.545208 12543 net.cpp:454] conv2_1b <- pool1_pool1_0_split_1
I1123 22:08:53.545217 12543 net.cpp:411] conv2_1b -> conv2_1b
I1123 22:08:53.547118 12543 net.cpp:150] Setting up conv2_1b
I1123 22:08:53.547129 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.547134 12543 net.cpp:165] Memory required for data: 46490800
I1123 22:08:53.547154 12543 layer_factory.hpp:76] Creating layer conv2_1
I1123 22:08:53.547164 12543 net.cpp:106] Creating Layer conv2_1
I1123 22:08:53.547171 12543 net.cpp:454] conv2_1 <- conv2_1a
I1123 22:08:53.547176 12543 net.cpp:454] conv2_1 <- conv2_1b
I1123 22:08:53.547183 12543 net.cpp:411] conv2_1 -> conv2_1
I1123 22:08:53.547232 12543 net.cpp:150] Setting up conv2_1
I1123 22:08:53.547240 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.547245 12543 net.cpp:165] Memory required for data: 47572400
I1123 22:08:53.547248 12543 layer_factory.hpp:76] Creating layer conv2_1_conv2_1_0_split
I1123 22:08:53.547255 12543 net.cpp:106] Creating Layer conv2_1_conv2_1_0_split
I1123 22:08:53.547258 12543 net.cpp:454] conv2_1_conv2_1_0_split <- conv2_1
I1123 22:08:53.547266 12543 net.cpp:411] conv2_1_conv2_1_0_split -> conv2_1_conv2_1_0_split_0
I1123 22:08:53.547273 12543 net.cpp:411] conv2_1_conv2_1_0_split -> conv2_1_conv2_1_0_split_1
I1123 22:08:53.547309 12543 net.cpp:150] Setting up conv2_1_conv2_1_0_split
I1123 22:08:53.547318 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.547324 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.547327 12543 net.cpp:165] Memory required for data: 49735600
I1123 22:08:53.547332 12543 layer_factory.hpp:76] Creating layer conv2_2a
I1123 22:08:53.547343 12543 net.cpp:106] Creating Layer conv2_2a
I1123 22:08:53.547346 12543 net.cpp:454] conv2_2a <- conv2_1_conv2_1_0_split_0
I1123 22:08:53.547355 12543 net.cpp:411] conv2_2a -> conv2_2a
I1123 22:08:53.549311 12543 net.cpp:150] Setting up conv2_2a
I1123 22:08:53.549324 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.549329 12543 net.cpp:165] Memory required for data: 50817200
I1123 22:08:53.549336 12543 layer_factory.hpp:76] Creating layer conv2_2b
I1123 22:08:53.549347 12543 net.cpp:106] Creating Layer conv2_2b
I1123 22:08:53.549352 12543 net.cpp:454] conv2_2b <- conv2_1_conv2_1_0_split_1
I1123 22:08:53.549361 12543 net.cpp:411] conv2_2b -> conv2_2b
I1123 22:08:53.551372 12543 net.cpp:150] Setting up conv2_2b
I1123 22:08:53.551383 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.551388 12543 net.cpp:165] Memory required for data: 51898800
I1123 22:08:53.551395 12543 layer_factory.hpp:76] Creating layer conv2_2
I1123 22:08:53.551404 12543 net.cpp:106] Creating Layer conv2_2
I1123 22:08:53.551409 12543 net.cpp:454] conv2_2 <- conv2_2a
I1123 22:08:53.551415 12543 net.cpp:454] conv2_2 <- conv2_2b
I1123 22:08:53.551421 12543 net.cpp:411] conv2_2 -> conv2_2
I1123 22:08:53.551466 12543 net.cpp:150] Setting up conv2_2
I1123 22:08:53.551475 12543 net.cpp:157] Top shape: 100 16 13 13 (270400)
I1123 22:08:53.551477 12543 net.cpp:165] Memory required for data: 52980400
I1123 22:08:53.551481 12543 layer_factory.hpp:76] Creating layer pool2
I1123 22:08:53.551489 12543 net.cpp:106] Creating Layer pool2
I1123 22:08:53.551493 12543 net.cpp:454] pool2 <- conv2_2
I1123 22:08:53.551501 12543 net.cpp:411] pool2 -> pool2
I1123 22:08:53.552086 12543 net.cpp:150] Setting up pool2
I1123 22:08:53.552098 12543 net.cpp:157] Top shape: 100 16 6 6 (57600)
I1123 22:08:53.552101 12543 net.cpp:165] Memory required for data: 53210800
I1123 22:08:53.552105 12543 layer_factory.hpp:76] Creating layer pool2_pool2_0_split
I1123 22:08:53.552112 12543 net.cpp:106] Creating Layer pool2_pool2_0_split
I1123 22:08:53.552116 12543 net.cpp:454] pool2_pool2_0_split <- pool2
I1123 22:08:53.552124 12543 net.cpp:411] pool2_pool2_0_split -> pool2_pool2_0_split_0
I1123 22:08:53.552131 12543 net.cpp:411] pool2_pool2_0_split -> pool2_pool2_0_split_1
I1123 22:08:53.552172 12543 net.cpp:150] Setting up pool2_pool2_0_split
I1123 22:08:53.552180 12543 net.cpp:157] Top shape: 100 16 6 6 (57600)
I1123 22:08:53.552186 12543 net.cpp:157] Top shape: 100 16 6 6 (57600)
I1123 22:08:53.552188 12543 net.cpp:165] Memory required for data: 53671600
I1123 22:08:53.552192 12543 layer_factory.hpp:76] Creating layer conv3_1a
I1123 22:08:53.552202 12543 net.cpp:106] Creating Layer conv3_1a
I1123 22:08:53.552206 12543 net.cpp:454] conv3_1a <- pool2_pool2_0_split_0
I1123 22:08:53.552227 12543 net.cpp:411] conv3_1a -> conv3_1a
I1123 22:08:53.554169 12543 net.cpp:150] Setting up conv3_1a
I1123 22:08:53.554180 12543 net.cpp:157] Top shape: 100 12 6 6 (43200)
I1123 22:08:53.554185 12543 net.cpp:165] Memory required for data: 53844400
I1123 22:08:53.554196 12543 layer_factory.hpp:76] Creating layer conv3_1b
I1123 22:08:53.554208 12543 net.cpp:106] Creating Layer conv3_1b
I1123 22:08:53.554215 12543 net.cpp:454] conv3_1b <- pool2_pool2_0_split_1
I1123 22:08:53.554224 12543 net.cpp:411] conv3_1b -> conv3_1b
I1123 22:08:53.556115 12543 net.cpp:150] Setting up conv3_1b
I1123 22:08:53.556129 12543 net.cpp:157] Top shape: 100 12 6 6 (43200)
I1123 22:08:53.556133 12543 net.cpp:165] Memory required for data: 54017200
I1123 22:08:53.556141 12543 layer_factory.hpp:76] Creating layer conv3_1
I1123 22:08:53.556150 12543 net.cpp:106] Creating Layer conv3_1
I1123 22:08:53.556155 12543 net.cpp:454] conv3_1 <- conv3_1a
I1123 22:08:53.556161 12543 net.cpp:454] conv3_1 <- conv3_1b
I1123 22:08:53.556167 12543 net.cpp:411] conv3_1 -> conv3_1
I1123 22:08:53.556213 12543 net.cpp:150] Setting up conv3_1
I1123 22:08:53.556221 12543 net.cpp:157] Top shape: 100 12 6 6 (43200)
I1123 22:08:53.556224 12543 net.cpp:165] Memory required for data: 54190000
I1123 22:08:53.556228 12543 layer_factory.hpp:76] Creating layer conv3_1_conv3_1_0_split
I1123 22:08:53.556236 12543 net.cpp:106] Creating Layer conv3_1_conv3_1_0_split
I1123 22:08:53.556242 12543 net.cpp:454] conv3_1_conv3_1_0_split <- conv3_1
I1123 22:08:53.556248 12543 net.cpp:411] conv3_1_conv3_1_0_split -> conv3_1_conv3_1_0_split_0
I1123 22:08:53.556255 12543 net.cpp:411] conv3_1_conv3_1_0_split -> conv3_1_conv3_1_0_split_1
I1123 22:08:53.556298 12543 net.cpp:150] Setting up conv3_1_conv3_1_0_split
I1123 22:08:53.556304 12543 net.cpp:157] Top shape: 100 12 6 6 (43200)
I1123 22:08:53.556310 12543 net.cpp:157] Top shape: 100 12 6 6 (43200)
I1123 22:08:53.556314 12543 net.cpp:165] Memory required for data: 54535600
I1123 22:08:53.556318 12543 layer_factory.hpp:76] Creating layer conv3_2a
I1123 22:08:53.556329 12543 net.cpp:106] Creating Layer conv3_2a
I1123 22:08:53.556334 12543 net.cpp:454] conv3_2a <- conv3_1_conv3_1_0_split_0
I1123 22:08:53.556341 12543 net.cpp:411] conv3_2a -> conv3_2a
I1123 22:08:53.558357 12543 net.cpp:150] Setting up conv3_2a
I1123 22:08:53.558375 12543 net.cpp:157] Top shape: 100 12 6 6 (43200)
I1123 22:08:53.558380 12543 net.cpp:165] Memory required for data: 54708400
I1123 22:08:53.558388 12543 layer_factory.hpp:76] Creating layer conv3_2b
I1123 22:08:53.558399 12543 net.cpp:106] Creating Layer conv3_2b
I1123 22:08:53.558404 12543 net.cpp:454] conv3_2b <- conv3_1_conv3_1_0_split_1
I1123 22:08:53.558413 12543 net.cpp:411] conv3_2b -> conv3_2b
I1123 22:08:53.560291 12543 net.cpp:150] Setting up conv3_2b
I1123 22:08:53.560302 12543 net.cpp:157] Top shape: 100 12 6 6 (43200)
I1123 22:08:53.560305 12543 net.cpp:165] Memory required for data: 54881200
I1123 22:08:53.560313 12543 layer_factory.hpp:76] Creating layer conv3_2
I1123 22:08:53.560322 12543 net.cpp:106] Creating Layer conv3_2
I1123 22:08:53.560327 12543 net.cpp:454] conv3_2 <- conv3_2a
I1123 22:08:53.560333 12543 net.cpp:454] conv3_2 <- conv3_2b
I1123 22:08:53.560339 12543 net.cpp:411] conv3_2 -> conv3_2
I1123 22:08:53.560384 12543 net.cpp:150] Setting up conv3_2
I1123 22:08:53.560392 12543 net.cpp:157] Top shape: 100 12 6 6 (43200)
I1123 22:08:53.560396 12543 net.cpp:165] Memory required for data: 55054000
I1123 22:08:53.560400 12543 layer_factory.hpp:76] Creating layer pool3
I1123 22:08:53.560410 12543 net.cpp:106] Creating Layer pool3
I1123 22:08:53.560413 12543 net.cpp:454] pool3 <- conv3_2
I1123 22:08:53.560420 12543 net.cpp:411] pool3 -> pool3
I1123 22:08:53.561101 12543 net.cpp:150] Setting up pool3
I1123 22:08:53.561112 12543 net.cpp:157] Top shape: 100 12 3 3 (10800)
I1123 22:08:53.561116 12543 net.cpp:165] Memory required for data: 55097200
I1123 22:08:53.561120 12543 layer_factory.hpp:76] Creating layer final_drop
I1123 22:08:53.561127 12543 net.cpp:106] Creating Layer final_drop
I1123 22:08:53.561149 12543 net.cpp:454] final_drop <- pool3
I1123 22:08:53.561156 12543 net.cpp:411] final_drop -> final_drop
I1123 22:08:53.561202 12543 net.cpp:150] Setting up final_drop
I1123 22:08:53.561209 12543 net.cpp:157] Top shape: 100 12 3 3 (10800)
I1123 22:08:53.561213 12543 net.cpp:165] Memory required for data: 55140400
I1123 22:08:53.561218 12543 layer_factory.hpp:76] Creating layer clf
I1123 22:08:53.561229 12543 net.cpp:106] Creating Layer clf
I1123 22:08:53.561233 12543 net.cpp:454] clf <- final_drop
I1123 22:08:53.561241 12543 net.cpp:411] clf -> clf
I1123 22:08:53.561359 12543 net.cpp:150] Setting up clf
I1123 22:08:53.561367 12543 net.cpp:157] Top shape: 100 10 (1000)
I1123 22:08:53.561370 12543 net.cpp:165] Memory required for data: 55144400
I1123 22:08:53.561378 12543 layer_factory.hpp:76] Creating layer clf_clf_0_split
I1123 22:08:53.561384 12543 net.cpp:106] Creating Layer clf_clf_0_split
I1123 22:08:53.561388 12543 net.cpp:454] clf_clf_0_split <- clf
I1123 22:08:53.561393 12543 net.cpp:411] clf_clf_0_split -> clf_clf_0_split_0
I1123 22:08:53.561400 12543 net.cpp:411] clf_clf_0_split -> clf_clf_0_split_1
I1123 22:08:53.561442 12543 net.cpp:150] Setting up clf_clf_0_split
I1123 22:08:53.561450 12543 net.cpp:157] Top shape: 100 10 (1000)
I1123 22:08:53.561455 12543 net.cpp:157] Top shape: 100 10 (1000)
I1123 22:08:53.561458 12543 net.cpp:165] Memory required for data: 55152400
I1123 22:08:53.561461 12543 layer_factory.hpp:76] Creating layer accuracy
I1123 22:08:53.561471 12543 net.cpp:106] Creating Layer accuracy
I1123 22:08:53.561476 12543 net.cpp:454] accuracy <- clf_clf_0_split_0
I1123 22:08:53.561481 12543 net.cpp:454] accuracy <- label_mnist_1_split_0
I1123 22:08:53.561487 12543 net.cpp:411] accuracy -> accuracy
I1123 22:08:53.561503 12543 net.cpp:150] Setting up accuracy
I1123 22:08:53.561509 12543 net.cpp:157] Top shape: (1)
I1123 22:08:53.561513 12543 net.cpp:165] Memory required for data: 55152404
I1123 22:08:53.561517 12543 layer_factory.hpp:76] Creating layer loss
I1123 22:08:53.561524 12543 net.cpp:106] Creating Layer loss
I1123 22:08:53.561528 12543 net.cpp:454] loss <- clf_clf_0_split_1
I1123 22:08:53.561533 12543 net.cpp:454] loss <- label_mnist_1_split_1
I1123 22:08:53.561538 12543 net.cpp:411] loss -> loss
I1123 22:08:53.561568 12543 net.cpp:150] Setting up loss
I1123 22:08:53.561574 12543 net.cpp:157] Top shape: (1)
I1123 22:08:53.561578 12543 net.cpp:160]     with loss weight 1
I1123 22:08:53.561589 12543 net.cpp:165] Memory required for data: 55152408
I1123 22:08:53.561592 12543 net.cpp:226] loss needs backward computation.
I1123 22:08:53.561597 12543 net.cpp:228] accuracy does not need backward computation.
I1123 22:08:53.561601 12543 net.cpp:226] clf_clf_0_split needs backward computation.
I1123 22:08:53.561605 12543 net.cpp:226] clf needs backward computation.
I1123 22:08:53.561609 12543 net.cpp:226] final_drop needs backward computation.
I1123 22:08:53.561614 12543 net.cpp:226] pool3 needs backward computation.
I1123 22:08:53.561617 12543 net.cpp:226] conv3_2 needs backward computation.
I1123 22:08:53.561621 12543 net.cpp:226] conv3_2b needs backward computation.
I1123 22:08:53.561625 12543 net.cpp:226] conv3_2a needs backward computation.
I1123 22:08:53.561630 12543 net.cpp:226] conv3_1_conv3_1_0_split needs backward computation.
I1123 22:08:53.561633 12543 net.cpp:226] conv3_1 needs backward computation.
I1123 22:08:53.561638 12543 net.cpp:226] conv3_1b needs backward computation.
I1123 22:08:53.561642 12543 net.cpp:226] conv3_1a needs backward computation.
I1123 22:08:53.561646 12543 net.cpp:226] pool2_pool2_0_split needs backward computation.
I1123 22:08:53.561650 12543 net.cpp:226] pool2 needs backward computation.
I1123 22:08:53.561655 12543 net.cpp:226] conv2_2 needs backward computation.
I1123 22:08:53.561660 12543 net.cpp:226] conv2_2b needs backward computation.
I1123 22:08:53.561663 12543 net.cpp:226] conv2_2a needs backward computation.
I1123 22:08:53.561667 12543 net.cpp:226] conv2_1_conv2_1_0_split needs backward computation.
I1123 22:08:53.561682 12543 net.cpp:226] conv2_1 needs backward computation.
I1123 22:08:53.561688 12543 net.cpp:226] conv2_1b needs backward computation.
I1123 22:08:53.561692 12543 net.cpp:226] conv2_1a needs backward computation.
I1123 22:08:53.561697 12543 net.cpp:226] pool1_pool1_0_split needs backward computation.
I1123 22:08:53.561700 12543 net.cpp:226] pool1 needs backward computation.
I1123 22:08:53.561704 12543 net.cpp:226] conv1_2 needs backward computation.
I1123 22:08:53.561709 12543 net.cpp:226] conv1_2b needs backward computation.
I1123 22:08:53.561713 12543 net.cpp:226] conv1_2a needs backward computation.
I1123 22:08:53.561717 12543 net.cpp:226] conv1_1_conv1_1_0_split needs backward computation.
I1123 22:08:53.561722 12543 net.cpp:226] conv1_1 needs backward computation.
I1123 22:08:53.561727 12543 net.cpp:226] conv1_1b needs backward computation.
I1123 22:08:53.561730 12543 net.cpp:226] conv1_1a needs backward computation.
I1123 22:08:53.561735 12543 net.cpp:228] label_mnist_1_split does not need backward computation.
I1123 22:08:53.561739 12543 net.cpp:228] data_mnist_0_split does not need backward computation.
I1123 22:08:53.561744 12543 net.cpp:228] mnist does not need backward computation.
I1123 22:08:53.561748 12543 net.cpp:270] This network produces output accuracy
I1123 22:08:53.561753 12543 net.cpp:270] This network produces output loss
I1123 22:08:53.561780 12543 net.cpp:283] Network initialization done.
I1123 22:08:53.561877 12543 solver.cpp:59] Solver scaffolding done.
I1123 22:08:53.562743 12543 caffe.cpp:128] Finetuning from fitnet_mnist_lsuv_rms_SVM.prototxt.caffemodel
I1123 22:08:53.563199 12543 caffe.cpp:212] Starting Optimization
I1123 22:08:53.563205 12543 solver.cpp:287] Solving FitNet_MNIST
I1123 22:08:53.563210 12543 solver.cpp:288] Learning Rate Policy: step
I1123 22:08:53.576011 12543 solver.cpp:236] Iteration 0, loss = 10.8294
I1123 22:08:53.576041 12543 solver.cpp:252]     Train net output #0: loss = 10.8294 (* 1 = 10.8294 loss)
I1123 22:08:53.576052 12543 sgd_solver.cpp:106] Iteration 0, lr = 0.002
I1123 22:08:54.256758 12543 solver.cpp:236] Iteration 100, loss = 1.9978
I1123 22:08:54.256788 12543 solver.cpp:252]     Train net output #0: loss = 1.54804 (* 1 = 1.54804 loss)
I1123 22:08:54.256794 12543 sgd_solver.cpp:106] Iteration 100, lr = 0.002
I1123 22:08:54.918180 12543 solver.cpp:236] Iteration 200, loss = 0.917501
I1123 22:08:54.918206 12543 solver.cpp:252]     Train net output #0: loss = 0.637018 (* 1 = 0.637018 loss)
I1123 22:08:54.918210 12543 sgd_solver.cpp:106] Iteration 200, lr = 0.002
I1123 22:08:55.576186 12543 solver.cpp:236] Iteration 300, loss = 0.477552
I1123 22:08:55.576213 12543 solver.cpp:252]     Train net output #0: loss = 0.434468 (* 1 = 0.434468 loss)
I1123 22:08:55.576217 12543 sgd_solver.cpp:106] Iteration 300, lr = 0.002
I1123 22:08:56.234590 12543 solver.cpp:236] Iteration 400, loss = 0.325615
I1123 22:08:56.234617 12543 solver.cpp:252]     Train net output #0: loss = 0.222101 (* 1 = 0.222101 loss)
I1123 22:08:56.234623 12543 sgd_solver.cpp:106] Iteration 400, lr = 0.002
I1123 22:08:56.886910 12543 solver.cpp:340] Iteration 500, Testing net (#0)
I1123 22:08:57.076058 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9771
I1123 22:08:57.076083 12543 solver.cpp:408]     Test net output #1: loss = 0.142472 (* 1 = 0.142472 loss)
I1123 22:08:57.077993 12543 solver.cpp:236] Iteration 500, loss = 0.334204
I1123 22:08:57.078007 12543 solver.cpp:252]     Train net output #0: loss = 0.172154 (* 1 = 0.172154 loss)
I1123 22:08:57.078012 12543 sgd_solver.cpp:106] Iteration 500, lr = 0.002
I1123 22:08:57.736480 12543 solver.cpp:236] Iteration 600, loss = 0.250092
I1123 22:08:57.736506 12543 solver.cpp:252]     Train net output #0: loss = 0.21891 (* 1 = 0.21891 loss)
I1123 22:08:57.736510 12543 sgd_solver.cpp:106] Iteration 600, lr = 0.002
I1123 22:08:58.395376 12543 solver.cpp:236] Iteration 700, loss = 0.209779
I1123 22:08:58.395403 12543 solver.cpp:252]     Train net output #0: loss = 0.253333 (* 1 = 0.253333 loss)
I1123 22:08:58.395408 12543 sgd_solver.cpp:106] Iteration 700, lr = 0.002
I1123 22:08:59.056224 12543 solver.cpp:236] Iteration 800, loss = 0.243558
I1123 22:08:59.056252 12543 solver.cpp:252]     Train net output #0: loss = 0.359954 (* 1 = 0.359954 loss)
I1123 22:08:59.056257 12543 sgd_solver.cpp:106] Iteration 800, lr = 0.002
I1123 22:08:59.714231 12543 solver.cpp:236] Iteration 900, loss = 0.207565
I1123 22:08:59.714257 12543 solver.cpp:252]     Train net output #0: loss = 0.194375 (* 1 = 0.194375 loss)
I1123 22:08:59.714262 12543 sgd_solver.cpp:106] Iteration 900, lr = 0.002
I1123 22:09:00.373669 12543 solver.cpp:340] Iteration 1000, Testing net (#0)
I1123 22:09:00.423162 12543 blocking_queue.cpp:50] Data layer prefetch queue empty
I1123 22:09:00.579592 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9792
I1123 22:09:00.579622 12543 solver.cpp:408]     Test net output #1: loss = 0.150768 (* 1 = 0.150768 loss)
I1123 22:09:00.581918 12543 solver.cpp:236] Iteration 1000, loss = 0.182297
I1123 22:09:00.581945 12543 solver.cpp:252]     Train net output #0: loss = 0.273148 (* 1 = 0.273148 loss)
I1123 22:09:00.581954 12543 sgd_solver.cpp:106] Iteration 1000, lr = 0.002
I1123 22:09:01.279069 12543 solver.cpp:236] Iteration 1100, loss = 0.244944
I1123 22:09:01.279099 12543 solver.cpp:252]     Train net output #0: loss = 0.0902964 (* 1 = 0.0902964 loss)
I1123 22:09:01.279106 12543 sgd_solver.cpp:106] Iteration 1100, lr = 0.002
I1123 22:09:01.952839 12543 solver.cpp:236] Iteration 1200, loss = 0.178892
I1123 22:09:01.952868 12543 solver.cpp:252]     Train net output #0: loss = 0.10081 (* 1 = 0.10081 loss)
I1123 22:09:01.952874 12543 sgd_solver.cpp:106] Iteration 1200, lr = 0.002
I1123 22:09:02.626168 12543 solver.cpp:236] Iteration 1300, loss = 0.14454
I1123 22:09:02.626194 12543 solver.cpp:252]     Train net output #0: loss = 0.0344929 (* 1 = 0.0344929 loss)
I1123 22:09:02.626199 12543 sgd_solver.cpp:106] Iteration 1300, lr = 0.002
I1123 22:09:03.301527 12543 solver.cpp:236] Iteration 1400, loss = 0.149756
I1123 22:09:03.301553 12543 solver.cpp:252]     Train net output #0: loss = 0.0691978 (* 1 = 0.0691978 loss)
I1123 22:09:03.301558 12543 sgd_solver.cpp:106] Iteration 1400, lr = 0.002
I1123 22:09:03.956130 12543 solver.cpp:340] Iteration 1500, Testing net (#0)
I1123 22:09:04.144650 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9871
I1123 22:09:04.144676 12543 solver.cpp:408]     Test net output #1: loss = 0.0824514 (* 1 = 0.0824514 loss)
I1123 22:09:04.146520 12543 solver.cpp:236] Iteration 1500, loss = 0.141965
I1123 22:09:04.146534 12543 solver.cpp:252]     Train net output #0: loss = 0.0630775 (* 1 = 0.0630775 loss)
I1123 22:09:04.146540 12543 sgd_solver.cpp:106] Iteration 1500, lr = 0.002
I1123 22:09:04.805403 12543 solver.cpp:236] Iteration 1600, loss = 0.155012
I1123 22:09:04.805433 12543 solver.cpp:252]     Train net output #0: loss = 0.0910775 (* 1 = 0.0910775 loss)
I1123 22:09:04.805436 12543 sgd_solver.cpp:106] Iteration 1600, lr = 0.002
I1123 22:09:05.468468 12543 solver.cpp:236] Iteration 1700, loss = 0.182751
I1123 22:09:05.468497 12543 solver.cpp:252]     Train net output #0: loss = 0.0811236 (* 1 = 0.0811236 loss)
I1123 22:09:05.468500 12543 sgd_solver.cpp:106] Iteration 1700, lr = 0.002
I1123 22:09:06.126904 12543 solver.cpp:236] Iteration 1800, loss = 0.152312
I1123 22:09:06.126931 12543 solver.cpp:252]     Train net output #0: loss = 0.0112379 (* 1 = 0.0112379 loss)
I1123 22:09:06.126935 12543 sgd_solver.cpp:106] Iteration 1800, lr = 0.002
I1123 22:09:06.792388 12543 solver.cpp:236] Iteration 1900, loss = 0.153372
I1123 22:09:06.792417 12543 solver.cpp:252]     Train net output #0: loss = 0.263582 (* 1 = 0.263582 loss)
I1123 22:09:06.792420 12543 sgd_solver.cpp:106] Iteration 1900, lr = 0.002
I1123 22:09:07.447958 12543 solver.cpp:340] Iteration 2000, Testing net (#0)
I1123 22:09:07.634907 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9822
I1123 22:09:07.634932 12543 solver.cpp:408]     Test net output #1: loss = 0.13025 (* 1 = 0.13025 loss)
I1123 22:09:07.636833 12543 solver.cpp:236] Iteration 2000, loss = 0.14904
I1123 22:09:07.636860 12543 solver.cpp:252]     Train net output #0: loss = 0.170726 (* 1 = 0.170726 loss)
I1123 22:09:07.636867 12543 sgd_solver.cpp:106] Iteration 2000, lr = 0.002
I1123 22:09:08.291056 12543 solver.cpp:236] Iteration 2100, loss = 0.122246
I1123 22:09:08.291085 12543 solver.cpp:252]     Train net output #0: loss = 0.0522153 (* 1 = 0.0522153 loss)
I1123 22:09:08.291088 12543 sgd_solver.cpp:106] Iteration 2100, lr = 0.002
I1123 22:09:08.948168 12543 solver.cpp:236] Iteration 2200, loss = 0.134889
I1123 22:09:08.948195 12543 solver.cpp:252]     Train net output #0: loss = 0.163797 (* 1 = 0.163797 loss)
I1123 22:09:08.948199 12543 sgd_solver.cpp:106] Iteration 2200, lr = 0.002
I1123 22:09:09.614725 12543 solver.cpp:236] Iteration 2300, loss = 0.156044
I1123 22:09:09.614753 12543 solver.cpp:252]     Train net output #0: loss = 0.214752 (* 1 = 0.214752 loss)
I1123 22:09:09.614756 12543 sgd_solver.cpp:106] Iteration 2300, lr = 0.002
I1123 22:09:10.269552 12543 solver.cpp:236] Iteration 2400, loss = 0.130289
I1123 22:09:10.269582 12543 solver.cpp:252]     Train net output #0: loss = 0.0765009 (* 1 = 0.0765009 loss)
I1123 22:09:10.269587 12543 sgd_solver.cpp:106] Iteration 2400, lr = 0.002
I1123 22:09:10.920516 12543 solver.cpp:340] Iteration 2500, Testing net (#0)
I1123 22:09:11.108711 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9876
I1123 22:09:11.108737 12543 solver.cpp:408]     Test net output #1: loss = 0.0820879 (* 1 = 0.0820879 loss)
I1123 22:09:11.110604 12543 solver.cpp:236] Iteration 2500, loss = 0.132588
I1123 22:09:11.110617 12543 solver.cpp:252]     Train net output #0: loss = 0.05148 (* 1 = 0.05148 loss)
I1123 22:09:11.110623 12543 sgd_solver.cpp:106] Iteration 2500, lr = 0.002
I1123 22:09:11.771823 12543 solver.cpp:236] Iteration 2600, loss = 0.139569
I1123 22:09:11.771852 12543 solver.cpp:252]     Train net output #0: loss = 0.227142 (* 1 = 0.227142 loss)
I1123 22:09:11.771855 12543 sgd_solver.cpp:106] Iteration 2600, lr = 0.002
I1123 22:09:12.428009 12543 solver.cpp:236] Iteration 2700, loss = 0.111473
I1123 22:09:12.428036 12543 solver.cpp:252]     Train net output #0: loss = 0.165664 (* 1 = 0.165664 loss)
I1123 22:09:12.428040 12543 sgd_solver.cpp:106] Iteration 2700, lr = 0.002
I1123 22:09:13.084501 12543 solver.cpp:236] Iteration 2800, loss = 0.0625222
I1123 22:09:13.084528 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:09:13.084532 12543 sgd_solver.cpp:106] Iteration 2800, lr = 0.002
I1123 22:09:13.739593 12543 solver.cpp:236] Iteration 2900, loss = 0.109687
I1123 22:09:13.739621 12543 solver.cpp:252]     Train net output #0: loss = 0.182467 (* 1 = 0.182467 loss)
I1123 22:09:13.739625 12543 sgd_solver.cpp:106] Iteration 2900, lr = 0.002
I1123 22:09:14.387589 12543 solver.cpp:340] Iteration 3000, Testing net (#0)
I1123 22:09:14.575803 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9831
I1123 22:09:14.575829 12543 solver.cpp:408]     Test net output #1: loss = 0.111196 (* 1 = 0.111196 loss)
I1123 22:09:14.577708 12543 solver.cpp:236] Iteration 3000, loss = 0.0973218
I1123 22:09:14.577723 12543 solver.cpp:252]     Train net output #0: loss = 0.257261 (* 1 = 0.257261 loss)
I1123 22:09:14.577728 12543 sgd_solver.cpp:106] Iteration 3000, lr = 0.002
I1123 22:09:15.231727 12543 solver.cpp:236] Iteration 3100, loss = 0.134804
I1123 22:09:15.231755 12543 solver.cpp:252]     Train net output #0: loss = 0.119779 (* 1 = 0.119779 loss)
I1123 22:09:15.231760 12543 sgd_solver.cpp:106] Iteration 3100, lr = 0.002
I1123 22:09:15.895104 12543 solver.cpp:236] Iteration 3200, loss = 0.111568
I1123 22:09:15.895130 12543 solver.cpp:252]     Train net output #0: loss = 0.0124678 (* 1 = 0.0124678 loss)
I1123 22:09:15.895134 12543 sgd_solver.cpp:106] Iteration 3200, lr = 0.002
I1123 22:09:16.552569 12543 solver.cpp:236] Iteration 3300, loss = 0.115752
I1123 22:09:16.552595 12543 solver.cpp:252]     Train net output #0: loss = 0.0238478 (* 1 = 0.0238478 loss)
I1123 22:09:16.552600 12543 sgd_solver.cpp:106] Iteration 3300, lr = 0.002
I1123 22:09:17.210602 12543 solver.cpp:236] Iteration 3400, loss = 0.0861032
I1123 22:09:17.210629 12543 solver.cpp:252]     Train net output #0: loss = 0.0236098 (* 1 = 0.0236098 loss)
I1123 22:09:17.210633 12543 sgd_solver.cpp:106] Iteration 3400, lr = 0.002
I1123 22:09:17.864172 12543 solver.cpp:340] Iteration 3500, Testing net (#0)
I1123 22:09:18.051730 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9901
I1123 22:09:18.051756 12543 solver.cpp:408]     Test net output #1: loss = 0.0873559 (* 1 = 0.0873559 loss)
I1123 22:09:18.053645 12543 solver.cpp:236] Iteration 3500, loss = 0.0992868
I1123 22:09:18.053659 12543 solver.cpp:252]     Train net output #0: loss = 0.169435 (* 1 = 0.169435 loss)
I1123 22:09:18.053665 12543 sgd_solver.cpp:106] Iteration 3500, lr = 0.002
I1123 22:09:18.712023 12543 solver.cpp:236] Iteration 3600, loss = 0.126392
I1123 22:09:18.712051 12543 solver.cpp:252]     Train net output #0: loss = 0.259063 (* 1 = 0.259063 loss)
I1123 22:09:18.712056 12543 sgd_solver.cpp:106] Iteration 3600, lr = 0.002
I1123 22:09:19.369503 12543 solver.cpp:236] Iteration 3700, loss = 0.0799635
I1123 22:09:19.369531 12543 solver.cpp:252]     Train net output #0: loss = 0.132617 (* 1 = 0.132617 loss)
I1123 22:09:19.369535 12543 sgd_solver.cpp:106] Iteration 3700, lr = 0.002
I1123 22:09:20.028018 12543 solver.cpp:236] Iteration 3800, loss = 0.102785
I1123 22:09:20.028048 12543 solver.cpp:252]     Train net output #0: loss = 0.0971812 (* 1 = 0.0971812 loss)
I1123 22:09:20.028051 12543 sgd_solver.cpp:106] Iteration 3800, lr = 0.002
I1123 22:09:20.685792 12543 solver.cpp:236] Iteration 3900, loss = 0.115355
I1123 22:09:20.685817 12543 solver.cpp:252]     Train net output #0: loss = 0.0218463 (* 1 = 0.0218463 loss)
I1123 22:09:20.685822 12543 sgd_solver.cpp:106] Iteration 3900, lr = 0.002
I1123 22:09:21.340998 12543 solver.cpp:340] Iteration 4000, Testing net (#0)
I1123 22:09:21.528980 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9836
I1123 22:09:21.529008 12543 solver.cpp:408]     Test net output #1: loss = 0.112539 (* 1 = 0.112539 loss)
I1123 22:09:21.530889 12543 solver.cpp:236] Iteration 4000, loss = 0.0864653
I1123 22:09:21.530902 12543 solver.cpp:252]     Train net output #0: loss = 0.168081 (* 1 = 0.168081 loss)
I1123 22:09:21.530910 12543 sgd_solver.cpp:106] Iteration 4000, lr = 0.002
I1123 22:09:22.193699 12543 solver.cpp:236] Iteration 4100, loss = 0.0796286
I1123 22:09:22.193727 12543 solver.cpp:252]     Train net output #0: loss = 0.0647511 (* 1 = 0.0647511 loss)
I1123 22:09:22.193732 12543 sgd_solver.cpp:106] Iteration 4100, lr = 0.002
I1123 22:09:22.853580 12543 solver.cpp:236] Iteration 4200, loss = 0.123715
I1123 22:09:22.853607 12543 solver.cpp:252]     Train net output #0: loss = 0.0822366 (* 1 = 0.0822366 loss)
I1123 22:09:22.853611 12543 sgd_solver.cpp:106] Iteration 4200, lr = 0.002
I1123 22:09:23.514015 12543 solver.cpp:236] Iteration 4300, loss = 0.102413
I1123 22:09:23.514122 12543 solver.cpp:252]     Train net output #0: loss = 0.247405 (* 1 = 0.247405 loss)
I1123 22:09:23.514127 12543 sgd_solver.cpp:106] Iteration 4300, lr = 0.002
I1123 22:09:24.165892 12543 solver.cpp:236] Iteration 4400, loss = 0.130453
I1123 22:09:24.165921 12543 solver.cpp:252]     Train net output #0: loss = 0.0748365 (* 1 = 0.0748365 loss)
I1123 22:09:24.165926 12543 sgd_solver.cpp:106] Iteration 4400, lr = 0.002
I1123 22:09:24.818064 12543 solver.cpp:340] Iteration 4500, Testing net (#0)
I1123 22:09:25.006834 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9893
I1123 22:09:25.006858 12543 solver.cpp:408]     Test net output #1: loss = 0.0752051 (* 1 = 0.0752051 loss)
I1123 22:09:25.008705 12543 solver.cpp:236] Iteration 4500, loss = 0.12408
I1123 22:09:25.008719 12543 solver.cpp:252]     Train net output #0: loss = 0.146785 (* 1 = 0.146785 loss)
I1123 22:09:25.008726 12543 sgd_solver.cpp:106] Iteration 4500, lr = 0.002
I1123 22:09:25.664835 12543 solver.cpp:236] Iteration 4600, loss = 0.0989711
I1123 22:09:25.664862 12543 solver.cpp:252]     Train net output #0: loss = 0.16595 (* 1 = 0.16595 loss)
I1123 22:09:25.664866 12543 sgd_solver.cpp:106] Iteration 4600, lr = 0.002
I1123 22:09:26.327795 12543 solver.cpp:236] Iteration 4700, loss = 0.0631169
I1123 22:09:26.327824 12543 solver.cpp:252]     Train net output #0: loss = 0.061486 (* 1 = 0.061486 loss)
I1123 22:09:26.327828 12543 sgd_solver.cpp:106] Iteration 4700, lr = 0.002
I1123 22:09:26.984366 12543 solver.cpp:236] Iteration 4800, loss = 0.121552
I1123 22:09:26.984395 12543 solver.cpp:252]     Train net output #0: loss = 0.0832662 (* 1 = 0.0832662 loss)
I1123 22:09:26.984400 12543 sgd_solver.cpp:106] Iteration 4800, lr = 0.002
I1123 22:09:27.643640 12543 solver.cpp:236] Iteration 4900, loss = 0.0708368
I1123 22:09:27.643666 12543 solver.cpp:252]     Train net output #0: loss = 0.108684 (* 1 = 0.108684 loss)
I1123 22:09:27.643671 12543 sgd_solver.cpp:106] Iteration 4900, lr = 0.002
I1123 22:09:28.296630 12543 solver.cpp:340] Iteration 5000, Testing net (#0)
I1123 22:09:28.484702 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9885
I1123 22:09:28.484729 12543 solver.cpp:408]     Test net output #1: loss = 0.0706386 (* 1 = 0.0706386 loss)
I1123 22:09:28.486591 12543 solver.cpp:236] Iteration 5000, loss = 0.0877916
I1123 22:09:28.486605 12543 solver.cpp:252]     Train net output #0: loss = 0.167358 (* 1 = 0.167358 loss)
I1123 22:09:28.486610 12543 sgd_solver.cpp:106] Iteration 5000, lr = 0.002
I1123 22:09:29.140405 12543 solver.cpp:236] Iteration 5100, loss = 0.0892007
I1123 22:09:29.140434 12543 solver.cpp:252]     Train net output #0: loss = 0.106832 (* 1 = 0.106832 loss)
I1123 22:09:29.140439 12543 sgd_solver.cpp:106] Iteration 5100, lr = 0.002
I1123 22:09:29.802484 12543 solver.cpp:236] Iteration 5200, loss = 0.0945067
I1123 22:09:29.802511 12543 solver.cpp:252]     Train net output #0: loss = 0.110769 (* 1 = 0.110769 loss)
I1123 22:09:29.802515 12543 sgd_solver.cpp:106] Iteration 5200, lr = 0.002
I1123 22:09:30.456924 12543 solver.cpp:236] Iteration 5300, loss = 0.0899406
I1123 22:09:30.456953 12543 solver.cpp:252]     Train net output #0: loss = 0.052312 (* 1 = 0.052312 loss)
I1123 22:09:30.456956 12543 sgd_solver.cpp:106] Iteration 5300, lr = 0.002
I1123 22:09:31.115500 12543 solver.cpp:236] Iteration 5400, loss = 0.0740384
I1123 22:09:31.115527 12543 solver.cpp:252]     Train net output #0: loss = 0.0859757 (* 1 = 0.0859757 loss)
I1123 22:09:31.115531 12543 sgd_solver.cpp:106] Iteration 5400, lr = 0.002
I1123 22:09:31.767496 12543 solver.cpp:340] Iteration 5500, Testing net (#0)
I1123 22:09:31.955059 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9905
I1123 22:09:31.955085 12543 solver.cpp:408]     Test net output #1: loss = 0.0641111 (* 1 = 0.0641111 loss)
I1123 22:09:31.956925 12543 solver.cpp:236] Iteration 5500, loss = 0.100795
I1123 22:09:31.956938 12543 solver.cpp:252]     Train net output #0: loss = 0.0495827 (* 1 = 0.0495827 loss)
I1123 22:09:31.956943 12543 sgd_solver.cpp:106] Iteration 5500, lr = 0.002
I1123 22:09:32.682677 12543 solver.cpp:236] Iteration 5600, loss = 0.0762165
I1123 22:09:32.682705 12543 solver.cpp:252]     Train net output #0: loss = 0.0344448 (* 1 = 0.0344448 loss)
I1123 22:09:32.682709 12543 sgd_solver.cpp:106] Iteration 5600, lr = 0.002
I1123 22:09:33.344389 12543 solver.cpp:236] Iteration 5700, loss = 0.0836104
I1123 22:09:33.344416 12543 solver.cpp:252]     Train net output #0: loss = 0.0232671 (* 1 = 0.0232671 loss)
I1123 22:09:33.344420 12543 sgd_solver.cpp:106] Iteration 5700, lr = 0.002
I1123 22:09:33.998410 12543 solver.cpp:236] Iteration 5800, loss = 0.0853701
I1123 22:09:33.998440 12543 solver.cpp:252]     Train net output #0: loss = 0.13808 (* 1 = 0.13808 loss)
I1123 22:09:33.998445 12543 sgd_solver.cpp:106] Iteration 5800, lr = 0.002
I1123 22:09:34.657315 12543 solver.cpp:236] Iteration 5900, loss = 0.0941326
I1123 22:09:34.657344 12543 solver.cpp:252]     Train net output #0: loss = 0.152204 (* 1 = 0.152204 loss)
I1123 22:09:34.657348 12543 sgd_solver.cpp:106] Iteration 5900, lr = 0.002
I1123 22:09:35.306864 12543 solver.cpp:340] Iteration 6000, Testing net (#0)
I1123 22:09:35.494212 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9906
I1123 22:09:35.494240 12543 solver.cpp:408]     Test net output #1: loss = 0.0585366 (* 1 = 0.0585366 loss)
I1123 22:09:35.496136 12543 solver.cpp:236] Iteration 6000, loss = 0.079167
I1123 22:09:35.496150 12543 solver.cpp:252]     Train net output #0: loss = 0.0982751 (* 1 = 0.0982751 loss)
I1123 22:09:35.496157 12543 sgd_solver.cpp:106] Iteration 6000, lr = 0.002
I1123 22:09:36.155110 12543 solver.cpp:236] Iteration 6100, loss = 0.0901099
I1123 22:09:36.155139 12543 solver.cpp:252]     Train net output #0: loss = 0.182691 (* 1 = 0.182691 loss)
I1123 22:09:36.155143 12543 sgd_solver.cpp:106] Iteration 6100, lr = 0.002
I1123 22:09:36.812252 12543 solver.cpp:236] Iteration 6200, loss = 0.0943907
I1123 22:09:36.812279 12543 solver.cpp:252]     Train net output #0: loss = 0.0982095 (* 1 = 0.0982095 loss)
I1123 22:09:36.812283 12543 sgd_solver.cpp:106] Iteration 6200, lr = 0.002
I1123 22:09:37.467155 12543 solver.cpp:236] Iteration 6300, loss = 0.095598
I1123 22:09:37.467185 12543 solver.cpp:252]     Train net output #0: loss = 0.0494947 (* 1 = 0.0494947 loss)
I1123 22:09:37.467188 12543 sgd_solver.cpp:106] Iteration 6300, lr = 0.002
I1123 22:09:38.125610 12543 solver.cpp:236] Iteration 6400, loss = 0.0890505
I1123 22:09:38.125638 12543 solver.cpp:252]     Train net output #0: loss = 0.129185 (* 1 = 0.129185 loss)
I1123 22:09:38.125643 12543 sgd_solver.cpp:106] Iteration 6400, lr = 0.002
I1123 22:09:38.779748 12543 solver.cpp:340] Iteration 6500, Testing net (#0)
I1123 22:09:38.966786 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9886
I1123 22:09:38.966812 12543 solver.cpp:408]     Test net output #1: loss = 0.0742609 (* 1 = 0.0742609 loss)
I1123 22:09:38.968726 12543 solver.cpp:236] Iteration 6500, loss = 0.0793393
I1123 22:09:38.968739 12543 solver.cpp:252]     Train net output #0: loss = 0.100153 (* 1 = 0.100153 loss)
I1123 22:09:38.968744 12543 sgd_solver.cpp:106] Iteration 6500, lr = 0.002
I1123 22:09:39.630463 12543 solver.cpp:236] Iteration 6600, loss = 0.0940845
I1123 22:09:39.630492 12543 solver.cpp:252]     Train net output #0: loss = 0.196589 (* 1 = 0.196589 loss)
I1123 22:09:39.630496 12543 sgd_solver.cpp:106] Iteration 6600, lr = 0.002
I1123 22:09:40.290421 12543 solver.cpp:236] Iteration 6700, loss = 0.105262
I1123 22:09:40.290446 12543 solver.cpp:252]     Train net output #0: loss = 0.0458728 (* 1 = 0.0458728 loss)
I1123 22:09:40.290451 12543 sgd_solver.cpp:106] Iteration 6700, lr = 0.002
I1123 22:09:40.944936 12543 solver.cpp:236] Iteration 6800, loss = 0.0803341
I1123 22:09:40.944963 12543 solver.cpp:252]     Train net output #0: loss = 0.00338677 (* 1 = 0.00338677 loss)
I1123 22:09:40.944967 12543 sgd_solver.cpp:106] Iteration 6800, lr = 0.002
I1123 22:09:41.605139 12543 solver.cpp:236] Iteration 6900, loss = 0.0923674
I1123 22:09:41.605168 12543 solver.cpp:252]     Train net output #0: loss = 0.0228969 (* 1 = 0.0228969 loss)
I1123 22:09:41.605193 12543 sgd_solver.cpp:106] Iteration 6900, lr = 0.002
I1123 22:09:42.257788 12543 solver.cpp:340] Iteration 7000, Testing net (#0)
I1123 22:09:42.446069 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9929
I1123 22:09:42.446094 12543 solver.cpp:408]     Test net output #1: loss = 0.0487814 (* 1 = 0.0487814 loss)
I1123 22:09:42.447968 12543 solver.cpp:236] Iteration 7000, loss = 0.0833976
I1123 22:09:42.447980 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:09:42.447985 12543 sgd_solver.cpp:106] Iteration 7000, lr = 0.002
I1123 22:09:43.107136 12543 solver.cpp:236] Iteration 7100, loss = 0.0764317
I1123 22:09:43.107164 12543 solver.cpp:252]     Train net output #0: loss = 0.125449 (* 1 = 0.125449 loss)
I1123 22:09:43.107168 12543 sgd_solver.cpp:106] Iteration 7100, lr = 0.002
I1123 22:09:43.768249 12543 solver.cpp:236] Iteration 7200, loss = 0.0920289
I1123 22:09:43.768277 12543 solver.cpp:252]     Train net output #0: loss = 0.0451522 (* 1 = 0.0451522 loss)
I1123 22:09:43.768281 12543 sgd_solver.cpp:106] Iteration 7200, lr = 0.002
I1123 22:09:44.432029 12543 solver.cpp:236] Iteration 7300, loss = 0.0915702
I1123 22:09:44.432055 12543 solver.cpp:252]     Train net output #0: loss = 0.22417 (* 1 = 0.22417 loss)
I1123 22:09:44.432060 12543 sgd_solver.cpp:106] Iteration 7300, lr = 0.002
I1123 22:09:45.091367 12543 solver.cpp:236] Iteration 7400, loss = 0.0818011
I1123 22:09:45.091394 12543 solver.cpp:252]     Train net output #0: loss = 0.0699285 (* 1 = 0.0699285 loss)
I1123 22:09:45.091398 12543 sgd_solver.cpp:106] Iteration 7400, lr = 0.002
I1123 22:09:45.745370 12543 solver.cpp:340] Iteration 7500, Testing net (#0)
I1123 22:09:45.917717 12550 blocking_queue.cpp:50] Waiting for data
I1123 22:09:45.949694 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9908
I1123 22:09:45.949769 12543 solver.cpp:408]     Test net output #1: loss = 0.0600325 (* 1 = 0.0600325 loss)
I1123 22:09:45.951917 12543 solver.cpp:236] Iteration 7500, loss = 0.0584268
I1123 22:09:45.951936 12543 solver.cpp:252]     Train net output #0: loss = 0.026899 (* 1 = 0.026899 loss)
I1123 22:09:45.951944 12543 sgd_solver.cpp:106] Iteration 7500, lr = 0.002
I1123 22:09:46.664543 12543 solver.cpp:236] Iteration 7600, loss = 0.0907464
I1123 22:09:46.664573 12543 solver.cpp:252]     Train net output #0: loss = 0.14921 (* 1 = 0.14921 loss)
I1123 22:09:46.664580 12543 sgd_solver.cpp:106] Iteration 7600, lr = 0.002
I1123 22:09:47.358904 12543 solver.cpp:236] Iteration 7700, loss = 0.0578532
I1123 22:09:47.358934 12543 solver.cpp:252]     Train net output #0: loss = 0.0350717 (* 1 = 0.0350717 loss)
I1123 22:09:47.358938 12543 sgd_solver.cpp:106] Iteration 7700, lr = 0.002
I1123 22:09:48.027806 12543 solver.cpp:236] Iteration 7800, loss = 0.0856606
I1123 22:09:48.027832 12543 solver.cpp:252]     Train net output #0: loss = 0.139962 (* 1 = 0.139962 loss)
I1123 22:09:48.027837 12543 sgd_solver.cpp:106] Iteration 7800, lr = 0.002
I1123 22:09:48.693945 12543 solver.cpp:236] Iteration 7900, loss = 0.0735381
I1123 22:09:48.693974 12543 solver.cpp:252]     Train net output #0: loss = 0.0305212 (* 1 = 0.0305212 loss)
I1123 22:09:48.693979 12543 sgd_solver.cpp:106] Iteration 7900, lr = 0.002
I1123 22:09:49.348134 12543 solver.cpp:340] Iteration 8000, Testing net (#0)
I1123 22:09:49.536900 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9916
I1123 22:09:49.536924 12543 solver.cpp:408]     Test net output #1: loss = 0.0563939 (* 1 = 0.0563939 loss)
I1123 22:09:49.538790 12543 solver.cpp:236] Iteration 8000, loss = 0.0706763
I1123 22:09:49.538805 12543 solver.cpp:252]     Train net output #0: loss = 0.0065619 (* 1 = 0.0065619 loss)
I1123 22:09:49.538810 12543 sgd_solver.cpp:106] Iteration 8000, lr = 0.002
I1123 22:09:50.199594 12543 solver.cpp:236] Iteration 8100, loss = 0.0679659
I1123 22:09:50.199623 12543 solver.cpp:252]     Train net output #0: loss = 0.0140993 (* 1 = 0.0140993 loss)
I1123 22:09:50.199628 12543 sgd_solver.cpp:106] Iteration 8100, lr = 0.002
I1123 22:09:50.859539 12543 solver.cpp:236] Iteration 8200, loss = 0.0651799
I1123 22:09:50.859582 12543 solver.cpp:252]     Train net output #0: loss = 0.0478038 (* 1 = 0.0478038 loss)
I1123 22:09:50.859587 12543 sgd_solver.cpp:106] Iteration 8200, lr = 0.002
I1123 22:09:51.525300 12543 solver.cpp:236] Iteration 8300, loss = 0.0934129
I1123 22:09:51.525328 12543 solver.cpp:252]     Train net output #0: loss = 0.288033 (* 1 = 0.288033 loss)
I1123 22:09:51.525332 12543 sgd_solver.cpp:106] Iteration 8300, lr = 0.002
I1123 22:09:52.214301 12543 solver.cpp:236] Iteration 8400, loss = 0.0673108
I1123 22:09:52.214330 12543 solver.cpp:252]     Train net output #0: loss = 0.0993907 (* 1 = 0.0993907 loss)
I1123 22:09:52.214336 12543 sgd_solver.cpp:106] Iteration 8400, lr = 0.002
I1123 22:09:52.906157 12543 solver.cpp:340] Iteration 8500, Testing net (#0)
I1123 22:09:53.101336 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9909
I1123 22:09:53.101366 12543 solver.cpp:408]     Test net output #1: loss = 0.0588619 (* 1 = 0.0588619 loss)
I1123 22:09:53.103283 12543 solver.cpp:236] Iteration 8500, loss = 0.0729906
I1123 22:09:53.103298 12543 solver.cpp:252]     Train net output #0: loss = 0.147082 (* 1 = 0.147082 loss)
I1123 22:09:53.103307 12543 sgd_solver.cpp:106] Iteration 8500, lr = 0.002
I1123 22:09:53.783360 12543 solver.cpp:236] Iteration 8600, loss = 0.0854708
I1123 22:09:53.783463 12543 solver.cpp:252]     Train net output #0: loss = 0.00974452 (* 1 = 0.00974452 loss)
I1123 22:09:53.783470 12543 sgd_solver.cpp:106] Iteration 8600, lr = 0.002
I1123 22:09:54.454475 12543 solver.cpp:236] Iteration 8700, loss = 0.090182
I1123 22:09:54.454504 12543 solver.cpp:252]     Train net output #0: loss = 0.0312165 (* 1 = 0.0312165 loss)
I1123 22:09:54.454509 12543 sgd_solver.cpp:106] Iteration 8700, lr = 0.002
I1123 22:09:55.158890 12543 solver.cpp:236] Iteration 8800, loss = 0.0664268
I1123 22:09:55.158918 12543 solver.cpp:252]     Train net output #0: loss = 0.0396288 (* 1 = 0.0396288 loss)
I1123 22:09:55.158922 12543 sgd_solver.cpp:106] Iteration 8800, lr = 0.002
I1123 22:09:55.844905 12543 solver.cpp:236] Iteration 8900, loss = 0.0771117
I1123 22:09:55.844933 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:09:55.844938 12543 sgd_solver.cpp:106] Iteration 8900, lr = 0.002
I1123 22:09:56.528410 12543 solver.cpp:340] Iteration 9000, Testing net (#0)
I1123 22:09:56.727603 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9911
I1123 22:09:56.727630 12543 solver.cpp:408]     Test net output #1: loss = 0.05885 (* 1 = 0.05885 loss)
I1123 22:09:56.729487 12543 solver.cpp:236] Iteration 9000, loss = 0.0831776
I1123 22:09:56.729501 12543 solver.cpp:252]     Train net output #0: loss = 0.0371401 (* 1 = 0.0371401 loss)
I1123 22:09:56.729506 12543 sgd_solver.cpp:106] Iteration 9000, lr = 0.002
I1123 22:09:57.410377 12543 solver.cpp:236] Iteration 9100, loss = 0.0889913
I1123 22:09:57.410404 12543 solver.cpp:252]     Train net output #0: loss = 0.150166 (* 1 = 0.150166 loss)
I1123 22:09:57.410408 12543 sgd_solver.cpp:106] Iteration 9100, lr = 0.002
I1123 22:09:58.109094 12543 solver.cpp:236] Iteration 9200, loss = 0.065286
I1123 22:09:58.109124 12543 solver.cpp:252]     Train net output #0: loss = 0.178376 (* 1 = 0.178376 loss)
I1123 22:09:58.109128 12543 sgd_solver.cpp:106] Iteration 9200, lr = 0.002
I1123 22:09:58.797797 12543 solver.cpp:236] Iteration 9300, loss = 0.0787753
I1123 22:09:58.797824 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:09:58.797828 12543 sgd_solver.cpp:106] Iteration 9300, lr = 0.002
I1123 22:09:59.475530 12543 solver.cpp:236] Iteration 9400, loss = 0.0846011
I1123 22:09:59.475558 12543 solver.cpp:252]     Train net output #0: loss = 0.304944 (* 1 = 0.304944 loss)
I1123 22:09:59.475563 12543 sgd_solver.cpp:106] Iteration 9400, lr = 0.002
I1123 22:10:00.143713 12543 solver.cpp:340] Iteration 9500, Testing net (#0)
I1123 22:10:00.332634 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9909
I1123 22:10:00.332661 12543 solver.cpp:408]     Test net output #1: loss = 0.0526222 (* 1 = 0.0526222 loss)
I1123 22:10:00.334527 12543 solver.cpp:236] Iteration 9500, loss = 0.0893059
I1123 22:10:00.334542 12543 solver.cpp:252]     Train net output #0: loss = 0.0490137 (* 1 = 0.0490137 loss)
I1123 22:10:00.334547 12543 sgd_solver.cpp:106] Iteration 9500, lr = 0.002
I1123 22:10:01.002953 12543 solver.cpp:236] Iteration 9600, loss = 0.0549742
I1123 22:10:01.002982 12543 solver.cpp:252]     Train net output #0: loss = 0.0239597 (* 1 = 0.0239597 loss)
I1123 22:10:01.002986 12543 sgd_solver.cpp:106] Iteration 9600, lr = 0.002
I1123 22:10:01.666401 12543 solver.cpp:236] Iteration 9700, loss = 0.0934792
I1123 22:10:01.666431 12543 solver.cpp:252]     Train net output #0: loss = 0.0688402 (* 1 = 0.0688402 loss)
I1123 22:10:01.666435 12543 sgd_solver.cpp:106] Iteration 9700, lr = 0.002
I1123 22:10:02.329721 12543 solver.cpp:236] Iteration 9800, loss = 0.0841388
I1123 22:10:02.329748 12543 solver.cpp:252]     Train net output #0: loss = 0.0579979 (* 1 = 0.0579979 loss)
I1123 22:10:02.329753 12543 sgd_solver.cpp:106] Iteration 9800, lr = 0.002
I1123 22:10:02.998126 12543 solver.cpp:236] Iteration 9900, loss = 0.0800035
I1123 22:10:02.998153 12543 solver.cpp:252]     Train net output #0: loss = 0.00134322 (* 1 = 0.00134322 loss)
I1123 22:10:02.998157 12543 sgd_solver.cpp:106] Iteration 9900, lr = 0.002
I1123 22:10:03.655179 12543 solver.cpp:340] Iteration 10000, Testing net (#0)
I1123 22:10:03.845499 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9919
I1123 22:10:03.845527 12543 solver.cpp:408]     Test net output #1: loss = 0.0573429 (* 1 = 0.0573429 loss)
I1123 22:10:03.847417 12543 solver.cpp:236] Iteration 10000, loss = 0.0811185
I1123 22:10:03.847430 12543 solver.cpp:252]     Train net output #0: loss = 0.0260247 (* 1 = 0.0260247 loss)
I1123 22:10:03.847436 12543 sgd_solver.cpp:106] Iteration 10000, lr = 0.002
I1123 22:10:04.510181 12543 solver.cpp:236] Iteration 10100, loss = 0.0731988
I1123 22:10:04.510210 12543 solver.cpp:252]     Train net output #0: loss = 0.126274 (* 1 = 0.126274 loss)
I1123 22:10:04.510213 12543 sgd_solver.cpp:106] Iteration 10100, lr = 0.002
I1123 22:10:05.168974 12543 solver.cpp:236] Iteration 10200, loss = 0.0602832
I1123 22:10:05.169006 12543 solver.cpp:252]     Train net output #0: loss = 0.249937 (* 1 = 0.249937 loss)
I1123 22:10:05.169010 12543 sgd_solver.cpp:106] Iteration 10200, lr = 0.002
I1123 22:10:05.840577 12543 solver.cpp:236] Iteration 10300, loss = 0.0426665
I1123 22:10:05.840605 12543 solver.cpp:252]     Train net output #0: loss = 0.0013417 (* 1 = 0.0013417 loss)
I1123 22:10:05.840608 12543 sgd_solver.cpp:106] Iteration 10300, lr = 0.002
I1123 22:10:06.514787 12543 solver.cpp:236] Iteration 10400, loss = 0.0468125
I1123 22:10:06.514816 12543 solver.cpp:252]     Train net output #0: loss = 0.0948811 (* 1 = 0.0948811 loss)
I1123 22:10:06.514821 12543 sgd_solver.cpp:106] Iteration 10400, lr = 0.002
I1123 22:10:07.179857 12543 solver.cpp:340] Iteration 10500, Testing net (#0)
I1123 22:10:07.369077 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9887
I1123 22:10:07.369104 12543 solver.cpp:408]     Test net output #1: loss = 0.0702206 (* 1 = 0.0702206 loss)
I1123 22:10:07.371034 12543 solver.cpp:236] Iteration 10500, loss = 0.0586525
I1123 22:10:07.371050 12543 solver.cpp:252]     Train net output #0: loss = 0.0841338 (* 1 = 0.0841338 loss)
I1123 22:10:07.371059 12543 sgd_solver.cpp:106] Iteration 10500, lr = 0.002
I1123 22:10:08.040606 12543 solver.cpp:236] Iteration 10600, loss = 0.0798912
I1123 22:10:08.040634 12543 solver.cpp:252]     Train net output #0: loss = 0.120885 (* 1 = 0.120885 loss)
I1123 22:10:08.040639 12543 sgd_solver.cpp:106] Iteration 10600, lr = 0.002
I1123 22:10:08.707438 12543 solver.cpp:236] Iteration 10700, loss = 0.0791568
I1123 22:10:08.707466 12543 solver.cpp:252]     Train net output #0: loss = 0.0282678 (* 1 = 0.0282678 loss)
I1123 22:10:08.707470 12543 sgd_solver.cpp:106] Iteration 10700, lr = 0.002
I1123 22:10:09.371215 12543 solver.cpp:236] Iteration 10800, loss = 0.0672805
I1123 22:10:09.371243 12543 solver.cpp:252]     Train net output #0: loss = 0.0104169 (* 1 = 0.0104169 loss)
I1123 22:10:09.371248 12543 sgd_solver.cpp:106] Iteration 10800, lr = 0.002
I1123 22:10:10.039743 12543 solver.cpp:236] Iteration 10900, loss = 0.0715774
I1123 22:10:10.039772 12543 solver.cpp:252]     Train net output #0: loss = 0.0268917 (* 1 = 0.0268917 loss)
I1123 22:10:10.039775 12543 sgd_solver.cpp:106] Iteration 10900, lr = 0.002
I1123 22:10:10.702347 12543 solver.cpp:340] Iteration 11000, Testing net (#0)
I1123 22:10:10.891958 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9915
I1123 22:10:10.891986 12543 solver.cpp:408]     Test net output #1: loss = 0.0589213 (* 1 = 0.0589213 loss)
I1123 22:10:10.893887 12543 solver.cpp:236] Iteration 11000, loss = 0.0747538
I1123 22:10:10.893903 12543 solver.cpp:252]     Train net output #0: loss = 0.0676869 (* 1 = 0.0676869 loss)
I1123 22:10:10.893908 12543 sgd_solver.cpp:106] Iteration 11000, lr = 0.002
I1123 22:10:11.566484 12543 solver.cpp:236] Iteration 11100, loss = 0.0778298
I1123 22:10:11.566512 12543 solver.cpp:252]     Train net output #0: loss = 0.207963 (* 1 = 0.207963 loss)
I1123 22:10:11.566516 12543 sgd_solver.cpp:106] Iteration 11100, lr = 0.002
I1123 22:10:12.245936 12543 solver.cpp:236] Iteration 11200, loss = 0.062389
I1123 22:10:12.245965 12543 solver.cpp:252]     Train net output #0: loss = 0.128248 (* 1 = 0.128248 loss)
I1123 22:10:12.245993 12543 sgd_solver.cpp:106] Iteration 11200, lr = 0.002
I1123 22:10:12.916757 12543 solver.cpp:236] Iteration 11300, loss = 0.0608351
I1123 22:10:12.916786 12543 solver.cpp:252]     Train net output #0: loss = 0.0538063 (* 1 = 0.0538063 loss)
I1123 22:10:12.916792 12543 sgd_solver.cpp:106] Iteration 11300, lr = 0.002
I1123 22:10:13.598731 12543 solver.cpp:236] Iteration 11400, loss = 0.099016
I1123 22:10:13.598757 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:10:13.598762 12543 sgd_solver.cpp:106] Iteration 11400, lr = 0.002
I1123 22:10:14.264968 12543 solver.cpp:340] Iteration 11500, Testing net (#0)
I1123 22:10:14.453012 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9896
I1123 22:10:14.453038 12543 solver.cpp:408]     Test net output #1: loss = 0.0656556 (* 1 = 0.0656556 loss)
I1123 22:10:14.455003 12543 solver.cpp:236] Iteration 11500, loss = 0.0674562
I1123 22:10:14.455023 12543 solver.cpp:252]     Train net output #0: loss = 0.027761 (* 1 = 0.027761 loss)
I1123 22:10:14.455027 12543 sgd_solver.cpp:106] Iteration 11500, lr = 0.002
I1123 22:10:15.130664 12543 solver.cpp:236] Iteration 11600, loss = 0.0762044
I1123 22:10:15.130692 12543 solver.cpp:252]     Train net output #0: loss = 0.0285468 (* 1 = 0.0285468 loss)
I1123 22:10:15.130697 12543 sgd_solver.cpp:106] Iteration 11600, lr = 0.002
I1123 22:10:15.802781 12543 solver.cpp:236] Iteration 11700, loss = 0.0839075
I1123 22:10:15.802809 12543 solver.cpp:252]     Train net output #0: loss = 0.138111 (* 1 = 0.138111 loss)
I1123 22:10:15.802813 12543 sgd_solver.cpp:106] Iteration 11700, lr = 0.002
I1123 22:10:16.490948 12543 solver.cpp:236] Iteration 11800, loss = 0.0811512
I1123 22:10:16.490975 12543 solver.cpp:252]     Train net output #0: loss = 0.217076 (* 1 = 0.217076 loss)
I1123 22:10:16.490979 12543 sgd_solver.cpp:106] Iteration 11800, lr = 0.002
I1123 22:10:17.169323 12543 solver.cpp:236] Iteration 11900, loss = 0.0771283
I1123 22:10:17.169347 12543 solver.cpp:252]     Train net output #0: loss = 0.074931 (* 1 = 0.074931 loss)
I1123 22:10:17.169350 12543 sgd_solver.cpp:106] Iteration 11900, lr = 0.002
I1123 22:10:17.833098 12543 solver.cpp:340] Iteration 12000, Testing net (#0)
I1123 22:10:18.026526 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9918
I1123 22:10:18.026553 12543 solver.cpp:408]     Test net output #1: loss = 0.0504376 (* 1 = 0.0504376 loss)
I1123 22:10:18.028480 12543 solver.cpp:236] Iteration 12000, loss = 0.0759588
I1123 22:10:18.028494 12543 solver.cpp:252]     Train net output #0: loss = 0.0860391 (* 1 = 0.0860391 loss)
I1123 22:10:18.028499 12543 sgd_solver.cpp:106] Iteration 12000, lr = 0.002
I1123 22:10:18.713624 12543 solver.cpp:236] Iteration 12100, loss = 0.0818045
I1123 22:10:18.713652 12543 solver.cpp:252]     Train net output #0: loss = 0.0328346 (* 1 = 0.0328346 loss)
I1123 22:10:18.713656 12543 sgd_solver.cpp:106] Iteration 12100, lr = 0.002
I1123 22:10:19.378398 12543 solver.cpp:236] Iteration 12200, loss = 0.0590581
I1123 22:10:19.378424 12543 solver.cpp:252]     Train net output #0: loss = 0.0358929 (* 1 = 0.0358929 loss)
I1123 22:10:19.378428 12543 sgd_solver.cpp:106] Iteration 12200, lr = 0.002
I1123 22:10:20.048161 12543 solver.cpp:236] Iteration 12300, loss = 0.0678735
I1123 22:10:20.048197 12543 solver.cpp:252]     Train net output #0: loss = 0.0457303 (* 1 = 0.0457303 loss)
I1123 22:10:20.048204 12543 sgd_solver.cpp:106] Iteration 12300, lr = 0.002
I1123 22:10:20.773501 12543 solver.cpp:236] Iteration 12400, loss = 0.0597152
I1123 22:10:20.773529 12543 solver.cpp:252]     Train net output #0: loss = 0.0633639 (* 1 = 0.0633639 loss)
I1123 22:10:20.773533 12543 sgd_solver.cpp:106] Iteration 12400, lr = 0.002
I1123 22:10:21.470119 12543 solver.cpp:340] Iteration 12500, Testing net (#0)
I1123 22:10:21.662155 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9906
I1123 22:10:21.662180 12543 solver.cpp:408]     Test net output #1: loss = 0.0615286 (* 1 = 0.0615286 loss)
I1123 22:10:21.664073 12543 solver.cpp:236] Iteration 12500, loss = 0.0758204
I1123 22:10:21.664101 12543 solver.cpp:252]     Train net output #0: loss = 0.0820926 (* 1 = 0.0820926 loss)
I1123 22:10:21.664108 12543 sgd_solver.cpp:106] Iteration 12500, lr = 0.002
I1123 22:10:22.342085 12543 solver.cpp:236] Iteration 12600, loss = 0.0628557
I1123 22:10:22.342113 12543 solver.cpp:252]     Train net output #0: loss = 0.0205315 (* 1 = 0.0205315 loss)
I1123 22:10:22.342118 12543 sgd_solver.cpp:106] Iteration 12600, lr = 0.002
I1123 22:10:23.015422 12543 solver.cpp:236] Iteration 12700, loss = 0.0695355
I1123 22:10:23.015449 12543 solver.cpp:252]     Train net output #0: loss = 0.0168893 (* 1 = 0.0168893 loss)
I1123 22:10:23.015452 12543 sgd_solver.cpp:106] Iteration 12700, lr = 0.002
I1123 22:10:23.688288 12543 solver.cpp:236] Iteration 12800, loss = 0.0745477
I1123 22:10:23.688315 12543 solver.cpp:252]     Train net output #0: loss = 0.0333307 (* 1 = 0.0333307 loss)
I1123 22:10:23.688320 12543 sgd_solver.cpp:106] Iteration 12800, lr = 0.002
I1123 22:10:24.375938 12543 solver.cpp:236] Iteration 12900, loss = 0.0599907
I1123 22:10:24.376040 12543 solver.cpp:252]     Train net output #0: loss = 0.128694 (* 1 = 0.128694 loss)
I1123 22:10:24.376046 12543 sgd_solver.cpp:106] Iteration 12900, lr = 0.002
I1123 22:10:25.054846 12543 solver.cpp:340] Iteration 13000, Testing net (#0)
I1123 22:10:25.251915 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9934
I1123 22:10:25.251943 12543 solver.cpp:408]     Test net output #1: loss = 0.0549455 (* 1 = 0.0549455 loss)
I1123 22:10:25.253845 12543 solver.cpp:236] Iteration 13000, loss = 0.0759907
I1123 22:10:25.253860 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:10:25.253866 12543 sgd_solver.cpp:106] Iteration 13000, lr = 0.002
I1123 22:10:25.920876 12543 solver.cpp:236] Iteration 13100, loss = 0.0569992
I1123 22:10:25.920907 12543 solver.cpp:252]     Train net output #0: loss = 0.0687538 (* 1 = 0.0687538 loss)
I1123 22:10:25.920915 12543 sgd_solver.cpp:106] Iteration 13100, lr = 0.002
I1123 22:10:26.602918 12543 solver.cpp:236] Iteration 13200, loss = 0.0633206
I1123 22:10:26.602947 12543 solver.cpp:252]     Train net output #0: loss = 0.0922487 (* 1 = 0.0922487 loss)
I1123 22:10:26.602953 12543 sgd_solver.cpp:106] Iteration 13200, lr = 0.002
I1123 22:10:27.274600 12543 solver.cpp:236] Iteration 13300, loss = 0.0688536
I1123 22:10:27.274629 12543 solver.cpp:252]     Train net output #0: loss = 0.0856637 (* 1 = 0.0856637 loss)
I1123 22:10:27.274636 12543 sgd_solver.cpp:106] Iteration 13300, lr = 0.002
I1123 22:10:27.943749 12543 solver.cpp:236] Iteration 13400, loss = 0.0567033
I1123 22:10:27.943789 12543 solver.cpp:252]     Train net output #0: loss = 0.101699 (* 1 = 0.101699 loss)
I1123 22:10:27.943799 12543 sgd_solver.cpp:106] Iteration 13400, lr = 0.002
I1123 22:10:28.626502 12543 solver.cpp:340] Iteration 13500, Testing net (#0)
I1123 22:10:28.822484 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9913
I1123 22:10:28.822513 12543 solver.cpp:408]     Test net output #1: loss = 0.0536754 (* 1 = 0.0536754 loss)
I1123 22:10:28.824463 12543 solver.cpp:236] Iteration 13500, loss = 0.0546024
I1123 22:10:28.824479 12543 solver.cpp:252]     Train net output #0: loss = 0.0631504 (* 1 = 0.0631504 loss)
I1123 22:10:28.824487 12543 sgd_solver.cpp:106] Iteration 13500, lr = 0.002
I1123 22:10:29.508005 12543 solver.cpp:236] Iteration 13600, loss = 0.058073
I1123 22:10:29.508034 12543 solver.cpp:252]     Train net output #0: loss = 0.0531958 (* 1 = 0.0531958 loss)
I1123 22:10:29.508040 12543 sgd_solver.cpp:106] Iteration 13600, lr = 0.002
I1123 22:10:30.213618 12543 solver.cpp:236] Iteration 13700, loss = 0.0803365
I1123 22:10:30.213649 12543 solver.cpp:252]     Train net output #0: loss = 0.257114 (* 1 = 0.257114 loss)
I1123 22:10:30.213654 12543 sgd_solver.cpp:106] Iteration 13700, lr = 0.002
I1123 22:10:30.917986 12543 solver.cpp:236] Iteration 13800, loss = 0.0630593
I1123 22:10:30.918018 12543 solver.cpp:252]     Train net output #0: loss = 0.00262593 (* 1 = 0.00262593 loss)
I1123 22:10:30.918026 12543 sgd_solver.cpp:106] Iteration 13800, lr = 0.002
I1123 22:10:31.596690 12543 solver.cpp:236] Iteration 13900, loss = 0.0719684
I1123 22:10:31.596719 12543 solver.cpp:252]     Train net output #0: loss = 0.0579716 (* 1 = 0.0579716 loss)
I1123 22:10:31.596725 12543 sgd_solver.cpp:106] Iteration 13900, lr = 0.002
I1123 22:10:32.259270 12543 solver.cpp:340] Iteration 14000, Testing net (#0)
I1123 22:10:32.449035 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9903
I1123 22:10:32.449062 12543 solver.cpp:408]     Test net output #1: loss = 0.0611147 (* 1 = 0.0611147 loss)
I1123 22:10:32.450965 12543 solver.cpp:236] Iteration 14000, loss = 0.0631014
I1123 22:10:32.450985 12543 solver.cpp:252]     Train net output #0: loss = 0.117467 (* 1 = 0.117467 loss)
I1123 22:10:32.450994 12543 sgd_solver.cpp:106] Iteration 14000, lr = 0.002
I1123 22:10:33.120491 12543 solver.cpp:236] Iteration 14100, loss = 0.072942
I1123 22:10:33.120520 12543 solver.cpp:252]     Train net output #0: loss = 0.199984 (* 1 = 0.199984 loss)
I1123 22:10:33.120525 12543 sgd_solver.cpp:106] Iteration 14100, lr = 0.002
I1123 22:10:33.790747 12543 solver.cpp:236] Iteration 14200, loss = 0.0813917
I1123 22:10:33.790776 12543 solver.cpp:252]     Train net output #0: loss = 0.120424 (* 1 = 0.120424 loss)
I1123 22:10:33.790781 12543 sgd_solver.cpp:106] Iteration 14200, lr = 0.002
I1123 22:10:34.460403 12543 solver.cpp:236] Iteration 14300, loss = 0.0474622
I1123 22:10:34.460433 12543 solver.cpp:252]     Train net output #0: loss = 0.0361248 (* 1 = 0.0361248 loss)
I1123 22:10:34.460438 12543 sgd_solver.cpp:106] Iteration 14300, lr = 0.002
I1123 22:10:35.144459 12543 solver.cpp:236] Iteration 14400, loss = 0.0699776
I1123 22:10:35.144487 12543 solver.cpp:252]     Train net output #0: loss = 0.00479582 (* 1 = 0.00479582 loss)
I1123 22:10:35.144495 12543 sgd_solver.cpp:106] Iteration 14400, lr = 0.002
I1123 22:10:35.806668 12543 solver.cpp:340] Iteration 14500, Testing net (#0)
I1123 22:10:35.997889 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9929
I1123 22:10:35.997915 12543 solver.cpp:408]     Test net output #1: loss = 0.0483155 (* 1 = 0.0483155 loss)
I1123 22:10:35.999836 12543 solver.cpp:236] Iteration 14500, loss = 0.0727441
I1123 22:10:35.999852 12543 solver.cpp:252]     Train net output #0: loss = 0.00883455 (* 1 = 0.00883455 loss)
I1123 22:10:35.999861 12543 sgd_solver.cpp:106] Iteration 14500, lr = 0.002
I1123 22:10:36.673372 12543 solver.cpp:236] Iteration 14600, loss = 0.0659243
I1123 22:10:36.673400 12543 solver.cpp:252]     Train net output #0: loss = 0.0638423 (* 1 = 0.0638423 loss)
I1123 22:10:36.673404 12543 sgd_solver.cpp:106] Iteration 14600, lr = 0.002
I1123 22:10:37.345505 12543 solver.cpp:236] Iteration 14700, loss = 0.0721492
I1123 22:10:37.345535 12543 solver.cpp:252]     Train net output #0: loss = 0.0340999 (* 1 = 0.0340999 loss)
I1123 22:10:37.345538 12543 sgd_solver.cpp:106] Iteration 14700, lr = 0.002
I1123 22:10:38.016726 12543 solver.cpp:236] Iteration 14800, loss = 0.0766923
I1123 22:10:38.016753 12543 solver.cpp:252]     Train net output #0: loss = 0.114345 (* 1 = 0.114345 loss)
I1123 22:10:38.016757 12543 sgd_solver.cpp:106] Iteration 14800, lr = 0.002
I1123 22:10:38.683493 12543 solver.cpp:236] Iteration 14900, loss = 0.0621935
I1123 22:10:38.683521 12543 solver.cpp:252]     Train net output #0: loss = 0.119366 (* 1 = 0.119366 loss)
I1123 22:10:38.683526 12543 sgd_solver.cpp:106] Iteration 14900, lr = 0.002
I1123 22:10:39.344120 12543 solver.cpp:340] Iteration 15000, Testing net (#0)
I1123 22:10:39.533965 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9923
I1123 22:10:39.533992 12543 solver.cpp:408]     Test net output #1: loss = 0.0519024 (* 1 = 0.0519024 loss)
I1123 22:10:39.535897 12543 solver.cpp:236] Iteration 15000, loss = 0.0433793
I1123 22:10:39.535915 12543 solver.cpp:252]     Train net output #0: loss = 0.0679638 (* 1 = 0.0679638 loss)
I1123 22:10:39.535923 12543 sgd_solver.cpp:106] Iteration 15000, lr = 0.0002
I1123 22:10:40.209697 12543 solver.cpp:236] Iteration 15100, loss = 0.0598909
I1123 22:10:40.209727 12543 solver.cpp:252]     Train net output #0: loss = 0.0571524 (* 1 = 0.0571524 loss)
I1123 22:10:40.209733 12543 sgd_solver.cpp:106] Iteration 15100, lr = 0.0002
I1123 22:10:40.875538 12543 solver.cpp:236] Iteration 15200, loss = 0.0396162
I1123 22:10:40.875567 12543 solver.cpp:252]     Train net output #0: loss = 0.0478339 (* 1 = 0.0478339 loss)
I1123 22:10:40.875573 12543 sgd_solver.cpp:106] Iteration 15200, lr = 0.0002
I1123 22:10:41.548282 12543 solver.cpp:236] Iteration 15300, loss = 0.0359416
I1123 22:10:41.548312 12543 solver.cpp:252]     Train net output #0: loss = 0.00374555 (* 1 = 0.00374555 loss)
I1123 22:10:41.548318 12543 sgd_solver.cpp:106] Iteration 15300, lr = 0.0002
I1123 22:10:42.220438 12543 solver.cpp:236] Iteration 15400, loss = 0.0328923
I1123 22:10:42.220468 12543 solver.cpp:252]     Train net output #0: loss = 0.00425322 (* 1 = 0.00425322 loss)
I1123 22:10:42.220475 12543 sgd_solver.cpp:106] Iteration 15400, lr = 0.0002
I1123 22:10:42.887130 12543 solver.cpp:340] Iteration 15500, Testing net (#0)
I1123 22:10:43.079617 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9944
I1123 22:10:43.079660 12543 solver.cpp:408]     Test net output #1: loss = 0.0336682 (* 1 = 0.0336682 loss)
I1123 22:10:43.081506 12543 solver.cpp:236] Iteration 15500, loss = 0.0298991
I1123 22:10:43.081521 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:10:43.081529 12543 sgd_solver.cpp:106] Iteration 15500, lr = 0.0002
I1123 22:10:43.748648 12543 solver.cpp:236] Iteration 15600, loss = 0.029321
I1123 22:10:43.748677 12543 solver.cpp:252]     Train net output #0: loss = 0.00122103 (* 1 = 0.00122103 loss)
I1123 22:10:43.748680 12543 sgd_solver.cpp:106] Iteration 15600, lr = 0.0002
I1123 22:10:44.416291 12543 solver.cpp:236] Iteration 15700, loss = 0.0250283
I1123 22:10:44.416317 12543 solver.cpp:252]     Train net output #0: loss = 0.0123507 (* 1 = 0.0123507 loss)
I1123 22:10:44.416322 12543 sgd_solver.cpp:106] Iteration 15700, lr = 0.0002
I1123 22:10:45.085896 12543 solver.cpp:236] Iteration 15800, loss = 0.0271638
I1123 22:10:45.085924 12543 solver.cpp:252]     Train net output #0: loss = 0.219556 (* 1 = 0.219556 loss)
I1123 22:10:45.085928 12543 sgd_solver.cpp:106] Iteration 15800, lr = 0.0002
I1123 22:10:45.758527 12543 solver.cpp:236] Iteration 15900, loss = 0.0187985
I1123 22:10:45.758554 12543 solver.cpp:252]     Train net output #0: loss = 0.0935235 (* 1 = 0.0935235 loss)
I1123 22:10:45.758558 12543 sgd_solver.cpp:106] Iteration 15900, lr = 0.0002
I1123 22:10:46.422444 12543 solver.cpp:340] Iteration 16000, Testing net (#0)
I1123 22:10:46.610497 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:10:46.610524 12543 solver.cpp:408]     Test net output #1: loss = 0.0308751 (* 1 = 0.0308751 loss)
I1123 22:10:46.612417 12543 solver.cpp:236] Iteration 16000, loss = 0.0298139
I1123 22:10:46.612431 12543 solver.cpp:252]     Train net output #0: loss = 0.0632592 (* 1 = 0.0632592 loss)
I1123 22:10:46.612435 12543 sgd_solver.cpp:106] Iteration 16000, lr = 0.0002
I1123 22:10:47.281339 12543 solver.cpp:236] Iteration 16100, loss = 0.031461
I1123 22:10:47.281366 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:10:47.281371 12543 sgd_solver.cpp:106] Iteration 16100, lr = 0.0002
I1123 22:10:47.951930 12543 solver.cpp:236] Iteration 16200, loss = 0.023897
I1123 22:10:47.951959 12543 solver.cpp:252]     Train net output #0: loss = 0.00203597 (* 1 = 0.00203597 loss)
I1123 22:10:47.951964 12543 sgd_solver.cpp:106] Iteration 16200, lr = 0.0002
I1123 22:10:48.623543 12543 solver.cpp:236] Iteration 16300, loss = 0.0267954
I1123 22:10:48.623579 12543 solver.cpp:252]     Train net output #0: loss = 0.00374486 (* 1 = 0.00374486 loss)
I1123 22:10:48.623585 12543 sgd_solver.cpp:106] Iteration 16300, lr = 0.0002
I1123 22:10:49.292587 12543 solver.cpp:236] Iteration 16400, loss = 0.0248358
I1123 22:10:49.292616 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:10:49.292623 12543 sgd_solver.cpp:106] Iteration 16400, lr = 0.0002
I1123 22:10:49.952131 12543 solver.cpp:340] Iteration 16500, Testing net (#0)
I1123 22:10:50.143872 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9961
I1123 22:10:50.143899 12543 solver.cpp:408]     Test net output #1: loss = 0.0283389 (* 1 = 0.0283389 loss)
I1123 22:10:50.145831 12543 solver.cpp:236] Iteration 16500, loss = 0.0283405
I1123 22:10:50.145846 12543 solver.cpp:252]     Train net output #0: loss = 0.0101907 (* 1 = 0.0101907 loss)
I1123 22:10:50.145854 12543 sgd_solver.cpp:106] Iteration 16500, lr = 0.0002
I1123 22:10:50.818210 12543 solver.cpp:236] Iteration 16600, loss = 0.0221181
I1123 22:10:50.818238 12543 solver.cpp:252]     Train net output #0: loss = 0.0399597 (* 1 = 0.0399597 loss)
I1123 22:10:50.818244 12543 sgd_solver.cpp:106] Iteration 16600, lr = 0.0002
I1123 22:10:51.491396 12543 solver.cpp:236] Iteration 16700, loss = 0.0199945
I1123 22:10:51.491426 12543 solver.cpp:252]     Train net output #0: loss = 0.00295819 (* 1 = 0.00295819 loss)
I1123 22:10:51.491432 12543 sgd_solver.cpp:106] Iteration 16700, lr = 0.0002
I1123 22:10:52.165802 12543 solver.cpp:236] Iteration 16800, loss = 0.0301118
I1123 22:10:52.165830 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:10:52.165837 12543 sgd_solver.cpp:106] Iteration 16800, lr = 0.0002
I1123 22:10:52.832062 12543 solver.cpp:236] Iteration 16900, loss = 0.0229713
I1123 22:10:52.832092 12543 solver.cpp:252]     Train net output #0: loss = 0.110227 (* 1 = 0.110227 loss)
I1123 22:10:52.832098 12543 sgd_solver.cpp:106] Iteration 16900, lr = 0.0002
I1123 22:10:53.493892 12543 solver.cpp:340] Iteration 17000, Testing net (#0)
I1123 22:10:53.683125 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:10:53.683154 12543 solver.cpp:408]     Test net output #1: loss = 0.0289999 (* 1 = 0.0289999 loss)
I1123 22:10:53.685066 12543 solver.cpp:236] Iteration 17000, loss = 0.0327295
I1123 22:10:53.685082 12543 solver.cpp:252]     Train net output #0: loss = 0.0312254 (* 1 = 0.0312254 loss)
I1123 22:10:53.685091 12543 sgd_solver.cpp:106] Iteration 17000, lr = 0.0002
I1123 22:10:54.355051 12543 solver.cpp:236] Iteration 17100, loss = 0.0213018
I1123 22:10:54.355082 12543 solver.cpp:252]     Train net output #0: loss = 0.00168401 (* 1 = 0.00168401 loss)
I1123 22:10:54.355089 12543 sgd_solver.cpp:106] Iteration 17100, lr = 0.0002
I1123 22:10:55.022867 12543 solver.cpp:236] Iteration 17200, loss = 0.0264996
I1123 22:10:55.022961 12543 solver.cpp:252]     Train net output #0: loss = 0.00811338 (* 1 = 0.00811338 loss)
I1123 22:10:55.022969 12543 sgd_solver.cpp:106] Iteration 17200, lr = 0.0002
I1123 22:10:55.693109 12543 solver.cpp:236] Iteration 17300, loss = 0.0383486
I1123 22:10:55.693137 12543 solver.cpp:252]     Train net output #0: loss = 0.00332463 (* 1 = 0.00332463 loss)
I1123 22:10:55.693143 12543 sgd_solver.cpp:106] Iteration 17300, lr = 0.0002
I1123 22:10:56.360924 12543 solver.cpp:236] Iteration 17400, loss = 0.0274058
I1123 22:10:56.360954 12543 solver.cpp:252]     Train net output #0: loss = 0.00437875 (* 1 = 0.00437875 loss)
I1123 22:10:56.360961 12543 sgd_solver.cpp:106] Iteration 17400, lr = 0.0002
I1123 22:10:57.021287 12543 solver.cpp:340] Iteration 17500, Testing net (#0)
I1123 22:10:57.211606 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9953
I1123 22:10:57.211633 12543 solver.cpp:408]     Test net output #1: loss = 0.0315407 (* 1 = 0.0315407 loss)
I1123 22:10:57.213551 12543 solver.cpp:236] Iteration 17500, loss = 0.0194782
I1123 22:10:57.213565 12543 solver.cpp:252]     Train net output #0: loss = 0.00264317 (* 1 = 0.00264317 loss)
I1123 22:10:57.213573 12543 sgd_solver.cpp:106] Iteration 17500, lr = 0.0002
I1123 22:10:57.883661 12543 solver.cpp:236] Iteration 17600, loss = 0.0222486
I1123 22:10:57.883690 12543 solver.cpp:252]     Train net output #0: loss = 0.0720621 (* 1 = 0.0720621 loss)
I1123 22:10:57.883697 12543 sgd_solver.cpp:106] Iteration 17600, lr = 0.0002
I1123 22:10:58.556278 12543 solver.cpp:236] Iteration 17700, loss = 0.0211497
I1123 22:10:58.556306 12543 solver.cpp:252]     Train net output #0: loss = 0.0218298 (* 1 = 0.0218298 loss)
I1123 22:10:58.556313 12543 sgd_solver.cpp:106] Iteration 17700, lr = 0.0002
I1123 22:10:59.221592 12543 solver.cpp:236] Iteration 17800, loss = 0.00763168
I1123 22:10:59.221621 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:10:59.221627 12543 sgd_solver.cpp:106] Iteration 17800, lr = 0.0002
I1123 22:10:59.888376 12543 solver.cpp:236] Iteration 17900, loss = 0.0190718
I1123 22:10:59.888406 12543 solver.cpp:252]     Train net output #0: loss = 0.0400945 (* 1 = 0.0400945 loss)
I1123 22:10:59.888411 12543 sgd_solver.cpp:106] Iteration 17900, lr = 0.0002
I1123 22:11:00.552654 12543 solver.cpp:340] Iteration 18000, Testing net (#0)
I1123 22:11:00.741421 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9946
I1123 22:11:00.741451 12543 solver.cpp:408]     Test net output #1: loss = 0.0310776 (* 1 = 0.0310776 loss)
I1123 22:11:00.743357 12543 solver.cpp:236] Iteration 18000, loss = 0.0219555
I1123 22:11:00.743372 12543 solver.cpp:252]     Train net output #0: loss = 0.00980271 (* 1 = 0.00980271 loss)
I1123 22:11:00.743379 12543 sgd_solver.cpp:106] Iteration 18000, lr = 0.0002
I1123 22:11:01.412991 12543 solver.cpp:236] Iteration 18100, loss = 0.0260624
I1123 22:11:01.413023 12543 solver.cpp:252]     Train net output #0: loss = 0.00632446 (* 1 = 0.00632446 loss)
I1123 22:11:01.413030 12543 sgd_solver.cpp:106] Iteration 18100, lr = 0.0002
I1123 22:11:02.078737 12543 solver.cpp:236] Iteration 18200, loss = 0.0246137
I1123 22:11:02.078766 12543 solver.cpp:252]     Train net output #0: loss = 0.00416782 (* 1 = 0.00416782 loss)
I1123 22:11:02.078773 12543 sgd_solver.cpp:106] Iteration 18200, lr = 0.0002
I1123 22:11:02.749161 12543 solver.cpp:236] Iteration 18300, loss = 0.0179976
I1123 22:11:02.749193 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:02.749202 12543 sgd_solver.cpp:106] Iteration 18300, lr = 0.0002
I1123 22:11:03.413131 12543 solver.cpp:236] Iteration 18400, loss = 0.0230664
I1123 22:11:03.413161 12543 solver.cpp:252]     Train net output #0: loss = 0.00572485 (* 1 = 0.00572485 loss)
I1123 22:11:03.413166 12543 sgd_solver.cpp:106] Iteration 18400, lr = 0.0002
I1123 22:11:04.076720 12543 solver.cpp:340] Iteration 18500, Testing net (#0)
I1123 22:11:04.264739 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9947
I1123 22:11:04.264767 12543 solver.cpp:408]     Test net output #1: loss = 0.0314929 (* 1 = 0.0314929 loss)
I1123 22:11:04.266672 12543 solver.cpp:236] Iteration 18500, loss = 0.0228309
I1123 22:11:04.266687 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:04.266695 12543 sgd_solver.cpp:106] Iteration 18500, lr = 0.0002
I1123 22:11:04.935585 12543 solver.cpp:236] Iteration 18600, loss = 0.0123514
I1123 22:11:04.935612 12543 solver.cpp:252]     Train net output #0: loss = 0.0807476 (* 1 = 0.0807476 loss)
I1123 22:11:04.935616 12543 sgd_solver.cpp:106] Iteration 18600, lr = 0.0002
I1123 22:11:05.606102 12543 solver.cpp:236] Iteration 18700, loss = 0.0201846
I1123 22:11:05.606130 12543 solver.cpp:252]     Train net output #0: loss = 0.0293261 (* 1 = 0.0293261 loss)
I1123 22:11:05.606134 12543 sgd_solver.cpp:106] Iteration 18700, lr = 0.0002
I1123 22:11:06.275851 12543 solver.cpp:236] Iteration 18800, loss = 0.0169406
I1123 22:11:06.275882 12543 solver.cpp:252]     Train net output #0: loss = 0.00898338 (* 1 = 0.00898338 loss)
I1123 22:11:06.275887 12543 sgd_solver.cpp:106] Iteration 18800, lr = 0.0002
I1123 22:11:06.939682 12543 solver.cpp:236] Iteration 18900, loss = 0.0222405
I1123 22:11:06.939713 12543 solver.cpp:252]     Train net output #0: loss = 0.0198258 (* 1 = 0.0198258 loss)
I1123 22:11:06.939718 12543 sgd_solver.cpp:106] Iteration 18900, lr = 0.0002
I1123 22:11:07.602730 12543 solver.cpp:340] Iteration 19000, Testing net (#0)
I1123 22:11:07.791429 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:11:07.791456 12543 solver.cpp:408]     Test net output #1: loss = 0.0294732 (* 1 = 0.0294732 loss)
I1123 22:11:07.793365 12543 solver.cpp:236] Iteration 19000, loss = 0.0166756
I1123 22:11:07.793380 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:07.793386 12543 sgd_solver.cpp:106] Iteration 19000, lr = 0.0002
I1123 22:11:08.456495 12543 solver.cpp:236] Iteration 19100, loss = 0.0162756
I1123 22:11:08.456522 12543 solver.cpp:252]     Train net output #0: loss = 0.00686183 (* 1 = 0.00686183 loss)
I1123 22:11:08.456526 12543 sgd_solver.cpp:106] Iteration 19100, lr = 0.0002
I1123 22:11:09.126173 12543 solver.cpp:236] Iteration 19200, loss = 0.0336473
I1123 22:11:09.126202 12543 solver.cpp:252]     Train net output #0: loss = 0.00409696 (* 1 = 0.00409696 loss)
I1123 22:11:09.126206 12543 sgd_solver.cpp:106] Iteration 19200, lr = 0.0002
I1123 22:11:09.791121 12543 solver.cpp:236] Iteration 19300, loss = 0.0205698
I1123 22:11:09.791148 12543 solver.cpp:252]     Train net output #0: loss = 0.0580098 (* 1 = 0.0580098 loss)
I1123 22:11:09.791153 12543 sgd_solver.cpp:106] Iteration 19300, lr = 0.0002
I1123 22:11:10.453862 12543 solver.cpp:236] Iteration 19400, loss = 0.0209767
I1123 22:11:10.453889 12543 solver.cpp:252]     Train net output #0: loss = 0.00910928 (* 1 = 0.00910928 loss)
I1123 22:11:10.453893 12543 sgd_solver.cpp:106] Iteration 19400, lr = 0.0002
I1123 22:11:11.115304 12543 solver.cpp:340] Iteration 19500, Testing net (#0)
I1123 22:11:11.305160 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9954
I1123 22:11:11.305186 12543 solver.cpp:408]     Test net output #1: loss = 0.0298289 (* 1 = 0.0298289 loss)
I1123 22:11:11.307049 12543 solver.cpp:236] Iteration 19500, loss = 0.0241675
I1123 22:11:11.307061 12543 solver.cpp:252]     Train net output #0: loss = 0.00754668 (* 1 = 0.00754668 loss)
I1123 22:11:11.307066 12543 sgd_solver.cpp:106] Iteration 19500, lr = 0.0002
I1123 22:11:11.980990 12543 solver.cpp:236] Iteration 19600, loss = 0.0250347
I1123 22:11:11.981022 12543 solver.cpp:252]     Train net output #0: loss = 0.0551809 (* 1 = 0.0551809 loss)
I1123 22:11:11.981027 12543 sgd_solver.cpp:106] Iteration 19600, lr = 0.0002
I1123 22:11:12.657107 12543 solver.cpp:236] Iteration 19700, loss = 0.0145553
I1123 22:11:12.657135 12543 solver.cpp:252]     Train net output #0: loss = 0.00615356 (* 1 = 0.00615356 loss)
I1123 22:11:12.657140 12543 sgd_solver.cpp:106] Iteration 19700, lr = 0.0002
I1123 22:11:13.326750 12543 solver.cpp:236] Iteration 19800, loss = 0.0238225
I1123 22:11:13.326778 12543 solver.cpp:252]     Train net output #0: loss = 0.0109284 (* 1 = 0.0109284 loss)
I1123 22:11:13.326798 12543 sgd_solver.cpp:106] Iteration 19800, lr = 0.0002
I1123 22:11:13.999660 12543 solver.cpp:236] Iteration 19900, loss = 0.0162839
I1123 22:11:13.999686 12543 solver.cpp:252]     Train net output #0: loss = 0.016759 (* 1 = 0.016759 loss)
I1123 22:11:13.999691 12543 sgd_solver.cpp:106] Iteration 19900, lr = 0.0002
I1123 22:11:14.668500 12543 solver.cpp:340] Iteration 20000, Testing net (#0)
I1123 22:11:14.858989 12543 solver.cpp:408]     Test net output #0: accuracy = 0.995
I1123 22:11:14.859015 12543 solver.cpp:408]     Test net output #1: loss = 0.029929 (* 1 = 0.029929 loss)
I1123 22:11:14.860908 12543 solver.cpp:236] Iteration 20000, loss = 0.0191566
I1123 22:11:14.860920 12543 solver.cpp:252]     Train net output #0: loss = 0.0257602 (* 1 = 0.0257602 loss)
I1123 22:11:14.860925 12543 sgd_solver.cpp:106] Iteration 20000, lr = 0.0002
I1123 22:11:15.534268 12543 solver.cpp:236] Iteration 20100, loss = 0.0186028
I1123 22:11:15.534296 12543 solver.cpp:252]     Train net output #0: loss = 0.0271407 (* 1 = 0.0271407 loss)
I1123 22:11:15.534301 12543 sgd_solver.cpp:106] Iteration 20100, lr = 0.0002
I1123 22:11:16.206476 12543 solver.cpp:236] Iteration 20200, loss = 0.0222135
I1123 22:11:16.206503 12543 solver.cpp:252]     Train net output #0: loss = 0.0202172 (* 1 = 0.0202172 loss)
I1123 22:11:16.206508 12543 sgd_solver.cpp:106] Iteration 20200, lr = 0.0002
I1123 22:11:16.880458 12543 solver.cpp:236] Iteration 20300, loss = 0.0177279
I1123 22:11:16.880484 12543 solver.cpp:252]     Train net output #0: loss = 0.00225557 (* 1 = 0.00225557 loss)
I1123 22:11:16.880489 12543 sgd_solver.cpp:106] Iteration 20300, lr = 0.0002
I1123 22:11:17.549800 12543 solver.cpp:236] Iteration 20400, loss = 0.0142333
I1123 22:11:17.549829 12543 solver.cpp:252]     Train net output #0: loss = 0.0175026 (* 1 = 0.0175026 loss)
I1123 22:11:17.549834 12543 sgd_solver.cpp:106] Iteration 20400, lr = 0.0002
I1123 22:11:18.223871 12543 solver.cpp:340] Iteration 20500, Testing net (#0)
I1123 22:11:18.414592 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9952
I1123 22:11:18.414618 12543 solver.cpp:408]     Test net output #1: loss = 0.0286873 (* 1 = 0.0286873 loss)
I1123 22:11:18.416519 12543 solver.cpp:236] Iteration 20500, loss = 0.0189347
I1123 22:11:18.416532 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:18.416538 12543 sgd_solver.cpp:106] Iteration 20500, lr = 0.0002
I1123 22:11:19.091740 12543 solver.cpp:236] Iteration 20600, loss = 0.0145327
I1123 22:11:19.091768 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:19.091771 12543 sgd_solver.cpp:106] Iteration 20600, lr = 0.0002
I1123 22:11:19.766075 12543 solver.cpp:236] Iteration 20700, loss = 0.017155
I1123 22:11:19.766103 12543 solver.cpp:252]     Train net output #0: loss = 0.0271418 (* 1 = 0.0271418 loss)
I1123 22:11:19.766108 12543 sgd_solver.cpp:106] Iteration 20700, lr = 0.0002
I1123 22:11:20.443647 12543 solver.cpp:236] Iteration 20800, loss = 0.0227026
I1123 22:11:20.443675 12543 solver.cpp:252]     Train net output #0: loss = 0.0324725 (* 1 = 0.0324725 loss)
I1123 22:11:20.443680 12543 sgd_solver.cpp:106] Iteration 20800, lr = 0.0002
I1123 22:11:21.120537 12543 solver.cpp:236] Iteration 20900, loss = 0.0164409
I1123 22:11:21.120563 12543 solver.cpp:252]     Train net output #0: loss = 0.011242 (* 1 = 0.011242 loss)
I1123 22:11:21.120568 12543 sgd_solver.cpp:106] Iteration 20900, lr = 0.0002
I1123 22:11:21.789407 12543 solver.cpp:340] Iteration 21000, Testing net (#0)
I1123 22:11:21.979171 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9951
I1123 22:11:21.979197 12543 solver.cpp:408]     Test net output #1: loss = 0.029368 (* 1 = 0.029368 loss)
I1123 22:11:21.981097 12543 solver.cpp:236] Iteration 21000, loss = 0.0179528
I1123 22:11:21.981111 12543 solver.cpp:252]     Train net output #0: loss = 0.0180819 (* 1 = 0.0180819 loss)
I1123 22:11:21.981115 12543 sgd_solver.cpp:106] Iteration 21000, lr = 0.0002
I1123 22:11:22.653563 12543 solver.cpp:236] Iteration 21100, loss = 0.0139837
I1123 22:11:22.653590 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:22.653594 12543 sgd_solver.cpp:106] Iteration 21100, lr = 0.0002
I1123 22:11:23.328814 12543 solver.cpp:236] Iteration 21200, loss = 0.0270459
I1123 22:11:23.328843 12543 solver.cpp:252]     Train net output #0: loss = 0.0289647 (* 1 = 0.0289647 loss)
I1123 22:11:23.328850 12543 sgd_solver.cpp:106] Iteration 21200, lr = 0.0002
I1123 22:11:24.005476 12543 solver.cpp:236] Iteration 21300, loss = 0.0178127
I1123 22:11:24.005506 12543 solver.cpp:252]     Train net output #0: loss = 0.0218673 (* 1 = 0.0218673 loss)
I1123 22:11:24.005511 12543 sgd_solver.cpp:106] Iteration 21300, lr = 0.0002
I1123 22:11:24.679039 12543 solver.cpp:236] Iteration 21400, loss = 0.0164755
I1123 22:11:24.679069 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:24.679075 12543 sgd_solver.cpp:106] Iteration 21400, lr = 0.0002
I1123 22:11:25.341949 12543 solver.cpp:340] Iteration 21500, Testing net (#0)
I1123 22:11:25.533212 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:11:25.533238 12543 solver.cpp:408]     Test net output #1: loss = 0.0282948 (* 1 = 0.0282948 loss)
I1123 22:11:25.535148 12543 solver.cpp:236] Iteration 21500, loss = 0.0175911
I1123 22:11:25.535162 12543 solver.cpp:252]     Train net output #0: loss = 0.0441472 (* 1 = 0.0441472 loss)
I1123 22:11:25.535171 12543 sgd_solver.cpp:106] Iteration 21500, lr = 0.0002
I1123 22:11:26.209686 12543 solver.cpp:236] Iteration 21600, loss = 0.0231941
I1123 22:11:26.209713 12543 solver.cpp:252]     Train net output #0: loss = 0.0811515 (* 1 = 0.0811515 loss)
I1123 22:11:26.209717 12543 sgd_solver.cpp:106] Iteration 21600, lr = 0.0002
I1123 22:11:26.882848 12543 solver.cpp:236] Iteration 21700, loss = 0.0216837
I1123 22:11:26.882874 12543 solver.cpp:252]     Train net output #0: loss = 0.0238524 (* 1 = 0.0238524 loss)
I1123 22:11:26.882879 12543 sgd_solver.cpp:106] Iteration 21700, lr = 0.0002
I1123 22:11:27.555982 12543 solver.cpp:236] Iteration 21800, loss = 0.0141965
I1123 22:11:27.556008 12543 solver.cpp:252]     Train net output #0: loss = 0.0121125 (* 1 = 0.0121125 loss)
I1123 22:11:27.556012 12543 sgd_solver.cpp:106] Iteration 21800, lr = 0.0002
I1123 22:11:28.229466 12543 solver.cpp:236] Iteration 21900, loss = 0.0157887
I1123 22:11:28.229495 12543 solver.cpp:252]     Train net output #0: loss = 0.0128607 (* 1 = 0.0128607 loss)
I1123 22:11:28.229498 12543 sgd_solver.cpp:106] Iteration 21900, lr = 0.0002
I1123 22:11:28.896687 12543 solver.cpp:340] Iteration 22000, Testing net (#0)
I1123 22:11:29.087620 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9955
I1123 22:11:29.087646 12543 solver.cpp:408]     Test net output #1: loss = 0.0276561 (* 1 = 0.0276561 loss)
I1123 22:11:29.089552 12543 solver.cpp:236] Iteration 22000, loss = 0.0287124
I1123 22:11:29.089565 12543 solver.cpp:252]     Train net output #0: loss = 0.000715237 (* 1 = 0.000715237 loss)
I1123 22:11:29.089571 12543 sgd_solver.cpp:106] Iteration 22000, lr = 0.0002
I1123 22:11:29.763859 12543 solver.cpp:236] Iteration 22100, loss = 0.0187056
I1123 22:11:29.763886 12543 solver.cpp:252]     Train net output #0: loss = 0.0973073 (* 1 = 0.0973073 loss)
I1123 22:11:29.763891 12543 sgd_solver.cpp:106] Iteration 22100, lr = 0.0002
I1123 22:11:30.434464 12543 solver.cpp:236] Iteration 22200, loss = 0.0173243
I1123 22:11:30.434491 12543 solver.cpp:252]     Train net output #0: loss = 0.0207911 (* 1 = 0.0207911 loss)
I1123 22:11:30.434495 12543 sgd_solver.cpp:106] Iteration 22200, lr = 0.0002
I1123 22:11:31.112334 12543 solver.cpp:236] Iteration 22300, loss = 0.0179461
I1123 22:11:31.112361 12543 solver.cpp:252]     Train net output #0: loss = 0.0471685 (* 1 = 0.0471685 loss)
I1123 22:11:31.112365 12543 sgd_solver.cpp:106] Iteration 22300, lr = 0.0002
I1123 22:11:31.782905 12543 solver.cpp:236] Iteration 22400, loss = 0.0209976
I1123 22:11:31.782932 12543 solver.cpp:252]     Train net output #0: loss = 0.0481511 (* 1 = 0.0481511 loss)
I1123 22:11:31.782937 12543 sgd_solver.cpp:106] Iteration 22400, lr = 0.0002
I1123 22:11:32.448132 12543 solver.cpp:340] Iteration 22500, Testing net (#0)
I1123 22:11:32.638032 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9954
I1123 22:11:32.638061 12543 solver.cpp:408]     Test net output #1: loss = 0.0278486 (* 1 = 0.0278486 loss)
I1123 22:11:32.639950 12543 solver.cpp:236] Iteration 22500, loss = 0.0158153
I1123 22:11:32.639962 12543 solver.cpp:252]     Train net output #0: loss = 0.00724719 (* 1 = 0.00724719 loss)
I1123 22:11:32.639967 12543 sgd_solver.cpp:106] Iteration 22500, lr = 0.0002
I1123 22:11:33.318899 12543 solver.cpp:236] Iteration 22600, loss = 0.0192626
I1123 22:11:33.318928 12543 solver.cpp:252]     Train net output #0: loss = 0.0531795 (* 1 = 0.0531795 loss)
I1123 22:11:33.318931 12543 sgd_solver.cpp:106] Iteration 22600, lr = 0.0002
I1123 22:11:33.993705 12543 solver.cpp:236] Iteration 22700, loss = 0.0148898
I1123 22:11:33.993732 12543 solver.cpp:252]     Train net output #0: loss = 0.0237753 (* 1 = 0.0237753 loss)
I1123 22:11:33.993752 12543 sgd_solver.cpp:106] Iteration 22700, lr = 0.0002
I1123 22:11:34.667716 12543 solver.cpp:236] Iteration 22800, loss = 0.0159949
I1123 22:11:34.667742 12543 solver.cpp:252]     Train net output #0: loss = 0.0374596 (* 1 = 0.0374596 loss)
I1123 22:11:34.667747 12543 sgd_solver.cpp:106] Iteration 22800, lr = 0.0002
I1123 22:11:35.341473 12543 solver.cpp:236] Iteration 22900, loss = 0.014189
I1123 22:11:35.341502 12543 solver.cpp:252]     Train net output #0: loss = 0.0226647 (* 1 = 0.0226647 loss)
I1123 22:11:35.341507 12543 sgd_solver.cpp:106] Iteration 22900, lr = 0.0002
I1123 22:11:36.013470 12543 solver.cpp:340] Iteration 23000, Testing net (#0)
I1123 22:11:36.201609 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9956
I1123 22:11:36.201637 12543 solver.cpp:408]     Test net output #1: loss = 0.0276146 (* 1 = 0.0276146 loss)
I1123 22:11:36.203517 12543 solver.cpp:236] Iteration 23000, loss = 0.0143803
I1123 22:11:36.203531 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:36.203536 12543 sgd_solver.cpp:106] Iteration 23000, lr = 0.0002
I1123 22:11:36.878698 12543 solver.cpp:236] Iteration 23100, loss = 0.0142707
I1123 22:11:36.878727 12543 solver.cpp:252]     Train net output #0: loss = 0.00766772 (* 1 = 0.00766772 loss)
I1123 22:11:36.878731 12543 sgd_solver.cpp:106] Iteration 23100, lr = 0.0002
I1123 22:11:37.551625 12543 solver.cpp:236] Iteration 23200, loss = 0.0148171
I1123 22:11:37.551650 12543 solver.cpp:252]     Train net output #0: loss = 0.0347829 (* 1 = 0.0347829 loss)
I1123 22:11:37.551654 12543 sgd_solver.cpp:106] Iteration 23200, lr = 0.0002
I1123 22:11:38.226398 12543 solver.cpp:236] Iteration 23300, loss = 0.0193119
I1123 22:11:38.226423 12543 solver.cpp:252]     Train net output #0: loss = 0.143385 (* 1 = 0.143385 loss)
I1123 22:11:38.226428 12543 sgd_solver.cpp:106] Iteration 23300, lr = 0.0002
I1123 22:11:38.898284 12543 solver.cpp:236] Iteration 23400, loss = 0.0115127
I1123 22:11:38.898313 12543 solver.cpp:252]     Train net output #0: loss = 0.0023854 (* 1 = 0.0023854 loss)
I1123 22:11:38.898316 12543 sgd_solver.cpp:106] Iteration 23400, lr = 0.0002
I1123 22:11:39.563338 12543 solver.cpp:340] Iteration 23500, Testing net (#0)
I1123 22:11:39.755115 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:11:39.755141 12543 solver.cpp:408]     Test net output #1: loss = 0.0260696 (* 1 = 0.0260696 loss)
I1123 22:11:39.757052 12543 solver.cpp:236] Iteration 23500, loss = 0.0157068
I1123 22:11:39.757068 12543 solver.cpp:252]     Train net output #0: loss = 0.0160048 (* 1 = 0.0160048 loss)
I1123 22:11:39.757076 12543 sgd_solver.cpp:106] Iteration 23500, lr = 0.0002
I1123 22:11:40.438364 12543 solver.cpp:236] Iteration 23600, loss = 0.0152253
I1123 22:11:40.438390 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:40.438395 12543 sgd_solver.cpp:106] Iteration 23600, lr = 0.0002
I1123 22:11:41.119123 12543 solver.cpp:236] Iteration 23700, loss = 0.0124097
I1123 22:11:41.119153 12543 solver.cpp:252]     Train net output #0: loss = 0.0125403 (* 1 = 0.0125403 loss)
I1123 22:11:41.119160 12543 sgd_solver.cpp:106] Iteration 23700, lr = 0.0002
I1123 22:11:41.804651 12543 solver.cpp:236] Iteration 23800, loss = 0.0133908
I1123 22:11:41.804679 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:41.804685 12543 sgd_solver.cpp:106] Iteration 23800, lr = 0.0002
I1123 22:11:42.495512 12543 solver.cpp:236] Iteration 23900, loss = 0.0146528
I1123 22:11:42.495543 12543 solver.cpp:252]     Train net output #0: loss = 0.000214627 (* 1 = 0.000214627 loss)
I1123 22:11:42.495548 12543 sgd_solver.cpp:106] Iteration 23900, lr = 0.0002
I1123 22:11:43.182503 12543 solver.cpp:340] Iteration 24000, Testing net (#0)
I1123 22:11:43.377496 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:11:43.377524 12543 solver.cpp:408]     Test net output #1: loss = 0.0281325 (* 1 = 0.0281325 loss)
I1123 22:11:43.379523 12543 solver.cpp:236] Iteration 24000, loss = 0.0195608
I1123 22:11:43.379566 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:43.379573 12543 sgd_solver.cpp:106] Iteration 24000, lr = 0.0002
I1123 22:11:44.075314 12543 solver.cpp:236] Iteration 24100, loss = 0.0171546
I1123 22:11:44.075342 12543 solver.cpp:252]     Train net output #0: loss = 0.0270608 (* 1 = 0.0270608 loss)
I1123 22:11:44.075346 12543 sgd_solver.cpp:106] Iteration 24100, lr = 0.0002
I1123 22:11:44.770001 12543 solver.cpp:236] Iteration 24200, loss = 0.0145454
I1123 22:11:44.770030 12543 solver.cpp:252]     Train net output #0: loss = 0.00298593 (* 1 = 0.00298593 loss)
I1123 22:11:44.770035 12543 sgd_solver.cpp:106] Iteration 24200, lr = 0.0002
I1123 22:11:45.464224 12543 solver.cpp:236] Iteration 24300, loss = 0.0263152
I1123 22:11:45.464252 12543 solver.cpp:252]     Train net output #0: loss = 0.0069987 (* 1 = 0.0069987 loss)
I1123 22:11:45.464257 12543 sgd_solver.cpp:106] Iteration 24300, lr = 0.0002
I1123 22:11:46.162713 12543 solver.cpp:236] Iteration 24400, loss = 0.0176839
I1123 22:11:46.162739 12543 solver.cpp:252]     Train net output #0: loss = 0.0219611 (* 1 = 0.0219611 loss)
I1123 22:11:46.162744 12543 sgd_solver.cpp:106] Iteration 24400, lr = 0.0002
I1123 22:11:46.851117 12543 solver.cpp:340] Iteration 24500, Testing net (#0)
I1123 22:11:47.045374 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9949
I1123 22:11:47.045402 12543 solver.cpp:408]     Test net output #1: loss = 0.0293472 (* 1 = 0.0293472 loss)
I1123 22:11:47.047363 12543 solver.cpp:236] Iteration 24500, loss = 0.0227246
I1123 22:11:47.047376 12543 solver.cpp:252]     Train net output #0: loss = 0.00128726 (* 1 = 0.00128726 loss)
I1123 22:11:47.047382 12543 sgd_solver.cpp:106] Iteration 24500, lr = 0.0002
I1123 22:11:47.744854 12543 solver.cpp:236] Iteration 24600, loss = 0.0153337
I1123 22:11:47.744884 12543 solver.cpp:252]     Train net output #0: loss = 0.0024236 (* 1 = 0.0024236 loss)
I1123 22:11:47.744889 12543 sgd_solver.cpp:106] Iteration 24600, lr = 0.0002
I1123 22:11:48.439131 12543 solver.cpp:236] Iteration 24700, loss = 0.0142188
I1123 22:11:48.439155 12543 solver.cpp:252]     Train net output #0: loss = 0.0148882 (* 1 = 0.0148882 loss)
I1123 22:11:48.439159 12543 sgd_solver.cpp:106] Iteration 24700, lr = 0.0002
I1123 22:11:49.135800 12543 solver.cpp:236] Iteration 24800, loss = 0.0267706
I1123 22:11:49.135831 12543 solver.cpp:252]     Train net output #0: loss = 0.0144707 (* 1 = 0.0144707 loss)
I1123 22:11:49.135836 12543 sgd_solver.cpp:106] Iteration 24800, lr = 0.0002
I1123 22:11:49.825826 12543 solver.cpp:236] Iteration 24900, loss = 0.0176597
I1123 22:11:49.825855 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:49.825857 12543 sgd_solver.cpp:106] Iteration 24900, lr = 0.0002
I1123 22:11:50.508635 12543 solver.cpp:340] Iteration 25000, Testing net (#0)
I1123 22:11:50.706030 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9953
I1123 22:11:50.706063 12543 solver.cpp:408]     Test net output #1: loss = 0.0292792 (* 1 = 0.0292792 loss)
I1123 22:11:50.708036 12543 solver.cpp:236] Iteration 25000, loss = 0.0157264
I1123 22:11:50.708051 12543 solver.cpp:252]     Train net output #0: loss = 0.00493842 (* 1 = 0.00493842 loss)
I1123 22:11:50.708056 12543 sgd_solver.cpp:106] Iteration 25000, lr = 0.0002
I1123 22:11:51.404629 12543 solver.cpp:236] Iteration 25100, loss = 0.0169369
I1123 22:11:51.404656 12543 solver.cpp:252]     Train net output #0: loss = 0.0270824 (* 1 = 0.0270824 loss)
I1123 22:11:51.404660 12543 sgd_solver.cpp:106] Iteration 25100, lr = 0.0002
I1123 22:11:52.100754 12543 solver.cpp:236] Iteration 25200, loss = 0.0147594
I1123 22:11:52.100781 12543 solver.cpp:252]     Train net output #0: loss = 0.0100103 (* 1 = 0.0100103 loss)
I1123 22:11:52.100785 12543 sgd_solver.cpp:106] Iteration 25200, lr = 0.0002
I1123 22:11:52.792353 12543 solver.cpp:236] Iteration 25300, loss = 0.00486063
I1123 22:11:52.792381 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:52.792384 12543 sgd_solver.cpp:106] Iteration 25300, lr = 0.0002
I1123 22:11:53.484537 12543 solver.cpp:236] Iteration 25400, loss = 0.0145767
I1123 22:11:53.484565 12543 solver.cpp:252]     Train net output #0: loss = 0.0264342 (* 1 = 0.0264342 loss)
I1123 22:11:53.484571 12543 sgd_solver.cpp:106] Iteration 25400, lr = 0.0002
I1123 22:11:54.167755 12543 solver.cpp:340] Iteration 25500, Testing net (#0)
I1123 22:11:54.363034 12543 solver.cpp:408]     Test net output #0: accuracy = 0.995
I1123 22:11:54.363061 12543 solver.cpp:408]     Test net output #1: loss = 0.0313848 (* 1 = 0.0313848 loss)
I1123 22:11:54.365034 12543 solver.cpp:236] Iteration 25500, loss = 0.0176939
I1123 22:11:54.365051 12543 solver.cpp:252]     Train net output #0: loss = 0.0522197 (* 1 = 0.0522197 loss)
I1123 22:11:54.365058 12543 sgd_solver.cpp:106] Iteration 25500, lr = 0.0002
I1123 22:11:55.061856 12543 solver.cpp:236] Iteration 25600, loss = 0.0178883
I1123 22:11:55.061885 12543 solver.cpp:252]     Train net output #0: loss = 0.00544252 (* 1 = 0.00544252 loss)
I1123 22:11:55.061892 12543 sgd_solver.cpp:106] Iteration 25600, lr = 0.0002
I1123 22:11:55.750617 12543 solver.cpp:236] Iteration 25700, loss = 0.0156229
I1123 22:11:55.750715 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:55.750725 12543 sgd_solver.cpp:106] Iteration 25700, lr = 0.0002
I1123 22:11:56.435245 12543 solver.cpp:236] Iteration 25800, loss = 0.0133104
I1123 22:11:56.435272 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:56.435279 12543 sgd_solver.cpp:106] Iteration 25800, lr = 0.0002
I1123 22:11:57.118835 12543 solver.cpp:236] Iteration 25900, loss = 0.0207074
I1123 22:11:57.118865 12543 solver.cpp:252]     Train net output #0: loss = 0.00408232 (* 1 = 0.00408232 loss)
I1123 22:11:57.118870 12543 sgd_solver.cpp:106] Iteration 25900, lr = 0.0002
I1123 22:11:57.795136 12543 solver.cpp:340] Iteration 26000, Testing net (#0)
I1123 22:11:57.987303 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9949
I1123 22:11:57.987331 12543 solver.cpp:408]     Test net output #1: loss = 0.0312555 (* 1 = 0.0312555 loss)
I1123 22:11:57.989253 12543 solver.cpp:236] Iteration 26000, loss = 0.0172049
I1123 22:11:57.989267 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:11:57.989275 12543 sgd_solver.cpp:106] Iteration 26000, lr = 0.0002
I1123 22:11:58.712322 12543 solver.cpp:236] Iteration 26100, loss = 0.0108887
I1123 22:11:58.712352 12543 solver.cpp:252]     Train net output #0: loss = 0.0601797 (* 1 = 0.0601797 loss)
I1123 22:11:58.712359 12543 sgd_solver.cpp:106] Iteration 26100, lr = 0.0002
I1123 22:11:59.441375 12543 solver.cpp:236] Iteration 26200, loss = 0.0158556
I1123 22:11:59.441402 12543 solver.cpp:252]     Train net output #0: loss = 0.00308231 (* 1 = 0.00308231 loss)
I1123 22:11:59.441409 12543 sgd_solver.cpp:106] Iteration 26200, lr = 0.0002
I1123 22:12:00.129997 12543 solver.cpp:236] Iteration 26300, loss = 0.0091867
I1123 22:12:00.130026 12543 solver.cpp:252]     Train net output #0: loss = 0.0242218 (* 1 = 0.0242218 loss)
I1123 22:12:00.130033 12543 sgd_solver.cpp:106] Iteration 26300, lr = 0.0002
I1123 22:12:00.824225 12543 solver.cpp:236] Iteration 26400, loss = 0.0152274
I1123 22:12:00.824254 12543 solver.cpp:252]     Train net output #0: loss = 0.0195854 (* 1 = 0.0195854 loss)
I1123 22:12:00.824259 12543 sgd_solver.cpp:106] Iteration 26400, lr = 0.0002
I1123 22:12:01.498715 12543 solver.cpp:340] Iteration 26500, Testing net (#0)
I1123 22:12:01.691395 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9955
I1123 22:12:01.691424 12543 solver.cpp:408]     Test net output #1: loss = 0.0282387 (* 1 = 0.0282387 loss)
I1123 22:12:01.693361 12543 solver.cpp:236] Iteration 26500, loss = 0.0122229
I1123 22:12:01.693377 12543 solver.cpp:252]     Train net output #0: loss = 0.00927327 (* 1 = 0.00927327 loss)
I1123 22:12:01.693384 12543 sgd_solver.cpp:106] Iteration 26500, lr = 0.0002
I1123 22:12:02.374171 12543 solver.cpp:236] Iteration 26600, loss = 0.0100912
I1123 22:12:02.374199 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:02.374205 12543 sgd_solver.cpp:106] Iteration 26600, lr = 0.0002
I1123 22:12:03.054414 12543 solver.cpp:236] Iteration 26700, loss = 0.0248491
I1123 22:12:03.054440 12543 solver.cpp:252]     Train net output #0: loss = 0.000166776 (* 1 = 0.000166776 loss)
I1123 22:12:03.054446 12543 sgd_solver.cpp:106] Iteration 26700, lr = 0.0002
I1123 22:12:03.742558 12543 solver.cpp:236] Iteration 26800, loss = 0.0149533
I1123 22:12:03.742588 12543 solver.cpp:252]     Train net output #0: loss = 0.0810317 (* 1 = 0.0810317 loss)
I1123 22:12:03.742594 12543 sgd_solver.cpp:106] Iteration 26800, lr = 0.0002
I1123 22:12:04.423471 12543 solver.cpp:236] Iteration 26900, loss = 0.0169073
I1123 22:12:04.423501 12543 solver.cpp:252]     Train net output #0: loss = 0.00551736 (* 1 = 0.00551736 loss)
I1123 22:12:04.423506 12543 sgd_solver.cpp:106] Iteration 26900, lr = 0.0002
I1123 22:12:05.096911 12543 solver.cpp:340] Iteration 27000, Testing net (#0)
I1123 22:12:05.288177 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9954
I1123 22:12:05.288205 12543 solver.cpp:408]     Test net output #1: loss = 0.0292883 (* 1 = 0.0292883 loss)
I1123 22:12:05.290169 12543 solver.cpp:236] Iteration 27000, loss = 0.0156847
I1123 22:12:05.290184 12543 solver.cpp:252]     Train net output #0: loss = 0.00160966 (* 1 = 0.00160966 loss)
I1123 22:12:05.290192 12543 sgd_solver.cpp:106] Iteration 27000, lr = 0.0002
I1123 22:12:05.965860 12543 solver.cpp:236] Iteration 27100, loss = 0.0224781
I1123 22:12:05.965888 12543 solver.cpp:252]     Train net output #0: loss = 0.0544875 (* 1 = 0.0544875 loss)
I1123 22:12:05.965893 12543 sgd_solver.cpp:106] Iteration 27100, lr = 0.0002
I1123 22:12:06.641469 12543 solver.cpp:236] Iteration 27200, loss = 0.0123685
I1123 22:12:06.641496 12543 solver.cpp:252]     Train net output #0: loss = 0.0014014 (* 1 = 0.0014014 loss)
I1123 22:12:06.641502 12543 sgd_solver.cpp:106] Iteration 27200, lr = 0.0002
I1123 22:12:07.315104 12543 solver.cpp:236] Iteration 27300, loss = 0.0164591
I1123 22:12:07.315132 12543 solver.cpp:252]     Train net output #0: loss = 0.0164858 (* 1 = 0.0164858 loss)
I1123 22:12:07.315138 12543 sgd_solver.cpp:106] Iteration 27300, lr = 0.0002
I1123 22:12:07.989717 12543 solver.cpp:236] Iteration 27400, loss = 0.0120412
I1123 22:12:07.989745 12543 solver.cpp:252]     Train net output #0: loss = 0.00927975 (* 1 = 0.00927975 loss)
I1123 22:12:07.989751 12543 sgd_solver.cpp:106] Iteration 27400, lr = 0.0002
I1123 22:12:08.662305 12543 solver.cpp:340] Iteration 27500, Testing net (#0)
I1123 22:12:08.853869 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9949
I1123 22:12:08.853896 12543 solver.cpp:408]     Test net output #1: loss = 0.0305162 (* 1 = 0.0305162 loss)
I1123 22:12:08.855797 12543 solver.cpp:236] Iteration 27500, loss = 0.0154704
I1123 22:12:08.855809 12543 solver.cpp:252]     Train net output #0: loss = 0.0541335 (* 1 = 0.0541335 loss)
I1123 22:12:08.855814 12543 sgd_solver.cpp:106] Iteration 27500, lr = 0.0002
I1123 22:12:09.533778 12543 solver.cpp:236] Iteration 27600, loss = 0.0159459
I1123 22:12:09.533807 12543 solver.cpp:252]     Train net output #0: loss = 0.0494641 (* 1 = 0.0494641 loss)
I1123 22:12:09.533810 12543 sgd_solver.cpp:106] Iteration 27600, lr = 0.0002
I1123 22:12:10.207098 12543 solver.cpp:236] Iteration 27700, loss = 0.0168693
I1123 22:12:10.207125 12543 solver.cpp:252]     Train net output #0: loss = 0.00475122 (* 1 = 0.00475122 loss)
I1123 22:12:10.207129 12543 sgd_solver.cpp:106] Iteration 27700, lr = 0.0002
I1123 22:12:10.880486 12543 solver.cpp:236] Iteration 27800, loss = 0.0159298
I1123 22:12:10.880513 12543 solver.cpp:252]     Train net output #0: loss = 0.022869 (* 1 = 0.022869 loss)
I1123 22:12:10.880518 12543 sgd_solver.cpp:106] Iteration 27800, lr = 0.0002
I1123 22:12:11.559242 12543 solver.cpp:236] Iteration 27900, loss = 0.013603
I1123 22:12:11.559267 12543 solver.cpp:252]     Train net output #0: loss = 0.0238008 (* 1 = 0.0238008 loss)
I1123 22:12:11.559273 12543 sgd_solver.cpp:106] Iteration 27900, lr = 0.0002
I1123 22:12:12.228242 12543 solver.cpp:340] Iteration 28000, Testing net (#0)
I1123 22:12:12.418833 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9955
I1123 22:12:12.418860 12543 solver.cpp:408]     Test net output #1: loss = 0.0259713 (* 1 = 0.0259713 loss)
I1123 22:12:12.420776 12543 solver.cpp:236] Iteration 28000, loss = 0.0163284
I1123 22:12:12.420791 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:12.420797 12543 sgd_solver.cpp:106] Iteration 28000, lr = 0.0002
I1123 22:12:13.095311 12543 solver.cpp:236] Iteration 28100, loss = 0.0126749
I1123 22:12:13.095340 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:13.095345 12543 sgd_solver.cpp:106] Iteration 28100, lr = 0.0002
I1123 22:12:13.770248 12543 solver.cpp:236] Iteration 28200, loss = 0.0111966
I1123 22:12:13.770277 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:13.770280 12543 sgd_solver.cpp:106] Iteration 28200, lr = 0.0002
I1123 22:12:14.447865 12543 solver.cpp:236] Iteration 28300, loss = 0.0168399
I1123 22:12:14.447892 12543 solver.cpp:252]     Train net output #0: loss = 0.00376652 (* 1 = 0.00376652 loss)
I1123 22:12:14.447918 12543 sgd_solver.cpp:106] Iteration 28300, lr = 0.0002
I1123 22:12:15.122301 12543 solver.cpp:236] Iteration 28400, loss = 0.0145311
I1123 22:12:15.122329 12543 solver.cpp:252]     Train net output #0: loss = 0.0239437 (* 1 = 0.0239437 loss)
I1123 22:12:15.122334 12543 sgd_solver.cpp:106] Iteration 28400, lr = 0.0002
I1123 22:12:15.793740 12543 solver.cpp:340] Iteration 28500, Testing net (#0)
I1123 22:12:15.985430 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9951
I1123 22:12:15.985455 12543 solver.cpp:408]     Test net output #1: loss = 0.0285035 (* 1 = 0.0285035 loss)
I1123 22:12:15.987354 12543 solver.cpp:236] Iteration 28500, loss = 0.0149263
I1123 22:12:15.987367 12543 solver.cpp:252]     Train net output #0: loss = 0.00819058 (* 1 = 0.00819058 loss)
I1123 22:12:15.987375 12543 sgd_solver.cpp:106] Iteration 28500, lr = 0.0002
I1123 22:12:16.665807 12543 solver.cpp:236] Iteration 28600, loss = 0.0137078
I1123 22:12:16.665838 12543 solver.cpp:252]     Train net output #0: loss = 0.0153337 (* 1 = 0.0153337 loss)
I1123 22:12:16.665843 12543 sgd_solver.cpp:106] Iteration 28600, lr = 0.0002
I1123 22:12:17.351459 12543 solver.cpp:236] Iteration 28700, loss = 0.0187113
I1123 22:12:17.351485 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:17.351490 12543 sgd_solver.cpp:106] Iteration 28700, lr = 0.0002
I1123 22:12:18.059394 12543 solver.cpp:236] Iteration 28800, loss = 0.0131284
I1123 22:12:18.059430 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:18.059437 12543 sgd_solver.cpp:106] Iteration 28800, lr = 0.0002
I1123 22:12:18.782632 12543 solver.cpp:236] Iteration 28900, loss = 0.0133785
I1123 22:12:18.782662 12543 solver.cpp:252]     Train net output #0: loss = 0.0122895 (* 1 = 0.0122895 loss)
I1123 22:12:18.782670 12543 sgd_solver.cpp:106] Iteration 28900, lr = 0.0002
I1123 22:12:19.491323 12543 solver.cpp:340] Iteration 29000, Testing net (#0)
I1123 22:12:19.703277 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:12:19.703351 12543 solver.cpp:408]     Test net output #1: loss = 0.027081 (* 1 = 0.027081 loss)
I1123 22:12:19.705267 12543 solver.cpp:236] Iteration 29000, loss = 0.0154687
I1123 22:12:19.705282 12543 solver.cpp:252]     Train net output #0: loss = 0.0254204 (* 1 = 0.0254204 loss)
I1123 22:12:19.705291 12543 sgd_solver.cpp:106] Iteration 29000, lr = 0.0002
I1123 22:12:20.414361 12543 solver.cpp:236] Iteration 29100, loss = 0.0165652
I1123 22:12:20.414391 12543 solver.cpp:252]     Train net output #0: loss = 0.0526018 (* 1 = 0.0526018 loss)
I1123 22:12:20.414397 12543 sgd_solver.cpp:106] Iteration 29100, lr = 0.0002
I1123 22:12:21.095628 12543 solver.cpp:236] Iteration 29200, loss = 0.0206139
I1123 22:12:21.095659 12543 solver.cpp:252]     Train net output #0: loss = 0.0282794 (* 1 = 0.0282794 loss)
I1123 22:12:21.095665 12543 sgd_solver.cpp:106] Iteration 29200, lr = 0.0002
I1123 22:12:21.796746 12543 solver.cpp:236] Iteration 29300, loss = 0.0110221
I1123 22:12:21.796773 12543 solver.cpp:252]     Train net output #0: loss = 0.0134325 (* 1 = 0.0134325 loss)
I1123 22:12:21.796778 12543 sgd_solver.cpp:106] Iteration 29300, lr = 0.0002
I1123 22:12:22.481983 12543 solver.cpp:236] Iteration 29400, loss = 0.0112585
I1123 22:12:22.482010 12543 solver.cpp:252]     Train net output #0: loss = 0.017985 (* 1 = 0.017985 loss)
I1123 22:12:22.482014 12543 sgd_solver.cpp:106] Iteration 29400, lr = 0.0002
I1123 22:12:23.148758 12543 solver.cpp:340] Iteration 29500, Testing net (#0)
I1123 22:12:23.345088 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9953
I1123 22:12:23.345114 12543 solver.cpp:408]     Test net output #1: loss = 0.0273868 (* 1 = 0.0273868 loss)
I1123 22:12:23.347066 12543 solver.cpp:236] Iteration 29500, loss = 0.0247471
I1123 22:12:23.347084 12543 solver.cpp:252]     Train net output #0: loss = 0.00259772 (* 1 = 0.00259772 loss)
I1123 22:12:23.347090 12543 sgd_solver.cpp:106] Iteration 29500, lr = 0.0002
I1123 22:12:24.023535 12543 solver.cpp:236] Iteration 29600, loss = 0.013955
I1123 22:12:24.023587 12543 solver.cpp:252]     Train net output #0: loss = 0.0457978 (* 1 = 0.0457978 loss)
I1123 22:12:24.023592 12543 sgd_solver.cpp:106] Iteration 29600, lr = 0.0002
I1123 22:12:24.697060 12543 solver.cpp:236] Iteration 29700, loss = 0.0166368
I1123 22:12:24.697088 12543 solver.cpp:252]     Train net output #0: loss = 0.000785111 (* 1 = 0.000785111 loss)
I1123 22:12:24.697091 12543 sgd_solver.cpp:106] Iteration 29700, lr = 0.0002
I1123 22:12:25.410863 12543 solver.cpp:236] Iteration 29800, loss = 0.0169692
I1123 22:12:25.410897 12543 solver.cpp:252]     Train net output #0: loss = 0.0343546 (* 1 = 0.0343546 loss)
I1123 22:12:25.410903 12543 sgd_solver.cpp:106] Iteration 29800, lr = 0.0002
I1123 22:12:26.132764 12543 solver.cpp:236] Iteration 29900, loss = 0.0204562
I1123 22:12:26.132966 12543 solver.cpp:252]     Train net output #0: loss = 0.0695279 (* 1 = 0.0695279 loss)
I1123 22:12:26.132975 12543 sgd_solver.cpp:106] Iteration 29900, lr = 0.0002
I1123 22:12:26.835276 12543 solver.cpp:340] Iteration 30000, Testing net (#0)
I1123 22:12:27.030354 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:12:27.030387 12543 solver.cpp:408]     Test net output #1: loss = 0.0275178 (* 1 = 0.0275178 loss)
I1123 22:12:27.032666 12543 solver.cpp:236] Iteration 30000, loss = 0.00743884
I1123 22:12:27.032685 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:27.032690 12543 sgd_solver.cpp:106] Iteration 30000, lr = 2e-05
I1123 22:12:27.712641 12543 solver.cpp:236] Iteration 30100, loss = 0.0139965
I1123 22:12:27.712668 12543 solver.cpp:252]     Train net output #0: loss = 0.0303957 (* 1 = 0.0303957 loss)
I1123 22:12:27.712672 12543 sgd_solver.cpp:106] Iteration 30100, lr = 2e-05
I1123 22:12:28.402192 12543 solver.cpp:236] Iteration 30200, loss = 0.0140415
I1123 22:12:28.402220 12543 solver.cpp:252]     Train net output #0: loss = 0.0358947 (* 1 = 0.0358947 loss)
I1123 22:12:28.402225 12543 sgd_solver.cpp:106] Iteration 30200, lr = 2e-05
I1123 22:12:29.080322 12543 solver.cpp:236] Iteration 30300, loss = 0.0128136
I1123 22:12:29.080350 12543 solver.cpp:252]     Train net output #0: loss = 0.024911 (* 1 = 0.024911 loss)
I1123 22:12:29.080354 12543 sgd_solver.cpp:106] Iteration 30300, lr = 2e-05
I1123 22:12:29.757350 12543 solver.cpp:236] Iteration 30400, loss = 0.0106447
I1123 22:12:29.757380 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:29.757385 12543 sgd_solver.cpp:106] Iteration 30400, lr = 2e-05
I1123 22:12:30.443341 12543 solver.cpp:340] Iteration 30500, Testing net (#0)
I1123 22:12:30.636627 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9956
I1123 22:12:30.636651 12543 solver.cpp:408]     Test net output #1: loss = 0.0280042 (* 1 = 0.0280042 loss)
I1123 22:12:30.638651 12543 solver.cpp:236] Iteration 30500, loss = 0.0112703
I1123 22:12:30.638666 12543 solver.cpp:252]     Train net output #0: loss = 0.00912273 (* 1 = 0.00912273 loss)
I1123 22:12:30.638672 12543 sgd_solver.cpp:106] Iteration 30500, lr = 2e-05
I1123 22:12:31.327100 12543 solver.cpp:236] Iteration 30600, loss = 0.0112552
I1123 22:12:31.327127 12543 solver.cpp:252]     Train net output #0: loss = 0.00682966 (* 1 = 0.00682966 loss)
I1123 22:12:31.327131 12543 sgd_solver.cpp:106] Iteration 30600, lr = 2e-05
I1123 22:12:32.004844 12543 solver.cpp:236] Iteration 30700, loss = 0.0117569
I1123 22:12:32.004871 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:32.004875 12543 sgd_solver.cpp:106] Iteration 30700, lr = 2e-05
I1123 22:12:32.690528 12543 solver.cpp:236] Iteration 30800, loss = 0.0107148
I1123 22:12:32.690557 12543 solver.cpp:252]     Train net output #0: loss = 0.118647 (* 1 = 0.118647 loss)
I1123 22:12:32.690560 12543 sgd_solver.cpp:106] Iteration 30800, lr = 2e-05
I1123 22:12:33.363518 12543 solver.cpp:236] Iteration 30900, loss = 0.0101995
I1123 22:12:33.363545 12543 solver.cpp:252]     Train net output #0: loss = 0.029472 (* 1 = 0.029472 loss)
I1123 22:12:33.363549 12543 sgd_solver.cpp:106] Iteration 30900, lr = 2e-05
I1123 22:12:34.028851 12543 solver.cpp:340] Iteration 31000, Testing net (#0)
I1123 22:12:34.220583 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9959
I1123 22:12:34.220613 12543 solver.cpp:408]     Test net output #1: loss = 0.0270477 (* 1 = 0.0270477 loss)
I1123 22:12:34.222539 12543 solver.cpp:236] Iteration 31000, loss = 0.00688075
I1123 22:12:34.222555 12543 solver.cpp:252]     Train net output #0: loss = 0.00159306 (* 1 = 0.00159306 loss)
I1123 22:12:34.222564 12543 sgd_solver.cpp:106] Iteration 31000, lr = 2e-05
I1123 22:12:34.894562 12543 solver.cpp:236] Iteration 31100, loss = 0.015408
I1123 22:12:34.894590 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:34.894594 12543 sgd_solver.cpp:106] Iteration 31100, lr = 2e-05
I1123 22:12:35.581434 12543 solver.cpp:236] Iteration 31200, loss = 0.0106276
I1123 22:12:35.581483 12543 solver.cpp:252]     Train net output #0: loss = 0.00238778 (* 1 = 0.00238778 loss)
I1123 22:12:35.581487 12543 sgd_solver.cpp:106] Iteration 31200, lr = 2e-05
I1123 22:12:36.256871 12543 solver.cpp:236] Iteration 31300, loss = 0.0150073
I1123 22:12:36.256901 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:36.256906 12543 sgd_solver.cpp:106] Iteration 31300, lr = 2e-05
I1123 22:12:36.930909 12543 solver.cpp:236] Iteration 31400, loss = 0.00983988
I1123 22:12:36.930938 12543 solver.cpp:252]     Train net output #0: loss = 0.00148127 (* 1 = 0.00148127 loss)
I1123 22:12:36.930943 12543 sgd_solver.cpp:106] Iteration 31400, lr = 2e-05
I1123 22:12:37.598713 12543 solver.cpp:340] Iteration 31500, Testing net (#0)
I1123 22:12:37.789515 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9956
I1123 22:12:37.789543 12543 solver.cpp:408]     Test net output #1: loss = 0.0269691 (* 1 = 0.0269691 loss)
I1123 22:12:37.791467 12543 solver.cpp:236] Iteration 31500, loss = 0.0126133
I1123 22:12:37.791483 12543 solver.cpp:252]     Train net output #0: loss = 0.00497556 (* 1 = 0.00497556 loss)
I1123 22:12:37.791489 12543 sgd_solver.cpp:106] Iteration 31500, lr = 2e-05
I1123 22:12:38.464212 12543 solver.cpp:236] Iteration 31600, loss = 0.011584
I1123 22:12:38.464238 12543 solver.cpp:252]     Train net output #0: loss = 0.0183056 (* 1 = 0.0183056 loss)
I1123 22:12:38.464243 12543 sgd_solver.cpp:106] Iteration 31600, lr = 2e-05
I1123 22:12:39.141777 12543 solver.cpp:236] Iteration 31700, loss = 0.0111385
I1123 22:12:39.141803 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:39.141808 12543 sgd_solver.cpp:106] Iteration 31700, lr = 2e-05
I1123 22:12:39.817163 12543 solver.cpp:236] Iteration 31800, loss = 0.0143329
I1123 22:12:39.817193 12543 solver.cpp:252]     Train net output #0: loss = 0.00533371 (* 1 = 0.00533371 loss)
I1123 22:12:39.817198 12543 sgd_solver.cpp:106] Iteration 31800, lr = 2e-05
I1123 22:12:40.489650 12543 solver.cpp:236] Iteration 31900, loss = 0.0137739
I1123 22:12:40.489678 12543 solver.cpp:252]     Train net output #0: loss = 0.0137187 (* 1 = 0.0137187 loss)
I1123 22:12:40.489682 12543 sgd_solver.cpp:106] Iteration 31900, lr = 2e-05
I1123 22:12:41.157701 12543 solver.cpp:340] Iteration 32000, Testing net (#0)
I1123 22:12:41.349035 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:12:41.349061 12543 solver.cpp:408]     Test net output #1: loss = 0.0267959 (* 1 = 0.0267959 loss)
I1123 22:12:41.351079 12543 solver.cpp:236] Iteration 32000, loss = 0.0139687
I1123 22:12:41.351091 12543 solver.cpp:252]     Train net output #0: loss = 0.0105342 (* 1 = 0.0105342 loss)
I1123 22:12:41.351096 12543 sgd_solver.cpp:106] Iteration 32000, lr = 2e-05
I1123 22:12:42.028486 12543 solver.cpp:236] Iteration 32100, loss = 0.00983054
I1123 22:12:42.028513 12543 solver.cpp:252]     Train net output #0: loss = 0.0110452 (* 1 = 0.0110452 loss)
I1123 22:12:42.028518 12543 sgd_solver.cpp:106] Iteration 32100, lr = 2e-05
I1123 22:12:42.707844 12543 solver.cpp:236] Iteration 32200, loss = 0.00980574
I1123 22:12:42.707872 12543 solver.cpp:252]     Train net output #0: loss = 0.00445893 (* 1 = 0.00445893 loss)
I1123 22:12:42.707876 12543 sgd_solver.cpp:106] Iteration 32200, lr = 2e-05
I1123 22:12:43.383127 12543 solver.cpp:236] Iteration 32300, loss = 0.0223584
I1123 22:12:43.383155 12543 solver.cpp:252]     Train net output #0: loss = 0.00332932 (* 1 = 0.00332932 loss)
I1123 22:12:43.383159 12543 sgd_solver.cpp:106] Iteration 32300, lr = 2e-05
I1123 22:12:44.058040 12543 solver.cpp:236] Iteration 32400, loss = 0.0160133
I1123 22:12:44.058068 12543 solver.cpp:252]     Train net output #0: loss = 0.0124667 (* 1 = 0.0124667 loss)
I1123 22:12:44.058073 12543 sgd_solver.cpp:106] Iteration 32400, lr = 2e-05
I1123 22:12:44.727005 12543 solver.cpp:340] Iteration 32500, Testing net (#0)
I1123 22:12:44.919237 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:12:44.919280 12543 solver.cpp:408]     Test net output #1: loss = 0.026687 (* 1 = 0.026687 loss)
I1123 22:12:44.921203 12543 solver.cpp:236] Iteration 32500, loss = 0.00989316
I1123 22:12:44.921217 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:44.921222 12543 sgd_solver.cpp:106] Iteration 32500, lr = 2e-05
I1123 22:12:45.593991 12543 solver.cpp:236] Iteration 32600, loss = 0.00836962
I1123 22:12:45.594023 12543 solver.cpp:252]     Train net output #0: loss = 0.046212 (* 1 = 0.046212 loss)
I1123 22:12:45.594032 12543 sgd_solver.cpp:106] Iteration 32600, lr = 2e-05
I1123 22:12:46.268069 12543 solver.cpp:236] Iteration 32700, loss = 0.0117338
I1123 22:12:46.268095 12543 solver.cpp:252]     Train net output #0: loss = 0.0192508 (* 1 = 0.0192508 loss)
I1123 22:12:46.268102 12543 sgd_solver.cpp:106] Iteration 32700, lr = 2e-05
I1123 22:12:46.943421 12543 solver.cpp:236] Iteration 32800, loss = 0.00356167
I1123 22:12:46.943449 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:46.943456 12543 sgd_solver.cpp:106] Iteration 32800, lr = 2e-05
I1123 22:12:47.620483 12543 solver.cpp:236] Iteration 32900, loss = 0.0106433
I1123 22:12:47.620513 12543 solver.cpp:252]     Train net output #0: loss = 0.0160572 (* 1 = 0.0160572 loss)
I1123 22:12:47.620519 12543 sgd_solver.cpp:106] Iteration 32900, lr = 2e-05
I1123 22:12:48.290565 12543 solver.cpp:340] Iteration 33000, Testing net (#0)
I1123 22:12:48.482179 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9954
I1123 22:12:48.482203 12543 solver.cpp:408]     Test net output #1: loss = 0.0270662 (* 1 = 0.0270662 loss)
I1123 22:12:48.484143 12543 solver.cpp:236] Iteration 33000, loss = 0.0120212
I1123 22:12:48.484158 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:48.484164 12543 sgd_solver.cpp:106] Iteration 33000, lr = 2e-05
I1123 22:12:49.164641 12543 solver.cpp:236] Iteration 33100, loss = 0.0142463
I1123 22:12:49.164669 12543 solver.cpp:252]     Train net output #0: loss = 0.00110828 (* 1 = 0.00110828 loss)
I1123 22:12:49.164674 12543 sgd_solver.cpp:106] Iteration 33100, lr = 2e-05
I1123 22:12:49.849249 12543 solver.cpp:236] Iteration 33200, loss = 0.0131118
I1123 22:12:49.849277 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:49.849282 12543 sgd_solver.cpp:106] Iteration 33200, lr = 2e-05
I1123 22:12:50.525288 12543 solver.cpp:236] Iteration 33300, loss = 0.00934966
I1123 22:12:50.525316 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:50.525321 12543 sgd_solver.cpp:106] Iteration 33300, lr = 2e-05
I1123 22:12:51.205225 12543 solver.cpp:236] Iteration 33400, loss = 0.0124023
I1123 22:12:51.205253 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:51.205257 12543 sgd_solver.cpp:106] Iteration 33400, lr = 2e-05
I1123 22:12:51.902544 12543 solver.cpp:340] Iteration 33500, Testing net (#0)
I1123 22:12:52.107702 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9959
I1123 22:12:52.107728 12543 solver.cpp:408]     Test net output #1: loss = 0.0264488 (* 1 = 0.0264488 loss)
I1123 22:12:52.109638 12543 solver.cpp:236] Iteration 33500, loss = 0.0112031
I1123 22:12:52.109652 12543 solver.cpp:252]     Train net output #0: loss = 0.0140546 (* 1 = 0.0140546 loss)
I1123 22:12:52.109657 12543 sgd_solver.cpp:106] Iteration 33500, lr = 2e-05
I1123 22:12:52.823776 12543 solver.cpp:236] Iteration 33600, loss = 0.011108
I1123 22:12:52.823812 12543 solver.cpp:252]     Train net output #0: loss = 0.00979956 (* 1 = 0.00979956 loss)
I1123 22:12:52.823822 12543 sgd_solver.cpp:106] Iteration 33600, lr = 2e-05
I1123 22:12:53.520777 12543 solver.cpp:236] Iteration 33700, loss = 0.00954217
I1123 22:12:53.520807 12543 solver.cpp:252]     Train net output #0: loss = 0.00829118 (* 1 = 0.00829118 loss)
I1123 22:12:53.520813 12543 sgd_solver.cpp:106] Iteration 33700, lr = 2e-05
I1123 22:12:54.210788 12543 solver.cpp:236] Iteration 33800, loss = 0.00752624
I1123 22:12:54.210816 12543 solver.cpp:252]     Train net output #0: loss = 0.0037856 (* 1 = 0.0037856 loss)
I1123 22:12:54.210835 12543 sgd_solver.cpp:106] Iteration 33800, lr = 2e-05
I1123 22:12:54.899101 12543 solver.cpp:236] Iteration 33900, loss = 0.0154037
I1123 22:12:54.899132 12543 solver.cpp:252]     Train net output #0: loss = 0.0173653 (* 1 = 0.0173653 loss)
I1123 22:12:54.899137 12543 sgd_solver.cpp:106] Iteration 33900, lr = 2e-05
I1123 22:12:55.584483 12543 solver.cpp:340] Iteration 34000, Testing net (#0)
I1123 22:12:55.777232 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9959
I1123 22:12:55.777258 12543 solver.cpp:408]     Test net output #1: loss = 0.0267851 (* 1 = 0.0267851 loss)
I1123 22:12:55.779140 12543 solver.cpp:236] Iteration 34000, loss = 0.00903646
I1123 22:12:55.779153 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:55.779160 12543 sgd_solver.cpp:106] Iteration 34000, lr = 2e-05
I1123 22:12:56.469806 12543 solver.cpp:236] Iteration 34100, loss = 0.0108697
I1123 22:12:56.469869 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:56.469876 12543 sgd_solver.cpp:106] Iteration 34100, lr = 2e-05
I1123 22:12:57.145998 12543 solver.cpp:236] Iteration 34200, loss = 0.017419
I1123 22:12:57.146026 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:12:57.146030 12543 sgd_solver.cpp:106] Iteration 34200, lr = 2e-05
I1123 22:12:57.822445 12543 solver.cpp:236] Iteration 34300, loss = 0.0115886
I1123 22:12:57.822473 12543 solver.cpp:252]     Train net output #0: loss = 0.0831445 (* 1 = 0.0831445 loss)
I1123 22:12:57.822476 12543 sgd_solver.cpp:106] Iteration 34300, lr = 2e-05
I1123 22:12:58.497874 12543 solver.cpp:236] Iteration 34400, loss = 0.0111122
I1123 22:12:58.497900 12543 solver.cpp:252]     Train net output #0: loss = 0.00758 (* 1 = 0.00758 loss)
I1123 22:12:58.497905 12543 sgd_solver.cpp:106] Iteration 34400, lr = 2e-05
I1123 22:12:59.168984 12543 solver.cpp:340] Iteration 34500, Testing net (#0)
I1123 22:12:59.364362 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9955
I1123 22:12:59.364385 12543 solver.cpp:408]     Test net output #1: loss = 0.0269178 (* 1 = 0.0269178 loss)
I1123 22:12:59.366329 12543 solver.cpp:236] Iteration 34500, loss = 0.0109947
I1123 22:12:59.366343 12543 solver.cpp:252]     Train net output #0: loss = 0.000237247 (* 1 = 0.000237247 loss)
I1123 22:12:59.366348 12543 sgd_solver.cpp:106] Iteration 34500, lr = 2e-05
I1123 22:13:00.050799 12543 solver.cpp:236] Iteration 34600, loss = 0.017246
I1123 22:13:00.050827 12543 solver.cpp:252]     Train net output #0: loss = 0.0555465 (* 1 = 0.0555465 loss)
I1123 22:13:00.050832 12543 sgd_solver.cpp:106] Iteration 34600, lr = 2e-05
I1123 22:13:00.759722 12543 solver.cpp:236] Iteration 34700, loss = 0.0112916
I1123 22:13:00.759748 12543 solver.cpp:252]     Train net output #0: loss = 0.0280471 (* 1 = 0.0280471 loss)
I1123 22:13:00.759752 12543 sgd_solver.cpp:106] Iteration 34700, lr = 2e-05
I1123 22:13:01.483101 12543 solver.cpp:236] Iteration 34800, loss = 0.0129412
I1123 22:13:01.483141 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:01.483149 12543 sgd_solver.cpp:106] Iteration 34800, lr = 2e-05
I1123 22:13:02.257830 12543 solver.cpp:236] Iteration 34900, loss = 0.00978943
I1123 22:13:02.257869 12543 solver.cpp:252]     Train net output #0: loss = 0.00834969 (* 1 = 0.00834969 loss)
I1123 22:13:02.257880 12543 sgd_solver.cpp:106] Iteration 34900, lr = 2e-05
I1123 22:13:03.012753 12543 solver.cpp:340] Iteration 35000, Testing net (#0)
I1123 22:13:03.249085 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:13:03.249112 12543 solver.cpp:408]     Test net output #1: loss = 0.0268132 (* 1 = 0.0268132 loss)
I1123 22:13:03.251073 12543 solver.cpp:236] Iteration 35000, loss = 0.0134678
I1123 22:13:03.251096 12543 solver.cpp:252]     Train net output #0: loss = 0.00507153 (* 1 = 0.00507153 loss)
I1123 22:13:03.251106 12543 sgd_solver.cpp:106] Iteration 35000, lr = 2e-05
I1123 22:13:04.046317 12543 solver.cpp:236] Iteration 35100, loss = 0.0112471
I1123 22:13:04.046349 12543 solver.cpp:252]     Train net output #0: loss = 0.0118218 (* 1 = 0.0118218 loss)
I1123 22:13:04.046355 12543 sgd_solver.cpp:106] Iteration 35100, lr = 2e-05
I1123 22:13:04.786180 12543 solver.cpp:236] Iteration 35200, loss = 0.0106112
I1123 22:13:04.786208 12543 solver.cpp:252]     Train net output #0: loss = 0.0143745 (* 1 = 0.0143745 loss)
I1123 22:13:04.786214 12543 sgd_solver.cpp:106] Iteration 35200, lr = 2e-05
I1123 22:13:05.573035 12543 solver.cpp:236] Iteration 35300, loss = 0.00915986
I1123 22:13:05.573071 12543 solver.cpp:252]     Train net output #0: loss = 0.000257967 (* 1 = 0.000257967 loss)
I1123 22:13:05.573079 12543 sgd_solver.cpp:106] Iteration 35300, lr = 2e-05
I1123 22:13:06.284955 12543 solver.cpp:236] Iteration 35400, loss = 0.0102822
I1123 22:13:06.284986 12543 solver.cpp:252]     Train net output #0: loss = 0.0174136 (* 1 = 0.0174136 loss)
I1123 22:13:06.284992 12543 sgd_solver.cpp:106] Iteration 35400, lr = 2e-05
I1123 22:13:06.961293 12543 solver.cpp:340] Iteration 35500, Testing net (#0)
I1123 22:13:07.152410 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:13:07.152437 12543 solver.cpp:408]     Test net output #1: loss = 0.0266292 (* 1 = 0.0266292 loss)
I1123 22:13:07.154423 12543 solver.cpp:236] Iteration 35500, loss = 0.0121141
I1123 22:13:07.154469 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:07.154479 12543 sgd_solver.cpp:106] Iteration 35500, lr = 2e-05
I1123 22:13:07.923687 12543 solver.cpp:236] Iteration 35600, loss = 0.00893755
I1123 22:13:07.923715 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:07.923722 12543 sgd_solver.cpp:106] Iteration 35600, lr = 2e-05
I1123 22:13:08.671454 12543 solver.cpp:236] Iteration 35700, loss = 0.00907696
I1123 22:13:08.671485 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:08.671490 12543 sgd_solver.cpp:106] Iteration 35700, lr = 2e-05
I1123 22:13:09.367104 12543 solver.cpp:236] Iteration 35800, loss = 0.0141644
I1123 22:13:09.367131 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:09.367136 12543 sgd_solver.cpp:106] Iteration 35800, lr = 2e-05
I1123 22:13:10.046099 12543 solver.cpp:236] Iteration 35900, loss = 0.0119043
I1123 22:13:10.046128 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:10.046133 12543 sgd_solver.cpp:106] Iteration 35900, lr = 2e-05
I1123 22:13:10.719120 12543 solver.cpp:340] Iteration 36000, Testing net (#0)
I1123 22:13:10.909528 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9954
I1123 22:13:10.909554 12543 solver.cpp:408]     Test net output #1: loss = 0.0267127 (* 1 = 0.0267127 loss)
I1123 22:13:10.911469 12543 solver.cpp:236] Iteration 36000, loss = 0.00872161
I1123 22:13:10.911484 12543 solver.cpp:252]     Train net output #0: loss = 0.0188343 (* 1 = 0.0188343 loss)
I1123 22:13:10.911492 12543 sgd_solver.cpp:106] Iteration 36000, lr = 2e-05
I1123 22:13:11.582897 12543 solver.cpp:236] Iteration 36100, loss = 0.0105389
I1123 22:13:11.582924 12543 solver.cpp:252]     Train net output #0: loss = 0.0130243 (* 1 = 0.0130243 loss)
I1123 22:13:11.582931 12543 sgd_solver.cpp:106] Iteration 36100, lr = 2e-05
I1123 22:13:12.268714 12543 solver.cpp:236] Iteration 36200, loss = 0.0142836
I1123 22:13:12.268743 12543 solver.cpp:252]     Train net output #0: loss = 0.0146126 (* 1 = 0.0146126 loss)
I1123 22:13:12.268748 12543 sgd_solver.cpp:106] Iteration 36200, lr = 2e-05
I1123 22:13:12.994129 12543 solver.cpp:236] Iteration 36300, loss = 0.0126249
I1123 22:13:12.994158 12543 solver.cpp:252]     Train net output #0: loss = 0.00275617 (* 1 = 0.00275617 loss)
I1123 22:13:12.994164 12543 sgd_solver.cpp:106] Iteration 36300, lr = 2e-05
I1123 22:13:13.670720 12543 solver.cpp:236] Iteration 36400, loss = 0.0089518
I1123 22:13:13.670747 12543 solver.cpp:252]     Train net output #0: loss = 0.0153365 (* 1 = 0.0153365 loss)
I1123 22:13:13.670752 12543 sgd_solver.cpp:106] Iteration 36400, lr = 2e-05
I1123 22:13:14.342103 12543 solver.cpp:340] Iteration 36500, Testing net (#0)
I1123 22:13:14.533622 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9959
I1123 22:13:14.533648 12543 solver.cpp:408]     Test net output #1: loss = 0.0263167 (* 1 = 0.0263167 loss)
I1123 22:13:14.535531 12543 solver.cpp:236] Iteration 36500, loss = 0.0117562
I1123 22:13:14.535543 12543 solver.cpp:252]     Train net output #0: loss = 0.00287946 (* 1 = 0.00287946 loss)
I1123 22:13:14.535549 12543 sgd_solver.cpp:106] Iteration 36500, lr = 2e-05
I1123 22:13:15.210600 12543 solver.cpp:236] Iteration 36600, loss = 0.0121345
I1123 22:13:15.210630 12543 solver.cpp:252]     Train net output #0: loss = 0.0242868 (* 1 = 0.0242868 loss)
I1123 22:13:15.210636 12543 sgd_solver.cpp:106] Iteration 36600, lr = 2e-05
I1123 22:13:15.895592 12543 solver.cpp:236] Iteration 36700, loss = 0.017388
I1123 22:13:15.895620 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:15.895624 12543 sgd_solver.cpp:106] Iteration 36700, lr = 2e-05
I1123 22:13:16.573820 12543 solver.cpp:236] Iteration 36800, loss = 0.00946552
I1123 22:13:16.573848 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:16.573851 12543 sgd_solver.cpp:106] Iteration 36800, lr = 2e-05
I1123 22:13:17.255655 12543 solver.cpp:236] Iteration 36900, loss = 0.0108148
I1123 22:13:17.255682 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:17.255686 12543 sgd_solver.cpp:106] Iteration 36900, lr = 2e-05
I1123 22:13:17.937731 12543 solver.cpp:340] Iteration 37000, Testing net (#0)
I1123 22:13:18.128487 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:13:18.128514 12543 solver.cpp:408]     Test net output #1: loss = 0.0267914 (* 1 = 0.0267914 loss)
I1123 22:13:18.130383 12543 solver.cpp:236] Iteration 37000, loss = 0.0192723
I1123 22:13:18.130396 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:18.130403 12543 sgd_solver.cpp:106] Iteration 37000, lr = 2e-05
I1123 22:13:18.810189 12543 solver.cpp:236] Iteration 37100, loss = 0.0141418
I1123 22:13:18.810215 12543 solver.cpp:252]     Train net output #0: loss = 0.063697 (* 1 = 0.063697 loss)
I1123 22:13:18.810220 12543 sgd_solver.cpp:106] Iteration 37100, lr = 2e-05
I1123 22:13:19.503916 12543 solver.cpp:236] Iteration 37200, loss = 0.0122898
I1123 22:13:19.503945 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:19.503950 12543 sgd_solver.cpp:106] Iteration 37200, lr = 2e-05
I1123 22:13:20.198377 12543 solver.cpp:236] Iteration 37300, loss = 0.00844557
I1123 22:13:20.198405 12543 solver.cpp:252]     Train net output #0: loss = 0.0283331 (* 1 = 0.0283331 loss)
I1123 22:13:20.198408 12543 sgd_solver.cpp:106] Iteration 37300, lr = 2e-05
I1123 22:13:20.885126 12543 solver.cpp:236] Iteration 37400, loss = 0.0162519
I1123 22:13:20.885154 12543 solver.cpp:252]     Train net output #0: loss = 0.058061 (* 1 = 0.058061 loss)
I1123 22:13:20.885159 12543 sgd_solver.cpp:106] Iteration 37400, lr = 2e-05
I1123 22:13:21.558485 12543 solver.cpp:340] Iteration 37500, Testing net (#0)
I1123 22:13:21.755067 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:13:21.755100 12543 solver.cpp:408]     Test net output #1: loss = 0.026486 (* 1 = 0.026486 loss)
I1123 22:13:21.757292 12543 solver.cpp:236] Iteration 37500, loss = 0.00814065
I1123 22:13:21.757313 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:21.757321 12543 sgd_solver.cpp:106] Iteration 37500, lr = 2e-05
I1123 22:13:22.432786 12543 solver.cpp:236] Iteration 37600, loss = 0.0133906
I1123 22:13:22.432817 12543 solver.cpp:252]     Train net output #0: loss = 0.0268155 (* 1 = 0.0268155 loss)
I1123 22:13:22.432824 12543 sgd_solver.cpp:106] Iteration 37600, lr = 2e-05
I1123 22:13:23.121911 12543 solver.cpp:236] Iteration 37700, loss = 0.0108379
I1123 22:13:23.121938 12543 solver.cpp:252]     Train net output #0: loss = 0.0123668 (* 1 = 0.0123668 loss)
I1123 22:13:23.121942 12543 sgd_solver.cpp:106] Iteration 37700, lr = 2e-05
I1123 22:13:23.798187 12543 solver.cpp:236] Iteration 37800, loss = 0.0133263
I1123 22:13:23.798214 12543 solver.cpp:252]     Train net output #0: loss = 0.01751 (* 1 = 0.01751 loss)
I1123 22:13:23.798219 12543 sgd_solver.cpp:106] Iteration 37800, lr = 2e-05
I1123 22:13:24.473397 12543 solver.cpp:236] Iteration 37900, loss = 0.00925055
I1123 22:13:24.473424 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:24.473428 12543 sgd_solver.cpp:106] Iteration 37900, lr = 2e-05
I1123 22:13:25.139322 12543 solver.cpp:340] Iteration 38000, Testing net (#0)
I1123 22:13:25.329644 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:13:25.329670 12543 solver.cpp:408]     Test net output #1: loss = 0.0267475 (* 1 = 0.0267475 loss)
I1123 22:13:25.331625 12543 solver.cpp:236] Iteration 38000, loss = 0.0126622
I1123 22:13:25.331640 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:25.331665 12543 sgd_solver.cpp:106] Iteration 38000, lr = 2e-05
I1123 22:13:26.007738 12543 solver.cpp:236] Iteration 38100, loss = 0.00820737
I1123 22:13:26.007766 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:26.007771 12543 sgd_solver.cpp:106] Iteration 38100, lr = 2e-05
I1123 22:13:26.680083 12543 solver.cpp:236] Iteration 38200, loss = 0.0111858
I1123 22:13:26.680165 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:26.680169 12543 sgd_solver.cpp:106] Iteration 38200, lr = 2e-05
I1123 22:13:27.354462 12543 solver.cpp:236] Iteration 38300, loss = 0.012308
I1123 22:13:27.354490 12543 solver.cpp:252]     Train net output #0: loss = 0.114259 (* 1 = 0.114259 loss)
I1123 22:13:27.354495 12543 sgd_solver.cpp:106] Iteration 38300, lr = 2e-05
I1123 22:13:28.025828 12543 solver.cpp:236] Iteration 38400, loss = 0.00907052
I1123 22:13:28.025854 12543 solver.cpp:252]     Train net output #0: loss = 0.0139258 (* 1 = 0.0139258 loss)
I1123 22:13:28.025859 12543 sgd_solver.cpp:106] Iteration 38400, lr = 2e-05
I1123 22:13:28.700248 12543 solver.cpp:340] Iteration 38500, Testing net (#0)
I1123 22:13:28.892767 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:13:28.892796 12543 solver.cpp:408]     Test net output #1: loss = 0.0262864 (* 1 = 0.0262864 loss)
I1123 22:13:28.894711 12543 solver.cpp:236] Iteration 38500, loss = 0.00815723
I1123 22:13:28.894724 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:28.894729 12543 sgd_solver.cpp:106] Iteration 38500, lr = 2e-05
I1123 22:13:29.567366 12543 solver.cpp:236] Iteration 38600, loss = 0.0123087
I1123 22:13:29.567394 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:29.567397 12543 sgd_solver.cpp:106] Iteration 38600, lr = 2e-05
I1123 22:13:30.236685 12543 solver.cpp:236] Iteration 38700, loss = 0.010327
I1123 22:13:30.236713 12543 solver.cpp:252]     Train net output #0: loss = 0.00571773 (* 1 = 0.00571773 loss)
I1123 22:13:30.236717 12543 sgd_solver.cpp:106] Iteration 38700, lr = 2e-05
I1123 22:13:30.910215 12543 solver.cpp:236] Iteration 38800, loss = 0.00752858
I1123 22:13:30.910244 12543 solver.cpp:252]     Train net output #0: loss = 0.010679 (* 1 = 0.010679 loss)
I1123 22:13:30.910249 12543 sgd_solver.cpp:106] Iteration 38800, lr = 2e-05
I1123 22:13:31.590416 12543 solver.cpp:236] Iteration 38900, loss = 0.00652741
I1123 22:13:31.590443 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:31.590446 12543 sgd_solver.cpp:106] Iteration 38900, lr = 2e-05
I1123 22:13:32.264955 12543 solver.cpp:340] Iteration 39000, Testing net (#0)
I1123 22:13:32.455674 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:13:32.455699 12543 solver.cpp:408]     Test net output #1: loss = 0.0265751 (* 1 = 0.0265751 loss)
I1123 22:13:32.457622 12543 solver.cpp:236] Iteration 39000, loss = 0.0130136
I1123 22:13:32.457635 12543 solver.cpp:252]     Train net output #0: loss = 0.000199963 (* 1 = 0.000199963 loss)
I1123 22:13:32.457641 12543 sgd_solver.cpp:106] Iteration 39000, lr = 2e-05
I1123 22:13:33.132477 12543 solver.cpp:236] Iteration 39100, loss = 0.01116
I1123 22:13:33.132505 12543 solver.cpp:252]     Train net output #0: loss = 0.022227 (* 1 = 0.022227 loss)
I1123 22:13:33.132510 12543 sgd_solver.cpp:106] Iteration 39100, lr = 2e-05
I1123 22:13:33.808092 12543 solver.cpp:236] Iteration 39200, loss = 0.00816375
I1123 22:13:33.808118 12543 solver.cpp:252]     Train net output #0: loss = 0.00504764 (* 1 = 0.00504764 loss)
I1123 22:13:33.808125 12543 sgd_solver.cpp:106] Iteration 39200, lr = 2e-05
I1123 22:13:34.487190 12543 solver.cpp:236] Iteration 39300, loss = 0.0161993
I1123 22:13:34.487220 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:34.487223 12543 sgd_solver.cpp:106] Iteration 39300, lr = 2e-05
I1123 22:13:35.179193 12543 solver.cpp:236] Iteration 39400, loss = 0.0117405
I1123 22:13:35.179217 12543 solver.cpp:252]     Train net output #0: loss = 0.0238307 (* 1 = 0.0238307 loss)
I1123 22:13:35.179222 12543 sgd_solver.cpp:106] Iteration 39400, lr = 2e-05
I1123 22:13:35.851178 12543 solver.cpp:340] Iteration 39500, Testing net (#0)
I1123 22:13:36.043099 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:13:36.043125 12543 solver.cpp:408]     Test net output #1: loss = 0.0263898 (* 1 = 0.0263898 loss)
I1123 22:13:36.045094 12543 solver.cpp:236] Iteration 39500, loss = 0.0153014
I1123 22:13:36.045120 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:36.045125 12543 sgd_solver.cpp:106] Iteration 39500, lr = 2e-05
I1123 22:13:36.720904 12543 solver.cpp:236] Iteration 39600, loss = 0.00772107
I1123 22:13:36.720932 12543 solver.cpp:252]     Train net output #0: loss = 0.0210194 (* 1 = 0.0210194 loss)
I1123 22:13:36.720938 12543 sgd_solver.cpp:106] Iteration 39600, lr = 2e-05
I1123 22:13:37.405774 12543 solver.cpp:236] Iteration 39700, loss = 0.0104336
I1123 22:13:37.405802 12543 solver.cpp:252]     Train net output #0: loss = 0.0285788 (* 1 = 0.0285788 loss)
I1123 22:13:37.405807 12543 sgd_solver.cpp:106] Iteration 39700, lr = 2e-05
I1123 22:13:38.079372 12543 solver.cpp:236] Iteration 39800, loss = 0.0195524
I1123 22:13:38.079399 12543 solver.cpp:252]     Train net output #0: loss = 0.0220573 (* 1 = 0.0220573 loss)
I1123 22:13:38.079403 12543 sgd_solver.cpp:106] Iteration 39800, lr = 2e-05
I1123 22:13:38.758414 12543 solver.cpp:236] Iteration 39900, loss = 0.0100354
I1123 22:13:38.758441 12543 solver.cpp:252]     Train net output #0: loss = 0.000621657 (* 1 = 0.000621657 loss)
I1123 22:13:38.758446 12543 sgd_solver.cpp:106] Iteration 39900, lr = 2e-05
I1123 22:13:39.429714 12543 solver.cpp:340] Iteration 40000, Testing net (#0)
I1123 22:13:39.622427 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:13:39.622453 12543 solver.cpp:408]     Test net output #1: loss = 0.0264781 (* 1 = 0.0264781 loss)
I1123 22:13:39.624366 12543 solver.cpp:236] Iteration 40000, loss = 0.0107474
I1123 22:13:39.624380 12543 solver.cpp:252]     Train net output #0: loss = 0.00129298 (* 1 = 0.00129298 loss)
I1123 22:13:39.624387 12543 sgd_solver.cpp:106] Iteration 40000, lr = 2e-05
I1123 22:13:40.304852 12543 solver.cpp:236] Iteration 40100, loss = 0.0076307
I1123 22:13:40.304879 12543 solver.cpp:252]     Train net output #0: loss = 0.0143954 (* 1 = 0.0143954 loss)
I1123 22:13:40.304883 12543 sgd_solver.cpp:106] Iteration 40100, lr = 2e-05
I1123 22:13:40.988793 12543 solver.cpp:236] Iteration 40200, loss = 0.0111043
I1123 22:13:40.988822 12543 solver.cpp:252]     Train net output #0: loss = 0.00147282 (* 1 = 0.00147282 loss)
I1123 22:13:40.988826 12543 sgd_solver.cpp:106] Iteration 40200, lr = 2e-05
I1123 22:13:41.668531 12543 solver.cpp:236] Iteration 40300, loss = 0.00488973
I1123 22:13:41.668556 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:41.668560 12543 sgd_solver.cpp:106] Iteration 40300, lr = 2e-05
I1123 22:13:42.372608 12543 solver.cpp:236] Iteration 40400, loss = 0.012971
I1123 22:13:42.372640 12543 solver.cpp:252]     Train net output #0: loss = 0.0277964 (* 1 = 0.0277964 loss)
I1123 22:13:42.372648 12543 sgd_solver.cpp:106] Iteration 40400, lr = 2e-05
I1123 22:13:43.062316 12543 solver.cpp:340] Iteration 40500, Testing net (#0)
I1123 22:13:43.252895 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:13:43.252923 12543 solver.cpp:408]     Test net output #1: loss = 0.0266968 (* 1 = 0.0266968 loss)
I1123 22:13:43.254806 12543 solver.cpp:236] Iteration 40500, loss = 0.0115679
I1123 22:13:43.254818 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:43.254823 12543 sgd_solver.cpp:106] Iteration 40500, lr = 2e-05
I1123 22:13:43.933006 12543 solver.cpp:236] Iteration 40600, loss = 0.0140451
I1123 22:13:43.933032 12543 solver.cpp:252]     Train net output #0: loss = 0.0128586 (* 1 = 0.0128586 loss)
I1123 22:13:43.933037 12543 sgd_solver.cpp:106] Iteration 40600, lr = 2e-05
I1123 22:13:44.613782 12543 solver.cpp:236] Iteration 40700, loss = 0.0123959
I1123 22:13:44.613814 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:44.613821 12543 sgd_solver.cpp:106] Iteration 40700, lr = 2e-05
I1123 22:13:45.293267 12543 solver.cpp:236] Iteration 40800, loss = 0.00764175
I1123 22:13:45.293294 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:45.293299 12543 sgd_solver.cpp:106] Iteration 40800, lr = 2e-05
I1123 22:13:45.973078 12543 solver.cpp:236] Iteration 40900, loss = 0.0110337
I1123 22:13:45.973106 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:45.973110 12543 sgd_solver.cpp:106] Iteration 40900, lr = 2e-05
I1123 22:13:46.645530 12543 solver.cpp:340] Iteration 41000, Testing net (#0)
I1123 22:13:46.833734 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:13:46.833760 12543 solver.cpp:408]     Test net output #1: loss = 0.0265159 (* 1 = 0.0265159 loss)
I1123 22:13:46.835644 12543 solver.cpp:236] Iteration 41000, loss = 0.00902618
I1123 22:13:46.835657 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:46.835664 12543 sgd_solver.cpp:106] Iteration 41000, lr = 2e-05
I1123 22:13:47.512404 12543 solver.cpp:236] Iteration 41100, loss = 0.00804332
I1123 22:13:47.512430 12543 solver.cpp:252]     Train net output #0: loss = 0.00725851 (* 1 = 0.00725851 loss)
I1123 22:13:47.512434 12543 sgd_solver.cpp:106] Iteration 41100, lr = 2e-05
I1123 22:13:48.205680 12543 solver.cpp:236] Iteration 41200, loss = 0.0089685
I1123 22:13:48.205708 12543 solver.cpp:252]     Train net output #0: loss = 0.0200268 (* 1 = 0.0200268 loss)
I1123 22:13:48.205714 12543 sgd_solver.cpp:106] Iteration 41200, lr = 2e-05
I1123 22:13:48.880904 12543 solver.cpp:236] Iteration 41300, loss = 0.00736854
I1123 22:13:48.880933 12543 solver.cpp:252]     Train net output #0: loss = 0.00256133 (* 1 = 0.00256133 loss)
I1123 22:13:48.880939 12543 sgd_solver.cpp:106] Iteration 41300, lr = 2e-05
I1123 22:13:49.558238 12543 solver.cpp:236] Iteration 41400, loss = 0.0135518
I1123 22:13:49.558267 12543 solver.cpp:252]     Train net output #0: loss = 0.0115444 (* 1 = 0.0115444 loss)
I1123 22:13:49.558274 12543 sgd_solver.cpp:106] Iteration 41400, lr = 2e-05
I1123 22:13:50.233487 12543 solver.cpp:340] Iteration 41500, Testing net (#0)
I1123 22:13:50.421298 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:13:50.421325 12543 solver.cpp:408]     Test net output #1: loss = 0.0265647 (* 1 = 0.0265647 loss)
I1123 22:13:50.423245 12543 solver.cpp:236] Iteration 41500, loss = 0.00956321
I1123 22:13:50.423261 12543 solver.cpp:252]     Train net output #0: loss = 0.00279961 (* 1 = 0.00279961 loss)
I1123 22:13:50.423266 12543 sgd_solver.cpp:106] Iteration 41500, lr = 2e-05
I1123 22:13:51.104333 12543 solver.cpp:236] Iteration 41600, loss = 0.00883883
I1123 22:13:51.104369 12543 solver.cpp:252]     Train net output #0: loss = 0.00261145 (* 1 = 0.00261145 loss)
I1123 22:13:51.104382 12543 sgd_solver.cpp:106] Iteration 41600, lr = 2e-05
I1123 22:13:51.782287 12543 solver.cpp:236] Iteration 41700, loss = 0.021485
I1123 22:13:51.782317 12543 solver.cpp:252]     Train net output #0: loss = 0.0127585 (* 1 = 0.0127585 loss)
I1123 22:13:51.782322 12543 sgd_solver.cpp:106] Iteration 41700, lr = 2e-05
I1123 22:13:52.458920 12543 solver.cpp:236] Iteration 41800, loss = 0.0134019
I1123 22:13:52.458950 12543 solver.cpp:252]     Train net output #0: loss = 0.100406 (* 1 = 0.100406 loss)
I1123 22:13:52.458956 12543 sgd_solver.cpp:106] Iteration 41800, lr = 2e-05
I1123 22:13:53.142416 12543 solver.cpp:236] Iteration 41900, loss = 0.0111359
I1123 22:13:53.142448 12543 solver.cpp:252]     Train net output #0: loss = 0.0255528 (* 1 = 0.0255528 loss)
I1123 22:13:53.142455 12543 sgd_solver.cpp:106] Iteration 41900, lr = 2e-05
I1123 22:13:53.813690 12543 solver.cpp:340] Iteration 42000, Testing net (#0)
I1123 22:13:54.002573 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9959
I1123 22:13:54.002599 12543 solver.cpp:408]     Test net output #1: loss = 0.0264153 (* 1 = 0.0264153 loss)
I1123 22:13:54.004520 12543 solver.cpp:236] Iteration 42000, loss = 0.011493
I1123 22:13:54.004536 12543 solver.cpp:252]     Train net output #0: loss = 0.0223287 (* 1 = 0.0223287 loss)
I1123 22:13:54.004544 12543 sgd_solver.cpp:106] Iteration 42000, lr = 2e-05
I1123 22:13:54.684646 12543 solver.cpp:236] Iteration 42100, loss = 0.0126275
I1123 22:13:54.684679 12543 solver.cpp:252]     Train net output #0: loss = 0.0326313 (* 1 = 0.0326313 loss)
I1123 22:13:54.684701 12543 sgd_solver.cpp:106] Iteration 42100, lr = 2e-05
I1123 22:13:55.365692 12543 solver.cpp:236] Iteration 42200, loss = 0.0107026
I1123 22:13:55.365721 12543 solver.cpp:252]     Train net output #0: loss = 0.0121527 (* 1 = 0.0121527 loss)
I1123 22:13:55.365727 12543 sgd_solver.cpp:106] Iteration 42200, lr = 2e-05
I1123 22:13:56.038244 12543 solver.cpp:236] Iteration 42300, loss = 0.0142086
I1123 22:13:56.038274 12543 solver.cpp:252]     Train net output #0: loss = 0.0121041 (* 1 = 0.0121041 loss)
I1123 22:13:56.038280 12543 sgd_solver.cpp:106] Iteration 42300, lr = 2e-05
I1123 22:13:56.715183 12543 solver.cpp:236] Iteration 42400, loss = 0.00801317
I1123 22:13:56.715276 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:13:56.715286 12543 sgd_solver.cpp:106] Iteration 42400, lr = 2e-05
I1123 22:13:57.381304 12543 solver.cpp:340] Iteration 42500, Testing net (#0)
I1123 22:13:57.574414 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9956
I1123 22:13:57.574445 12543 solver.cpp:408]     Test net output #1: loss = 0.0269069 (* 1 = 0.0269069 loss)
I1123 22:13:57.576761 12543 solver.cpp:236] Iteration 42500, loss = 0.0141313
I1123 22:13:57.576783 12543 solver.cpp:252]     Train net output #0: loss = 0.00428405 (* 1 = 0.00428405 loss)
I1123 22:13:57.576792 12543 sgd_solver.cpp:106] Iteration 42500, lr = 2e-05
I1123 22:13:58.259994 12543 solver.cpp:236] Iteration 42600, loss = 0.0114248
I1123 22:13:58.260025 12543 solver.cpp:252]     Train net output #0: loss = 0.00407891 (* 1 = 0.00407891 loss)
I1123 22:13:58.260032 12543 sgd_solver.cpp:106] Iteration 42600, lr = 2e-05
I1123 22:13:58.933398 12543 solver.cpp:236] Iteration 42700, loss = 0.0134644
I1123 22:13:58.933429 12543 solver.cpp:252]     Train net output #0: loss = 0.0170307 (* 1 = 0.0170307 loss)
I1123 22:13:58.933436 12543 sgd_solver.cpp:106] Iteration 42700, lr = 2e-05
I1123 22:13:59.609716 12543 solver.cpp:236] Iteration 42800, loss = 0.0104514
I1123 22:13:59.609746 12543 solver.cpp:252]     Train net output #0: loss = 0.0241679 (* 1 = 0.0241679 loss)
I1123 22:13:59.609752 12543 sgd_solver.cpp:106] Iteration 42800, lr = 2e-05
I1123 22:14:00.290314 12543 solver.cpp:236] Iteration 42900, loss = 0.0100475
I1123 22:14:00.290345 12543 solver.cpp:252]     Train net output #0: loss = 0.00757864 (* 1 = 0.00757864 loss)
I1123 22:14:00.290352 12543 sgd_solver.cpp:106] Iteration 42900, lr = 2e-05
I1123 22:14:00.964462 12543 solver.cpp:340] Iteration 43000, Testing net (#0)
I1123 22:14:01.152734 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9959
I1123 22:14:01.152762 12543 solver.cpp:408]     Test net output #1: loss = 0.0265657 (* 1 = 0.0265657 loss)
I1123 22:14:01.154697 12543 solver.cpp:236] Iteration 43000, loss = 0.0126396
I1123 22:14:01.154716 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:01.154724 12543 sgd_solver.cpp:106] Iteration 43000, lr = 2e-05
I1123 22:14:01.827586 12543 solver.cpp:236] Iteration 43100, loss = 0.0080444
I1123 22:14:01.827615 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:01.827621 12543 sgd_solver.cpp:106] Iteration 43100, lr = 2e-05
I1123 22:14:02.505650 12543 solver.cpp:236] Iteration 43200, loss = 0.00920666
I1123 22:14:02.505681 12543 solver.cpp:252]     Train net output #0: loss = 0.00475038 (* 1 = 0.00475038 loss)
I1123 22:14:02.505686 12543 sgd_solver.cpp:106] Iteration 43200, lr = 2e-05
I1123 22:14:03.180042 12543 solver.cpp:236] Iteration 43300, loss = 0.0149242
I1123 22:14:03.180071 12543 solver.cpp:252]     Train net output #0: loss = 0.00015915 (* 1 = 0.00015915 loss)
I1123 22:14:03.180078 12543 sgd_solver.cpp:106] Iteration 43300, lr = 2e-05
I1123 22:14:03.867986 12543 solver.cpp:236] Iteration 43400, loss = 0.00944992
I1123 22:14:03.868015 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:03.868021 12543 sgd_solver.cpp:106] Iteration 43400, lr = 2e-05
I1123 22:14:04.539726 12543 solver.cpp:340] Iteration 43500, Testing net (#0)
I1123 22:14:04.729686 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:14:04.729717 12543 solver.cpp:408]     Test net output #1: loss = 0.0263665 (* 1 = 0.0263665 loss)
I1123 22:14:04.731684 12543 solver.cpp:236] Iteration 43500, loss = 0.0111734
I1123 22:14:04.731706 12543 solver.cpp:252]     Train net output #0: loss = 0.0223342 (* 1 = 0.0223342 loss)
I1123 22:14:04.731715 12543 sgd_solver.cpp:106] Iteration 43500, lr = 2e-05
I1123 22:14:05.418087 12543 solver.cpp:236] Iteration 43600, loss = 0.00892361
I1123 22:14:05.418117 12543 solver.cpp:252]     Train net output #0: loss = 0.00586847 (* 1 = 0.00586847 loss)
I1123 22:14:05.418123 12543 sgd_solver.cpp:106] Iteration 43600, lr = 2e-05
I1123 22:14:06.095845 12543 solver.cpp:236] Iteration 43700, loss = 0.0151871
I1123 22:14:06.095876 12543 solver.cpp:252]     Train net output #0: loss = 0.0263558 (* 1 = 0.0263558 loss)
I1123 22:14:06.095882 12543 sgd_solver.cpp:106] Iteration 43700, lr = 2e-05
I1123 22:14:06.774963 12543 solver.cpp:236] Iteration 43800, loss = 0.010032
I1123 22:14:06.774994 12543 solver.cpp:252]     Train net output #0: loss = 0.0022984 (* 1 = 0.0022984 loss)
I1123 22:14:06.775002 12543 sgd_solver.cpp:106] Iteration 43800, lr = 2e-05
I1123 22:14:07.449067 12543 solver.cpp:236] Iteration 43900, loss = 0.00765763
I1123 22:14:07.449098 12543 solver.cpp:252]     Train net output #0: loss = 0.0116736 (* 1 = 0.0116736 loss)
I1123 22:14:07.449106 12543 sgd_solver.cpp:106] Iteration 43900, lr = 2e-05
I1123 22:14:08.118510 12543 solver.cpp:340] Iteration 44000, Testing net (#0)
I1123 22:14:08.308751 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9959
I1123 22:14:08.308779 12543 solver.cpp:408]     Test net output #1: loss = 0.0264349 (* 1 = 0.0264349 loss)
I1123 22:14:08.310662 12543 solver.cpp:236] Iteration 44000, loss = 0.0108321
I1123 22:14:08.310678 12543 solver.cpp:252]     Train net output #0: loss = 0.0089858 (* 1 = 0.0089858 loss)
I1123 22:14:08.310686 12543 sgd_solver.cpp:106] Iteration 44000, lr = 2e-05
I1123 22:14:09.006260 12543 solver.cpp:236] Iteration 44100, loss = 0.0141188
I1123 22:14:09.006290 12543 solver.cpp:252]     Train net output #0: loss = 0.0340718 (* 1 = 0.0340718 loss)
I1123 22:14:09.006297 12543 sgd_solver.cpp:106] Iteration 44100, lr = 2e-05
I1123 22:14:09.701509 12543 solver.cpp:236] Iteration 44200, loss = 0.0164641
I1123 22:14:09.701557 12543 solver.cpp:252]     Train net output #0: loss = 0.00387968 (* 1 = 0.00387968 loss)
I1123 22:14:09.701570 12543 sgd_solver.cpp:106] Iteration 44200, lr = 2e-05
I1123 22:14:10.388201 12543 solver.cpp:236] Iteration 44300, loss = 0.00765155
I1123 22:14:10.388232 12543 solver.cpp:252]     Train net output #0: loss = 0.00694744 (* 1 = 0.00694744 loss)
I1123 22:14:10.388239 12543 sgd_solver.cpp:106] Iteration 44300, lr = 2e-05
I1123 22:14:11.063305 12543 solver.cpp:236] Iteration 44400, loss = 0.0127581
I1123 22:14:11.063335 12543 solver.cpp:252]     Train net output #0: loss = 0.0103098 (* 1 = 0.0103098 loss)
I1123 22:14:11.063344 12543 sgd_solver.cpp:106] Iteration 44400, lr = 2e-05
I1123 22:14:11.773813 12543 solver.cpp:340] Iteration 44500, Testing net (#0)
I1123 22:14:11.969321 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9957
I1123 22:14:11.969349 12543 solver.cpp:408]     Test net output #1: loss = 0.02668 (* 1 = 0.02668 loss)
I1123 22:14:11.971287 12543 solver.cpp:236] Iteration 44500, loss = 0.0179704
I1123 22:14:11.971304 12543 solver.cpp:252]     Train net output #0: loss = 0.0125825 (* 1 = 0.0125825 loss)
I1123 22:14:11.971312 12543 sgd_solver.cpp:106] Iteration 44500, lr = 2e-05
I1123 22:14:12.677680 12543 solver.cpp:236] Iteration 44600, loss = 0.0119422
I1123 22:14:12.677711 12543 solver.cpp:252]     Train net output #0: loss = 0.04716 (* 1 = 0.04716 loss)
I1123 22:14:12.677721 12543 sgd_solver.cpp:106] Iteration 44600, lr = 2e-05
I1123 22:14:13.391113 12543 solver.cpp:236] Iteration 44700, loss = 0.00880619
I1123 22:14:13.391144 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:13.391151 12543 sgd_solver.cpp:106] Iteration 44700, lr = 2e-05
I1123 22:14:14.070639 12543 solver.cpp:236] Iteration 44800, loss = 0.00830554
I1123 22:14:14.070668 12543 solver.cpp:252]     Train net output #0: loss = 0.0252466 (* 1 = 0.0252466 loss)
I1123 22:14:14.070677 12543 sgd_solver.cpp:106] Iteration 44800, lr = 2e-05
I1123 22:14:14.746116 12543 solver.cpp:236] Iteration 44900, loss = 0.0146011
I1123 22:14:14.746145 12543 solver.cpp:252]     Train net output #0: loss = 0.0479246 (* 1 = 0.0479246 loss)
I1123 22:14:14.746151 12543 sgd_solver.cpp:106] Iteration 44900, lr = 2e-05
I1123 22:14:15.430721 12543 solver.cpp:340] Iteration 45000, Testing net (#0)
I1123 22:14:15.641333 12543 solver.cpp:408]     Test net output #0: accuracy = 0.9958
I1123 22:14:15.641386 12543 solver.cpp:408]     Test net output #1: loss = 0.0266712 (* 1 = 0.0266712 loss)
I1123 22:14:15.643338 12543 solver.cpp:236] Iteration 45000, loss = 0.00839218
I1123 22:14:15.643357 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:15.643364 12543 sgd_solver.cpp:106] Iteration 45000, lr = 2e-06
I1123 22:14:16.343430 12543 solver.cpp:236] Iteration 45100, loss = 0.0126984
I1123 22:14:16.343472 12543 solver.cpp:252]     Train net output #0: loss = 0.0202373 (* 1 = 0.0202373 loss)
I1123 22:14:16.343483 12543 sgd_solver.cpp:106] Iteration 45100, lr = 2e-06
I1123 22:14:17.033550 12543 solver.cpp:236] Iteration 45200, loss = 0.00850868
I1123 22:14:17.033581 12543 solver.cpp:252]     Train net output #0: loss = 0.0140583 (* 1 = 0.0140583 loss)
I1123 22:14:17.033586 12543 sgd_solver.cpp:106] Iteration 45200, lr = 2e-06
I1123 22:14:17.711827 12543 solver.cpp:236] Iteration 45300, loss = 0.0133935
I1123 22:14:17.711855 12543 solver.cpp:252]     Train net output #0: loss = 0.012903 (* 1 = 0.012903 loss)
I1123 22:14:17.711860 12543 sgd_solver.cpp:106] Iteration 45300, lr = 2e-06
I1123 22:14:18.392215 12543 solver.cpp:236] Iteration 45400, loss = 0.00917908
I1123 22:14:18.392242 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:18.392247 12543 sgd_solver.cpp:106] Iteration 45400, lr = 2e-06
I1123 22:14:19.078325 12543 solver.cpp:340] Iteration 45500, Testing net (#0)
I1123 22:14:19.276854 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:19.276881 12543 solver.cpp:408]     Test net output #1: loss = 0.0266849 (* 1 = 0.0266849 loss)
I1123 22:14:19.278823 12543 solver.cpp:236] Iteration 45500, loss = 0.00890907
I1123 22:14:19.278841 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:19.278849 12543 sgd_solver.cpp:106] Iteration 45500, lr = 2e-06
I1123 22:14:19.966780 12543 solver.cpp:236] Iteration 45600, loss = 0.0073025
I1123 22:14:19.966812 12543 solver.cpp:252]     Train net output #0: loss = 0.00116638 (* 1 = 0.00116638 loss)
I1123 22:14:19.966821 12543 sgd_solver.cpp:106] Iteration 45600, lr = 2e-06
I1123 22:14:20.648777 12543 solver.cpp:236] Iteration 45700, loss = 0.0124384
I1123 22:14:20.648805 12543 solver.cpp:252]     Train net output #0: loss = 0.00201557 (* 1 = 0.00201557 loss)
I1123 22:14:20.648813 12543 sgd_solver.cpp:106] Iteration 45700, lr = 2e-06
I1123 22:14:21.329982 12543 solver.cpp:236] Iteration 45800, loss = 0.0124762
I1123 22:14:21.330013 12543 solver.cpp:252]     Train net output #0: loss = 0.115476 (* 1 = 0.115476 loss)
I1123 22:14:21.330021 12543 sgd_solver.cpp:106] Iteration 45800, lr = 2e-06
I1123 22:14:22.012487 12543 solver.cpp:236] Iteration 45900, loss = 0.00793416
I1123 22:14:22.012512 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:22.012517 12543 sgd_solver.cpp:106] Iteration 45900, lr = 2e-06
I1123 22:14:22.682852 12543 solver.cpp:340] Iteration 46000, Testing net (#0)
I1123 22:14:22.875957 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:22.875982 12543 solver.cpp:408]     Test net output #1: loss = 0.0266346 (* 1 = 0.0266346 loss)
I1123 22:14:22.877903 12543 solver.cpp:236] Iteration 46000, loss = 0.00695756
I1123 22:14:22.877918 12543 solver.cpp:252]     Train net output #0: loss = 0.0017423 (* 1 = 0.0017423 loss)
I1123 22:14:22.877923 12543 sgd_solver.cpp:106] Iteration 46000, lr = 2e-06
I1123 22:14:23.553130 12543 solver.cpp:236] Iteration 46100, loss = 0.0118036
I1123 22:14:23.553158 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:23.553163 12543 sgd_solver.cpp:106] Iteration 46100, lr = 2e-06
I1123 22:14:24.229414 12543 solver.cpp:236] Iteration 46200, loss = 0.00966575
I1123 22:14:24.229442 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:24.229446 12543 sgd_solver.cpp:106] Iteration 46200, lr = 2e-06
I1123 22:14:24.904563 12543 solver.cpp:236] Iteration 46300, loss = 0.00826561
I1123 22:14:24.904592 12543 solver.cpp:252]     Train net output #0: loss = 1.65654e-05 (* 1 = 1.65654e-05 loss)
I1123 22:14:24.904608 12543 sgd_solver.cpp:106] Iteration 46300, lr = 2e-06
I1123 22:14:25.580482 12543 solver.cpp:236] Iteration 46400, loss = 0.00744298
I1123 22:14:25.580518 12543 solver.cpp:252]     Train net output #0: loss = 0.00481755 (* 1 = 0.00481755 loss)
I1123 22:14:25.580525 12543 sgd_solver.cpp:106] Iteration 46400, lr = 2e-06
I1123 22:14:26.264536 12543 solver.cpp:340] Iteration 46500, Testing net (#0)
I1123 22:14:26.458350 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:26.458374 12543 solver.cpp:408]     Test net output #1: loss = 0.0266124 (* 1 = 0.0266124 loss)
I1123 22:14:26.460278 12543 solver.cpp:236] Iteration 46500, loss = 0.0119331
I1123 22:14:26.460290 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:26.460295 12543 sgd_solver.cpp:106] Iteration 46500, lr = 2e-06
I1123 22:14:27.156128 12543 solver.cpp:236] Iteration 46600, loss = 0.0087435
I1123 22:14:27.156220 12543 solver.cpp:252]     Train net output #0: loss = 0.000709755 (* 1 = 0.000709755 loss)
I1123 22:14:27.156229 12543 sgd_solver.cpp:106] Iteration 46600, lr = 2e-06
I1123 22:14:27.841855 12543 solver.cpp:236] Iteration 46700, loss = 0.00816379
I1123 22:14:27.841882 12543 solver.cpp:252]     Train net output #0: loss = 0.00332064 (* 1 = 0.00332064 loss)
I1123 22:14:27.841888 12543 sgd_solver.cpp:106] Iteration 46700, lr = 2e-06
I1123 22:14:28.525851 12543 solver.cpp:236] Iteration 46800, loss = 0.0158358
I1123 22:14:28.525879 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:28.525885 12543 sgd_solver.cpp:106] Iteration 46800, lr = 2e-06
I1123 22:14:29.207458 12543 solver.cpp:236] Iteration 46900, loss = 0.0141373
I1123 22:14:29.207486 12543 solver.cpp:252]     Train net output #0: loss = 0.0136807 (* 1 = 0.0136807 loss)
I1123 22:14:29.207494 12543 sgd_solver.cpp:106] Iteration 46900, lr = 2e-06
I1123 22:14:29.888646 12543 solver.cpp:340] Iteration 47000, Testing net (#0)
I1123 22:14:30.095963 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:30.095989 12543 solver.cpp:408]     Test net output #1: loss = 0.0266416 (* 1 = 0.0266416 loss)
I1123 22:14:30.097920 12543 solver.cpp:236] Iteration 47000, loss = 0.0179464
I1123 22:14:30.097934 12543 solver.cpp:252]     Train net output #0: loss = 0.00535584 (* 1 = 0.00535584 loss)
I1123 22:14:30.097941 12543 sgd_solver.cpp:106] Iteration 47000, lr = 2e-06
I1123 22:14:30.770515 12543 solver.cpp:236] Iteration 47100, loss = 0.0083282
I1123 22:14:30.770542 12543 solver.cpp:252]     Train net output #0: loss = 0.00452783 (* 1 = 0.00452783 loss)
I1123 22:14:30.770547 12543 sgd_solver.cpp:106] Iteration 47100, lr = 2e-06
I1123 22:14:31.446646 12543 solver.cpp:236] Iteration 47200, loss = 0.00828476
I1123 22:14:31.446676 12543 solver.cpp:252]     Train net output #0: loss = 0.0177493 (* 1 = 0.0177493 loss)
I1123 22:14:31.446681 12543 sgd_solver.cpp:106] Iteration 47200, lr = 2e-06
I1123 22:14:32.137344 12543 solver.cpp:236] Iteration 47300, loss = 0.0143582
I1123 22:14:32.137372 12543 solver.cpp:252]     Train net output #0: loss = 0.00247911 (* 1 = 0.00247911 loss)
I1123 22:14:32.137377 12543 sgd_solver.cpp:106] Iteration 47300, lr = 2e-06
I1123 22:14:32.814106 12543 solver.cpp:236] Iteration 47400, loss = 0.0112746
I1123 22:14:32.814134 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:32.814138 12543 sgd_solver.cpp:106] Iteration 47400, lr = 2e-06
I1123 22:14:33.487129 12543 solver.cpp:340] Iteration 47500, Testing net (#0)
I1123 22:14:33.674857 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:33.674883 12543 solver.cpp:408]     Test net output #1: loss = 0.0266348 (* 1 = 0.0266348 loss)
I1123 22:14:33.676796 12543 solver.cpp:236] Iteration 47500, loss = 0.00928639
I1123 22:14:33.676810 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:33.676815 12543 sgd_solver.cpp:106] Iteration 47500, lr = 2e-06
I1123 22:14:34.351748 12543 solver.cpp:236] Iteration 47600, loss = 0.0081619
I1123 22:14:34.351775 12543 solver.cpp:252]     Train net output #0: loss = 0.0156975 (* 1 = 0.0156975 loss)
I1123 22:14:34.351781 12543 sgd_solver.cpp:106] Iteration 47600, lr = 2e-06
I1123 22:14:35.037590 12543 solver.cpp:236] Iteration 47700, loss = 0.0140609
I1123 22:14:35.037618 12543 solver.cpp:252]     Train net output #0: loss = 0.0034462 (* 1 = 0.0034462 loss)
I1123 22:14:35.037623 12543 sgd_solver.cpp:106] Iteration 47700, lr = 2e-06
I1123 22:14:35.718726 12543 solver.cpp:236] Iteration 47800, loss = 0.00469
I1123 22:14:35.718755 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:35.718760 12543 sgd_solver.cpp:106] Iteration 47800, lr = 2e-06
I1123 22:14:36.398977 12543 solver.cpp:236] Iteration 47900, loss = 0.0101347
I1123 22:14:36.399005 12543 solver.cpp:252]     Train net output #0: loss = 0.00295037 (* 1 = 0.00295037 loss)
I1123 22:14:36.399010 12543 sgd_solver.cpp:106] Iteration 47900, lr = 2e-06
I1123 22:14:37.067713 12543 solver.cpp:340] Iteration 48000, Testing net (#0)
I1123 22:14:37.258136 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:37.258162 12543 solver.cpp:408]     Test net output #1: loss = 0.0266609 (* 1 = 0.0266609 loss)
I1123 22:14:37.260236 12543 solver.cpp:236] Iteration 48000, loss = 0.0142378
I1123 22:14:37.260257 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:37.260265 12543 sgd_solver.cpp:106] Iteration 48000, lr = 2e-06
I1123 22:14:37.942865 12543 solver.cpp:236] Iteration 48100, loss = 0.011558
I1123 22:14:37.942895 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:37.942901 12543 sgd_solver.cpp:106] Iteration 48100, lr = 2e-06
I1123 22:14:38.621413 12543 solver.cpp:236] Iteration 48200, loss = 0.0107461
I1123 22:14:38.621443 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:38.621448 12543 sgd_solver.cpp:106] Iteration 48200, lr = 2e-06
I1123 22:14:39.296674 12543 solver.cpp:236] Iteration 48300, loss = 0.00937921
I1123 22:14:39.296703 12543 solver.cpp:252]     Train net output #0: loss = 0.0026509 (* 1 = 0.0026509 loss)
I1123 22:14:39.296710 12543 sgd_solver.cpp:106] Iteration 48300, lr = 2e-06
I1123 22:14:39.979259 12543 solver.cpp:236] Iteration 48400, loss = 0.0118352
I1123 22:14:39.979287 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:39.979293 12543 sgd_solver.cpp:106] Iteration 48400, lr = 2e-06
I1123 22:14:40.646522 12543 solver.cpp:340] Iteration 48500, Testing net (#0)
I1123 22:14:40.838194 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:40.838220 12543 solver.cpp:408]     Test net output #1: loss = 0.0266601 (* 1 = 0.0266601 loss)
I1123 22:14:40.840140 12543 solver.cpp:236] Iteration 48500, loss = 0.0104602
I1123 22:14:40.840155 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:40.840163 12543 sgd_solver.cpp:106] Iteration 48500, lr = 2e-06
I1123 22:14:41.524045 12543 solver.cpp:236] Iteration 48600, loss = 0.00917544
I1123 22:14:41.524075 12543 solver.cpp:252]     Train net output #0: loss = 0.0200897 (* 1 = 0.0200897 loss)
I1123 22:14:41.524080 12543 sgd_solver.cpp:106] Iteration 48600, lr = 2e-06
I1123 22:14:42.215751 12543 solver.cpp:236] Iteration 48700, loss = 0.010818
I1123 22:14:42.215778 12543 solver.cpp:252]     Train net output #0: loss = 0.0201519 (* 1 = 0.0201519 loss)
I1123 22:14:42.215783 12543 sgd_solver.cpp:106] Iteration 48700, lr = 2e-06
I1123 22:14:42.901362 12543 solver.cpp:236] Iteration 48800, loss = 0.00434972
I1123 22:14:42.901396 12543 solver.cpp:252]     Train net output #0: loss = 0.0079049 (* 1 = 0.0079049 loss)
I1123 22:14:42.901401 12543 sgd_solver.cpp:106] Iteration 48800, lr = 2e-06
I1123 22:14:43.580647 12543 solver.cpp:236] Iteration 48900, loss = 0.0158491
I1123 22:14:43.580674 12543 solver.cpp:252]     Train net output #0: loss = 0.0263151 (* 1 = 0.0263151 loss)
I1123 22:14:43.580678 12543 sgd_solver.cpp:106] Iteration 48900, lr = 2e-06
I1123 22:14:44.264459 12543 solver.cpp:340] Iteration 49000, Testing net (#0)
I1123 22:14:44.455164 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:44.455186 12543 solver.cpp:408]     Test net output #1: loss = 0.0267013 (* 1 = 0.0267013 loss)
I1123 22:14:44.457126 12543 solver.cpp:236] Iteration 49000, loss = 0.00842201
I1123 22:14:44.457139 12543 solver.cpp:252]     Train net output #0: loss = 0.0129052 (* 1 = 0.0129052 loss)
I1123 22:14:44.457145 12543 sgd_solver.cpp:106] Iteration 49000, lr = 2e-06
I1123 22:14:45.135126 12543 solver.cpp:236] Iteration 49100, loss = 0.0104
I1123 22:14:45.135154 12543 solver.cpp:252]     Train net output #0: loss = 0.0164769 (* 1 = 0.0164769 loss)
I1123 22:14:45.135159 12543 sgd_solver.cpp:106] Iteration 49100, lr = 2e-06
I1123 22:14:45.821532 12543 solver.cpp:236] Iteration 49200, loss = 0.0173309
I1123 22:14:45.821569 12543 solver.cpp:252]     Train net output #0: loss = 0.00279066 (* 1 = 0.00279066 loss)
I1123 22:14:45.821586 12543 sgd_solver.cpp:106] Iteration 49200, lr = 2e-06
I1123 22:14:46.546974 12543 solver.cpp:236] Iteration 49300, loss = 0.0119972
I1123 22:14:46.547005 12543 solver.cpp:252]     Train net output #0: loss = 0.0895553 (* 1 = 0.0895553 loss)
I1123 22:14:46.547013 12543 sgd_solver.cpp:106] Iteration 49300, lr = 2e-06
I1123 22:14:47.239023 12543 solver.cpp:236] Iteration 49400, loss = 0.0101502
I1123 22:14:47.239053 12543 solver.cpp:252]     Train net output #0: loss = 0.00786953 (* 1 = 0.00786953 loss)
I1123 22:14:47.239060 12543 sgd_solver.cpp:106] Iteration 49400, lr = 2e-06
I1123 22:14:47.915376 12543 solver.cpp:340] Iteration 49500, Testing net (#0)
I1123 22:14:48.105013 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:48.105041 12543 solver.cpp:408]     Test net output #1: loss = 0.0266223 (* 1 = 0.0266223 loss)
I1123 22:14:48.106940 12543 solver.cpp:236] Iteration 49500, loss = 0.00851631
I1123 22:14:48.106955 12543 solver.cpp:252]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 22:14:48.106962 12543 sgd_solver.cpp:106] Iteration 49500, lr = 2e-06
I1123 22:14:48.775465 12543 solver.cpp:236] Iteration 49600, loss = 0.013844
I1123 22:14:48.775492 12543 solver.cpp:252]     Train net output #0: loss = 0.00749868 (* 1 = 0.00749868 loss)
I1123 22:14:48.775499 12543 sgd_solver.cpp:106] Iteration 49600, lr = 2e-06
I1123 22:14:49.450523 12543 solver.cpp:236] Iteration 49700, loss = 0.00896147
I1123 22:14:49.450552 12543 solver.cpp:252]     Train net output #0: loss = 0.00564947 (* 1 = 0.00564947 loss)
I1123 22:14:49.450558 12543 sgd_solver.cpp:106] Iteration 49700, lr = 2e-06
I1123 22:14:50.126483 12543 solver.cpp:236] Iteration 49800, loss = 0.0125892
I1123 22:14:50.126513 12543 solver.cpp:252]     Train net output #0: loss = 0.00325787 (* 1 = 0.00325787 loss)
I1123 22:14:50.126519 12543 sgd_solver.cpp:106] Iteration 49800, lr = 2e-06
I1123 22:14:50.803684 12543 solver.cpp:236] Iteration 49900, loss = 0.00663792
I1123 22:14:50.803715 12543 solver.cpp:252]     Train net output #0: loss = 0.00184853 (* 1 = 0.00184853 loss)
I1123 22:14:50.803721 12543 sgd_solver.cpp:106] Iteration 49900, lr = 2e-06
I1123 22:14:51.470054 12543 solver.cpp:461] Snapshotting to binary proto file snapshots/fitnet_mnist_lsuv_SVM_iter_50000.caffemodel
I1123 22:14:51.475633 12543 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/fitnet_mnist_lsuv_SVM_iter_50000.solverstate
I1123 22:14:51.477143 12543 solver.cpp:320] Iteration 50000, loss = 0.00849906
I1123 22:14:51.477156 12543 solver.cpp:340] Iteration 50000, Testing net (#0)
I1123 22:14:51.663259 12543 solver.cpp:408]     Test net output #0: accuracy = 0.996
I1123 22:14:51.663287 12543 solver.cpp:408]     Test net output #1: loss = 0.0266461 (* 1 = 0.0266461 loss)
I1123 22:14:51.663292 12543 solver.cpp:325] Optimization Done.
I1123 22:14:51.663296 12543 caffe.cpp:215] Optimization Done.
